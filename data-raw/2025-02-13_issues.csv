rowid,number,state,title,labels_name,labels_id,labels_color,labels_description,commentcount,body,comments_txt,draft,comments_url,created_at,updated_at,user,assignee1,medium,high,high-ish,high not high-ish
1,738,open,Identify functions where arrow as_data_table = FALSE can speed up site selection/analysis,enhancement|datasets/ pins/ AWS/ etc.|speed / performance (see #444)|urgency high-ish but not a bug,4538805068|6343736234|6535412240|7539794549,cfd3d7|0E8A16|e99695|B9463A,"New feature or request|related to data files via pins board, AWS, dataload_ etc.|related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.|for high urgency enhancements, to rank them just below high urgency bugs",2,,"@DougMoy please look at attached list of scripts for feasibility of this approach|https://github.com/USEPA/EJAM/tree/issue738SpeedUpSiteSelection
Will make a PR when generic branch is reviewed","For some tasks, arrow queries can work much faster than data.table operations. We want to identify functions where we use arrow datasets already that may benefit from speedups. Start by looking in functions that call `dataload_from_pins` within them - see attached list [scripts_with_dataload_from_pins.txt](https://github.com/user-attachments/files/18675055/scripts_with_dataload_from_pins.txt)

Typically this involves two steps: 
1. reading an arrow file in with `as_data_frame = FALSE`. we now can do this on development through `dataload_from_pins('dataset', return_data_table = FALSE)`
2. applying dplyr's `filter, mutate, select` operations followed by `dplyr::collect()` - see more info here: https://arrow.apache.org/docs/r/articles/data_wrangling.html

Example for site selection: `frs_from_naics`

```
## loads frs dataset
dataload_from_pins('frs')
## loads frs_arrow dataset
dataload_from_pins('frs', return_data_table = FALSE)

microbenchmark::microbenchmark(
  data.table = {
      test_c <- frs_from_naics('112')
    },
  arrow = {
      test_a <- frs_arrow %>% 
                filter(REGISTRY_ID %in% regid_from_naics(naics_from_any('112')$code, id_only=T)) %>% 
                collect()
    },
  times=25
)
# Unit: milliseconds
# expr            min         lq       mean     median         uq       max     neval cld
# data.table  2059.28204 2082.12350 2154.57276 2098.81441 2127.61937 2586.4577    25  a 
# arrow         69.04982   69.62738   80.03024   74.55602   83.03712  120.1646    25   b
```",https://api.github.com/repos/USEPA/EJAM/issues/738/comments,2/5/2025,2/13/2025,mlfurman3,DougMoy,0,1,1,FALSE
2,727,open,Improve messages used when max points uploaded/selected is exceeded,urgency medium,6227894519,FBCA04,,0,,,"When using the app, we have a few inputs that check the number of points uploaded or selected and limit the functionality
- `input$max_pts_map`: stop mapping but can continue analyzing
- `input$max_pts_upload`: disable analysis button if exceeded
- `input$max_pts_select`: disable analysis button if exceeded

More descriptive language is needed in the shiny::validate statements for these situations. Some potential suggestions

- ""Too many locations to display the map. You can still run an analysis."" or

- ""Too many locations have been uploaded. Please choose a file with fewer locations.""

- ""Too many locations have been selected. Please choose a group with fewer locations.""",https://api.github.com/repos/USEPA/EJAM/issues/727/comments,1/28/2025,1/28/2025,mlfurman3,saradelessio-abt,1,0,0,FALSE
3,725,open,"set  use_shapefile_from_any=TRUE, if ready to fix/use newer code in server",refactor|urgency low,6208400114|6227891676,8F13A1|cfd3d7,Rewrite how code works or break into smaller pieces|,0,,,"A chunk of server code was meant to be used once it was working, to replace some server code with a function. It should get cleaned up/used or that chunk should be dropped if appropriate.
see global.R and app_server.R section with this:
```
if (use_shapefile_from_any)

```",https://api.github.com/repos/USEPA/EJAM/issues/725/comments,1/28/2025,2/3/2025,ejanalysis,ParkerJanMalek,0,0,0,FALSE
4,719,open,"delete obsolete branches, update/use those still relevant (to avoid confusion and clutter & incorporate work already done)",enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,1,,"Worked on branches that were labeled as mine. I updated older branches that still had relevant work with the development branch and deleted branches that were already merged in/obsolete. Below is a summary for what I did with each branch. 


Issue131, standalone functions for plots in app_server. Still need to add documentation to standalone functions. 
Function of the app shouldn't change with this branch. Updated it from dev and addressed merge conflicts in latest push

Deleted issue180 branch, looks like its already resolved in development

Deleted issue497 branch, already merged in

Issue133 was fips refactoring, decided to close for now and revisit when more fips refactoring would occur. 

issue317 was refactoring all nrow to NROW. Just updated it from dev and addressed merge conflicts in latest push. 

Deleted fixTest_fixcolnames, already merged in.

Deleted issue604, already merged in

issue88NewVersion is optimized version of doaggregate, has open pull request: https://github.com.mcas.ms/USEPA/EJAM/pull/646

Issue595 - added new ejscreen variables pulled from ejscreen api to blockgroupstats. Still need to look at the new data before deciding the next move. Leaving the branch as is.","1. If a branch is obsolete, go ahead and delete it to avoid confusion / clutter.
2. If a branch appears outdated but actually still has useful work on it that was never merged into dev, it should be updated from development and conflicts resolved and either turned into a PR or at least further worked on or noted as being on hold, etc.
 
Attached are 2 screenshots that show a long list of branches and how many commits they are behind and/or ahead of the development branch.

- About 25 branches are hundreds of commits behind development branch, suggesting they have not been worked on for a very long time and may be obsolete or need to be updated/ revived. 
- About 9 branches (as of 1/22/25) that seem to have zero commits ahead of development branch, suggesting they were already merged in but not yet deleted. 
- Another 11 branches are 1 commit ahead of development, so some of those are probably obsolete as well.


![Image](https://github.com/user-attachments/assets/8544e7cf-6629-4d23-9f3d-f6078ac309d9)
![Image](https://github.com/user-attachments/assets/fba08822-0e56-436e-856a-6eab59251086)",https://api.github.com/repos/USEPA/EJAM/issues/719/comments,1/22/2025,1/23/2025,ejanalysis,alex-silverman,1,0,0,FALSE
5,718,open,Update FRS data and scripts that do that,enhancement|urgency medium|datasets/ pins/ AWS/ etc.,4538805068|6227894519|6343736234,cfd3d7|FBCA04|0E8A16,"New feature or request||related to data files via pins board, AWS, dataload_ etc.",4,,"This PR contains updates to the FRS arrow dataset creation scripts and should be safe to integrate.|Need to make sure arrow datasets are updated so lookups and such will work.|> Need to make sure arrow datasets are updated so lookups and such will work.
OK, if not ready to merge in, at least just make a written note (here?) of what scripts /functions would have to be run to do those updates / what locations are the datasets stored at currently that need to be updated and how to update them at those locations. 
is it just USEPA/ejamdata ? are the old AWS and any other pins boards no longer used? 
is the script in EJAM\data-raw\datacreate_0_UPDATE_ALL_DATASETS.R sufficient?|I have now re-run the `data-raw/datacreate_frs_.R` script to re-build the 5 arrow datasets and associated count-based rda files. Still testing out the effects on the app and package.

The updated arrow files are in a PR to the ejamdata repo - need to be merged into main there. That will trigger a GHA to create a new release and then anytime EJAM is loaded or installed by a user, it will pull down the latest files.

Note: the data-raw script failed during the SIC part but ran that individually and worked ok. 

",FALSE,https://api.github.com/repos/USEPA/EJAM/issues/718/comments,1/22/2025,2/12/2025,ejanalysis,none,1,0,0,FALSE
6,715,open,"rerun pkgdown scripts to update the docs website (e.g., changes in ejam2report, etc.)",documentation|enhancement|urgency high-ish but not a bug,4538805066|4538805068|7539794549,C5DEF5|cfd3d7|B9463A,"Improvements or additions to documentation|New feature or request|for high urgency enhancements, to rank them just below high urgency bugs",0,,,"
rerun pkgdown scripts to update the documentation website for ejam2report() and other related functions, and maybe some outputs in some vignettes/articles or the screenshot snapshots of reports that are used there",https://api.github.com/repos/USEPA/EJAM/issues/715/comments,1/22/2025,1/22/2025,ejanalysis,ejanalysis,0,1,1,FALSE
7,714,open,update User Guide screenshots to reflect additional info in summary report,documentation|enhancement|urgency medium,4538805066|4538805068|6227894519,C5DEF5|cfd3d7|FBCA04,Improvements or additions to documentation|New feature or request|,0,,,,https://api.github.com/repos/USEPA/EJAM/issues/714/comments,1/22/2025,2/3/2025,ejanalysis,ejanalysis,1,0,0,FALSE
8,713,open,update example html report in testdata output examples,enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,0,,,"rerun scripts to datacreate_ the output example html report - recent PR added more indicators, etc.
",https://api.github.com/repos/USEPA/EJAM/issues/713/comments,1/22/2025,2/3/2025,ejanalysis,mlfurman3,0,0,0,FALSE
9,657,open,add to web app ability to see distribution of scores in each group,enhancement|urgency low|distance-related,4538805068|6227891676|6343333395,cfd3d7|cfd3d7|C2E0C6,New feature or request||related to distances variables or calculations or plots,0,,,"See Advanced vignette about by group by distance. Would need to define explicitly which tables and plots we want to show, out of the options listed in the vignette/article.",https://api.github.com/repos/USEPA/EJAM/issues/657/comments,12/13/2024,12/13/2024,ejanalysis,none,0,0,0,FALSE
10,652,open,polygon-based EJScreen Report functions needed + for webapp,enhancement|urgency low|maps-related|calculate/validate to EJScreen,4538805068|6227891676|6228710425|6343712128,cfd3d7|cfd3d7|C2E0C6|FBCA04,"New feature or request||related to maps|related to errors in numbers, replicating EJScreen stats",0,,,"- First, need at least a very simple way to query ejscreen API with a polygon to get a report on one polygon using the existing API. The existing suite of ejscreenapi-related functions need to be made to handle a shapefile/polygon query of the EJScreen API.

- The web app needs to be able to pull up an EJScreen Report for one polygon when a user clicks the button in the detailed results site by site table. To enable that, see below:
  -  Need to decide what query method works and if url-encoded works. If possible, url-encoded requests for EJScreen API report on polygon would be most consistent with how proximity-based or fips-based EJScreen API reports are obtained. The URL-generating function should create a link to such a report if that is possible (but might not be able to do it via simple url-encoded query, GET vs POST??). If a link can be created that generates such a report, then the results_bysite table output of ejamit, doaggregate, etc. normally have a URL link to EJScreen report - if possible, that should link to such a report for a polygon when appropriate. If it cannot be url-encoded then tabular outputs probably cannot have a working link to polygon-based ejscreenapi report? Same is true for the excel table -- if a link would work, that link needs to be able to pull up an EJScreen Report for one polygon when a user clicks the button in the detailed results site by site table tab. There could be a workaround, possibly, where a unique link is created that does not contain the polygon but somehow is able to use an ID to refer to and obtain the saved or downloadable polygon and then run a report on that via ejscreen api using POST??
  - Need to decide if and how to return the geometry/bounds, not just the tables of numerical results. And how will subsequent functions use that spatial object. Currently it probably just drops the geometry fields returned and/or does not even ask for geometry to be returned?



",https://api.github.com/repos/USEPA/EJAM/issues/652/comments,12/12/2024,1/4/2025,ejanalysis,ParkerJanMalek,0,0,0,FALSE
11,651,open,fix app_server to be able to map FIPS types other than just county and blockgroup,enhancement|urgency medium|maps-related,4538805068|6227894519|6228710425,cfd3d7|FBCA04|C2E0C6,New feature or request||related to maps,0,,,"in app_server.R where it says, ""Download FIPS Boundaries via API"" around line 1590 or so, the code has used shapes_blockgroups_from_bgfips() or shapes_counties_from_countyfips() and warned it cannot handle other types of FIPS shapes. But now there is the function shapes_from_fips() and it should be used in that section to handle mapping any kind of FIPS that it is able to handle.

Not sure that can/how we should handle city/CDP?? check that since it is the most important missing case (along with States).",https://api.github.com/repos/USEPA/EJAM/issues/651/comments,12/11/2024,12/11/2024,ejanalysis,none,1,0,0,FALSE
12,649,open,"EJAM:::datapack('EJAM') fails to sort by size, unless  simple = F",bug|urgency low,4538805065|6227891676,d73a4a|cfd3d7,Something isn't working|,0,,,"sortbysize = T is default but fails if simple = T which is also a default
`
EJAM:::datapack('EJAM', sortbysize = T, simple = F) 
`
**It should always use sortbysize even if simple = T**
",https://api.github.com/repos/USEPA/EJAM/issues/649/comments,12/10/2024,12/10/2024,ejanalysis,ejanalysis,0,0,0,FALSE
13,640,open,change params of ejam2shapefile() or whatever it is renamed to,enhancement|refactor|urgency medium,4538805068|6208400114|6227894519,cfd3d7|8F13A1|FBCA04,New feature or request|Rewrite how code works or break into smaller pieces|,0,,," Change the params, arguments of ejam2shapefile() to match those of shape2zip()",https://api.github.com/repos/USEPA/EJAM/issues/640/comments,12/6/2024,12/10/2024,ejanalysis,ParkerJanMalek,1,0,0,FALSE
14,639,open,"rename shapefile functions to be short, consistent",refactor|urgency low,6208400114|6227891676,8F13A1|cfd3d7,Rewrite how code works or break into smaller pieces|,0,,,"RENAME THESE SHAPEFILE FUNCTIONS AT SOME POINT

**OPTION 1:** 

ejam2shapefile()   
probably should get renamed to 
ejam2zip()  

 shapefile_ in many functions actually means a data object not a file,
so  
shapefile_from_xyz 
probably should get renamed to 
shape_from_xyz()  

 and then we will have 
shape_from_zip() & 
shape2zip() 
 which would be the names for going to or from the object, from or to the zipfile.

**OPTION 2:** 

using new names like
shape_write() &
shape_read() 
 would be names more similar to
sf::st_write() &
sf::st_read() ",https://api.github.com/repos/USEPA/EJAM/issues/639/comments,12/6/2024,1/2/2025,ejanalysis,ParkerJanMalek,0,0,0,FALSE
15,637,open,make ejam2shapfile() handle results of fips analysis like ejam2map() can,enhancement|maps-related|shapefile-related|urgency high-ish but not a bug,4538805068|6228710425|6343756696|7539794549,cfd3d7|C2E0C6|C2E0C6|B9463A,"New feature or request|related to maps|related to polygons/ shapefile/ GIS data/ buffers|for high urgency enhancements, to rank them just below high urgency bugs",0,,,"
```
ejfips <- name2fips(c('Tucson, AZ', 'Cleveland, OH')) 
# City/CDP, so FIPS not neatly mapped to a set of blockgroups exactly filling it

outejfips <- ejamit(fips = ejfips) 
# works for CITY/CDP fips case by downloading polygons
#  (but didn't need to do download if fips was bg, tract, county or state )

mapfastej(outejfips ) # works now for fips case by re-downloading polygons
ejam2map(outejfips) # works now for fips case by re-downloading polygons

shp <- ejam2shapefile(outejfips, save = FALSE) # does not yet work for fips case
```",https://api.github.com/repos/USEPA/EJAM/issues/637/comments,12/6/2024,1/21/2025,ejanalysis,ParkerJanMalek,0,1,1,FALSE
16,612,open,447 add back in urls to acs report,enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,0,,,FALSE,https://api.github.com/repos/USEPA/EJAM/issues/612/comments,11/25/2024,1/28/2025,saradelessio-abt,mlfurman3,0,0,0,FALSE
17,595,open,Integration of additional EJScreen variables,calculate/validate to EJScreen|datasets/ pins/ AWS/ etc.,6343712128|6343736234,FBCA04|0E8A16,"related to errors in numbers, replicating EJScreen stats|related to data files via pins board, AWS, dataload_ etc.",2,,"@DougMoy please look into how to add these columns into blockgroupstats|Thought I commented on this, but added new data. Waiting on analysis before next step:

https://github.com/USEPA/EJAM/tree/issue595",We have collected 60~ variables through the EJScreen API that were previously missing in their data releases. These should be integrated into EJAM could be used for analysis summary statistics.,https://api.github.com/repos/USEPA/EJAM/issues/595/comments,11/11/2024,1/27/2025,leeeddie424,DougMoy,0,0,0,FALSE
18,593,open,Optimize manual test script runtime,,,,,0,,,,https://api.github.com/repos/USEPA/EJAM/issues/593/comments,11/5/2024,11/22/2024,leeeddie424,none,0,0,0,FALSE
19,591,open,Read and write data from temp-directory,test|urgency low,6148706060|6227891676,6F7271|cfd3d7,test to be developed|,0,,,"Adjust unit tests so that data files are read from and written to a temp-directory. This should reduce scoping issues, and allow test to be more reproducible. Will need to think about best way to pull data from package. ",https://api.github.com/repos/USEPA/EJAM/issues/591/comments,11/5/2024,11/22/2024,leeeddie424,none,0,0,0,FALSE
20,589,open,Declutter setup script,test|urgency medium,6148706060|6227894519,6F7271|FBCA04,test to be developed|,0,,,This ticket refers to the tests/testthat/setup.R script since this file gets run before each group of unit tests. Want to reduce any long-running tasks (move them into individual test blocks). Ideally this script only loads packages. ,https://api.github.com/repos/USEPA/EJAM/issues/589/comments,11/5/2024,11/22/2024,leeeddie424,none,1,0,0,FALSE
21,576,open,format_ejamit_columns() should use approach in table_signif_round_x100() and branch of that name,refactor|urgency medium,6208400114|6227894519,8F13A1|FBCA04,Rewrite how code works or break into smaller pieces|,0,,,"`table_signif_round_x100()` was drafted to wrap the functions table_signif() table_round() and table_x100() into one step, and is in the branch called table_signif_round_x100  -- see https://github.com/USEPA/EJAM/tree/table_signif_round_x100 

`format_ejamit_columns()` uses a different approach to formatting numbers for display and should be merged with the approach in table_signif_round_x100() that is provided in the branch called table_signif_round_x100

If the approach in format_ejamit_columns.R is better, then table_signif_round_x100 should be updated and the improved version could be used everywhere. 

Also, format_ejamit_columns() and related utilities should be made internal not exported, by adding @keywords internal and removing @export, and that will mean redoing document() and rebuilding the pkgdown site.
",https://api.github.com/repos/USEPA/EJAM/issues/576/comments,10/22/2024,10/23/2024,ejanalysis,ejanalysis,1,0,0,FALSE
22,575,open,Unit test clean up,test|urgency high-ish but not a bug,6148706060|7539794549,6F7271|B9463A,"test to be developed|for high urgency enhancements, to rank them just below high urgency bugs",0,,,"Re-organize and re-write existing EJAM unit tests with the goal of being able to run and evaluate tests better.
 
- Want to cut down on runtime for whole testing suite

- Want to be able to source individual unit testing scripts and tests

- Want to be able to use Rstudio devtools::test() functionality

- [ ] #589
- [x] #590
- [ ] #591
- [x] #592
- [ ] #593",https://api.github.com/repos/USEPA/EJAM/issues/575/comments,10/22/2024,1/28/2025,leeeddie424,mlfurman3,0,1,1,FALSE
23,570,open,Rename `naics_validation`,refactor|urgency low,6208400114|6227891676,8F13A1|cfd3d7,Rewrite how code works or break into smaller pieces|,1,,May need to run devtools::document() after all global search and replaces are complete. This will update the help page.,"Rename `naics_validation` and refactor calls to this function
 
Determined the function works as intended where called in the app, but name is misleading. Should rename to something like `naics_is_nonempty` as the function doesn't actually validate the NAICS input (that is what `naics_is.valid` does)",https://api.github.com/repos/USEPA/EJAM/issues/570/comments,10/15/2024,11/22/2024,mlfurman3,none,0,0,0,FALSE
24,562,open,"Simplify UI by dropping ""What type of data are you uploading?"" Let app figure out which type was uploaded.",enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,1,,"Assigning: @saradelessio-abt , @mlfurman3 will review and reach out.","Revamp UI (and server) to remove need for What type of data are you uploading? selection. It is sometimes very confusing when an upload does not seem to work and it is because you forgot to change the selection from latlon to fips, for example. The code should allow you to upload a file of any of those acceptable types and figure out which type it is based on the table headers.

If it is ambiguous, use these rules to prioritize which type to treat it as - The order of priority will be this if more than one type of info is found:
shapefile > latlon > regid > progid > fips

If there is nothing but fips, except there are multiple types of FIPS, like city fips and county fips and state fips, then we probably want to use county but should warn user of the ambiguity.

This priority order makes sense because FIPS of some type may be a column in a latlon or other table, and latlon is more explicit about their preferred location than the id and if they have both then the latlon were probably just taken from the id anyway, and shapefiles if provided are probably what they want to analyze even if it has columns with FIPS or even latlon like centroids for example.

Text like ""Upload a file with lat-long coordinates"" will need to list all the valid types, and ""required files:...."" would need changes too.

The automatic change in default radius if shapefile is picked would have to be triggered after the file upload when server infers what type of data was provided.

We still will need the conditional pulldown called ""How would you like to select categories?"" if they pick ""Select a category...""
We will not in the web app allow uploads of lists of NAICS, SIC, MACT, EPA program type. It would be very unusual for someone to need to analyze more than one or very few codes at once -- too many facilities, too broad. One can continue to manually select multiple ones from the pulldowns if necessary. Or one can use the R functions directly for that.

Note we also want to retain the ability to easily later add features that allow 1) uploads of Street Address files and 2) pulldown selection of Census Designated Places, to be supported by placenames-related and address-related functions that already exist.
 ",https://api.github.com/repos/USEPA/EJAM/issues/562/comments,10/9/2024,11/26/2024,ejanalysis,mlfurman3,1,0,0,FALSE
25,560,open,provide projected ETA for large analysis - relates to #163,enhancement|urgency low|speed / performance (see #444),4538805068|6227891676|6535412240,cfd3d7|cfd3d7|e99695,"New feature or request||related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.",3,,"Extension of issue #299 |@mlfurman3 please reassign|@DougMoy re-assigning ticket to you
cc: @sarasoko ","For example, 10k points at 3 miles radius can take >2 minutes to finish as of 10/2024:

This issue is just about warnings/ projections on timing:

- [ ] **create benchmark times** required to do various kinds of analysis while varying a few key parameters: Finish it first for points and then do it for shapefiles. Key params to vary in testing: 
  - Number of places =
    -  100, 300, 1k,  3k, 10k, 30k for testing points 
    - similar for shapefiles
    - FIPS: all counties in 1 moderate sized state, and then all counties in 1 big epa region
  - Size of each place: 
    - radius for latlon (1, 3.1, 6.2 miles, plus maybe 30 miles for just 100 and 300 sites), 
    - avg square meters per polygon (avg sizes of redlined zones PWS service areas, and NPL site boundaries, and then plus 1 mile buffer), and 
    - typical type/size of FIPS (City/CDPs sample, random Counties, random States).

Analysis of points can be benchmarked like this:
```
speedseen_all <- EJAM:::speedtest(
       n = c(100, 300, 1000,  3000, 10000),
       radii = c(1, 3.106856, 6.2, 10), logging = TRUE) 
```
- [ ] **fit a rough formula for projecting how long an analysis will take**, as a function of those key parameters. This probably should be done on the web app first. but should also run in ejamit() to see if times are about the same.
- [ ] **Warning/estimate webapp:** provide a warning/ estimate of about how long it is going to take in shiny web app before it starts, based on prior benchmarks of rate per hour as a function of the key factors
- [ ] **Warning/estimate RStudio**: provide a warning/ estimate of about how long it is going to take in ejamit() before it starts
- [ ] **ETA webapp**: when it starts in shiny app, give estimated time projected completion (ETA) based on the above and start-time. 
- [ ] **ETA RStudio:** when it starts in ejamit(), give estimated time projected completion (ETA) based on the above and start-time. 
- [ ] **Running ETA** while running doaggregate(): Give regular updates on the ETA for just doaggregate(), the predicted time at which it will finish that function, based on the number remaining and the time and the rate for all done in doaggregate() so far. 
- [ ] If possible, incorporate that into the web app if not already communicated adequately.
- [ ] Running ETA while running getbblocksnearby or the related fips and shape functions?  optional if easy but not so useful since it still has to do doaggregate() after that.


Also see separate lists of issues about how to profile and speed up ejamit() & web app -  see #444 and #385  
```
#  more than 2 minutes to run:
 system.time({
     pts <- latlon_from_naics(naics_from_any(3273, children = TRUE)$code)
     # 11180 points found
     out11k <- ejamit(pts, radius = 3, include_ejindexes = T, quiet = T)  
  })
```
Similar timing in web app, probably.

",https://api.github.com/repos/USEPA/EJAM/issues/560/comments,10/9/2024,2/10/2025,ejanalysis,DougMoy,0,0,0,FALSE
26,545,open,"speed up getblocksnearby_from_fips(), stop using blockid2fips in general",enhancement|urgency medium|speed / performance (see #444),4538805068|6227894519|6535412240,cfd3d7|FBCA04|e99695,"New feature or request||related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.",0,,,"also see branch called cut_reliance_on_huge_...  

This could easily be much faster. It takes almost 5 seconds for all counties in region 6, e.g.
`system.time({x = getblocksnearby_from_fips(fips_counties_from_statefips(fips_states_in_eparegion(6)))})
`

- [ ] The _slowest_ part is probably the ` dplyr::left_join( ` section and **data.table could probably do this MUCH more quickly**.

- [ ] Another slow step is this which takes around 1.5 seconds for all counties in region 6:
`system.time({all_bgs <- stack(sapply(fips_counties_from_statefips(fips_states_in_eparegion(6)), fips_bg_from_anyfips))})`

- finish the work to **drop reliance on `blockid2fips` dataset** and `bgid2fips` to speed things up and shrink the required datasets/package overall. see branch called cut_reliance_on_huge_...   like this as a way to get from any fips to all bgfips to bgid to blockids ...
    - use fips_bgs_in_fips(fips) to get all bg fips values
    - use join to blockgroupstats on bgfips, to get all bgid values... see drafted  state_from_blockid() in that branch  cut_reliance_on_huge_... 
    - use join to blockwts on bgid, to get all the blockid values.
    - delete the code no longer needed, including where it does dataload_  and uses those 2 xyz2fips tables 
    - switch all other pkg code that now uses `blockid2fips` to instead rely on `blockgroupstats` since it is already in memory,
    - completely drop all mentions of `blockid2fips `from the package, after globally finding and editing/recoding each place it had been used or mentioned in examples, help docs, vignettes, etc. ",https://api.github.com/repos/USEPA/EJAM/issues/545/comments,9/18/2024,9/19/2024,ejanalysis,ejanalysis,1,0,0,FALSE
27,544,open,rename fips functions that are not 1 to 1 (that find all subunits),refactor|urgency medium,6208400114|6227894519,8F13A1|FBCA04,Rewrite how code works or break into smaller pieces|,1,,@DougMoy revisit when we restart refactoring code,"Most fips-related functions are 1 output per input, such as `fips2state_abbrev(c('10001', '10001')) ` which returns c(""DE"",""DE""). But some important ones focus instead on finding all the blockgroups or counties inside some larger unit, for example. Examples include these:
```
 fips_states_in_eparegion(2)
 fips_counties_from_state_abbrev('DE') # and related functions fips_counties_from_xyz
 fips_bg_from_anyfips('10001') 
 state_from_fips_bybg('10001') 
  ```
They are important and useful for easily working with a list of all counties in a state, and then making the blocks table for ejam analysis, for example.

These functions are not 1 to 1 (1 input to 1 output), but are 1 to many:
 1 input to all ___ (bg) units inside each input. Finds the ___ (fips) of all ____ (bg) contained in the specified ___ (st or county?) fips

Maybe we just change them to say ""in"" instead of ""from"" if it is a 1 to many relationship. Names could be like these ideas:

States
- fips_states_in_eparegion()     already exists

Counties
- fips_counties_in_statefips      has been called  fips_counties_from_statefips()
- fips_counties_in_ST  ?            has been named  fips_counties_from_state_abbrev
- fips_counties_in_statename    has been called  fips_counties_from_statename() 
- fips_counties_in_eparegion  ?  

Blockgroups
- fips_bgs_in_countyfips
- fips_bgs_in_statefips    (and maybe fips_bgs_in_statename and fips_bgs_in_ST ? )
- fips_bgs_in_eparegion?

These functions are useful but need consistent clear names to avoid confusion. The name would communicate that it 
- returns the fips or abbreviations or names of
- ""all"" of the 
- blocks, blockgroups, tracts, counties, or states 
- that are ""in"", ""within"", ""contained"" in or ""parts"" or ""components"" of (""all_x_in"" not ""from""?)
- the ""parent"" or ""overall"" larger unit like EPA REGION, state, county, tract, bg
- where those inputs are specified in terms of FIPS (but also maybe stfips, ST, statename,  or countyfips, countyname, or tractfips or bgfips).

These are different - they return a table of all the blocks inside:
```
 counties_as_sites('10001')
 states_as_sites('10')
```",https://api.github.com/repos/USEPA/EJAM/issues/544/comments,9/17/2024,12/2/2024,ejanalysis,DougMoy,1,0,0,FALSE
28,543,open,fips validations need to be more consistent (or better documented and justified),bug|urgency low,4538805065|6227891676,d73a4a|cfd3d7,Something isn't working|,3,,"@DougMoy please look into this issue.|@DougMoy reassigning this issue back to you.|Talked with Marschall, seems to be working as intended now. Added tests to the test suite to ensure consistent behavior:

https://github.com/USEPA/EJAM/pull/709
","There is inconsistent and thus potentially unexpected behavior that should be fixed (or at least documented/warned about if it is appropriate but not expected). The examples below are about leading zeroes but this idea may go beyond just missing leading zeroes to other kinds of invalid inputs. Clear examples of inconsistent, potentially confusing behavior:
```
fips2state_abbrev(1:5)  # says SOME are invalid - correctly gives right output for valids, NA for others

fipstype(1:5)          # implies NONE are invalid -  just says all are ""state"" 
fips2state_fips(1:5)   # implies NONE are invalid - just adds leading zeroes

EJAM:::fips_valid(1:5)    # says ALL are invalid - does not try to add leading zeroes
```
Other FIPS-related functions should be checked as well.",https://api.github.com/repos/USEPA/EJAM/issues/543/comments,9/17/2024,1/21/2025,ejanalysis,DougMoy,0,0,0,FALSE
29,529,open,"add $ sign on per cap income in excel, no cents, comma e.g.,   $25,000  ",enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,1,,"@DougMoy re-assigning ticket to you
cc: @sarasoko",,https://api.github.com/repos/USEPA/EJAM/issues/529/comments,9/11/2024,2/10/2025,ejanalysis,DougMoy,0,0,0,FALSE
30,526,open,handle crs (CRS) more robustly for uploads to shiny app,bug|urgency medium|shapefile-related,4538805065|6227894519|6343756696,d73a4a|FBCA04|C2E0C6,Something isn't working||related to polygons/ shapefile/ GIS data/ buffers,0,,,"Check for (possible) problem cases for uploads of various shapefiles to shiny app, focused on CRS and lat/lon vs lon/lat, and detecting crs correctly and whether all functions correctly transform if and when needed via crs parameters, etc. projected vs not, etc.

Same for saving shapefile output from the app (if that is implemented) and then from  ejam2shapefile() 

one possible issue:
> EPSG:4326 formally defines coordinate axes to be in the order latitude-longitude, but practically all data sources and software environments use longitude-latitude axis order. OGC:CRS84 is equivalent to EPSG:4326 except that it defines coordinate axis order longitude-latitude, removing this ambiguity so to speak. See also [st_axis_order()](https://r-spatial.github.io/sf/reference/st_crs.html)
 see
https://r-spatial.github.io/sf/articles/sf6.html#why-should-we-use-ogccrs84-instead-of-epsg4326",https://api.github.com/repos/USEPA/EJAM/issues/526/comments,9/9/2024,9/9/2024,ejanalysis,ParkerJanMalek,1,0,0,FALSE
31,517,open,"in doaggregate() replace, with a function, the code defining Columns Order (which sorts variables for output tables)",enhancement|refactor|urgency medium,4538805068|6208400114|6227894519,cfd3d7|8F13A1|FBCA04,New feature or request|Rewrite how code works or break into smaller pieces|,1,,"Assigning to @DougMoy, @mlfurman3 to reach out to discuss","COLUMNS ORDER section of doaggregate()  (around lines 1470-1620 very roughly) is almost 200 lines of code just defining the sort order of indicators for output tables like results_bysite etc.

There is a draft function called table_order_variables() that should be fixed and used there instead of all that code in doaggregate. Unclear how useful that old function is as-written since it provides an order very different from current and seemed overly complicated.

The function should be redone to rely on `map_headernames` info about sort order, probably relying on just one column in map_headernames for the sort order in results_overall (and other columns could specify sort order elsewhere like in community report, maybe in excel if we wanted the option of that sort being different, and other places where we show outputs).

It probably should rely on a column in map_headernames that would specify the sort order for doaggregate outputs, like ""sort_results_overall"" 

The resulting order should be very close to what had been the order in doaggregate() outputs, with a few fixes to be specified in separate issues. 

Note it is very important that sort order of related groups be identical, so names_e, names_e_pctile, names_e_avg, names_ej, etc. should all use the same order for their analogous indicators!  This will require understanding the extra tabs in map_headernames....xlsx that originally were the way sorting was handled.",https://api.github.com/repos/USEPA/EJAM/issues/517/comments,9/5/2024,12/2/2024,ejanalysis,DougMoy,1,0,0,FALSE
32,516,open,"in map_headernames, add in_how_many_states",enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,2,,"Reassigning to @DougMoy |@agemady this file is in `data-raw/map_headernames_2.32.xlsx` 

Once added, will need to run `data-raw/datacreate_map_headernames.R`","add in_how_many_states as a new row in map_headernames, 
rname = in_how_many_states
varlist = ""names_geo""
long = ""Number of States among the Census blocks included""
decimals = 0
sort order could be fixed later 

This variable is now added by doaggregate() by using the function state_per_site_for_doaggregate() which in turn uses state_from_s2b_bysite() 

",https://api.github.com/repos/USEPA/EJAM/issues/516/comments,9/5/2024,11/22/2024,ejanalysis,none,0,0,0,FALSE
33,500,open,Fix/clarify what State's percentiles to use if a polygon spans 2 states,bug|urgency low|calculate/validate to EJScreen,4538805065|6227891676|6343712128,d73a4a|cfd3d7|FBCA04,"Something isn't working||related to errors in numbers, replicating EJScreen stats",1,,@ejanalysis have you heard anything from EJscreen team ,"Fix/clarify what State's percentiles to use if a polygon includes blocks from 2+ states. Not sure what it does in EJAM right now when this situation arises. Need reprex

Check/fix assignment of ST (state) for doaggregate() / ejamit() / shiny app for the case where a shapefile spans 2 states!!

First try to figure out what does EJScreen do? Which State's percentiles are used if a polygon spills into a second state?

 If they do it wrong or they fail to report state percentiles for those (or while/if we cannot figure out what they do?) then choose a method: 
- Simplest way would be to use the 1 state per polygon that accounts for most of the residents in that polygon? 
- Complicated but more appropriate calculation would be to handle each portion that is in its own state and average them together within a polygon to get the overall weighted average of percentiles from the 2 or more states in the poly, just like we already do to create the ""results_overall"" state percentiles and ratios to avg now in doaggregate.
",https://api.github.com/repos/USEPA/EJAM/issues/500/comments,8/29/2024,1/7/2025,ejanalysis,mlfurman3,0,0,0,FALSE
34,499,open,Ratios - reconcile/ consolidate calculations of ratios,refactor|urgency low,6208400114|6227891676,8F13A1|cfd3d7,Rewrite how code works or break into smaller pieces|,2,,"This consolidation does NOT have to happen right away and we should discuss how/whether to do it. 

Having the calculations be done via a function is a good idea, so we can reuse that outside doaggregate() and it can be unit tested, etc.  The code in `doaggregate()` still does ratios within doaggregate() right now, where it says 
`if (calculate_ratios) { `
HOWEVER, it is not a lot of code and not super complicated. 
ALSO, calc_ratios_to_avg() returns a list of vectors with specific names  which can be confusing, and is not very generic. It was just meant as a helper to plot the ratios in the ejscreenapi functions. 


see PR #532 which tried to fix `calc_ratios_to_avg()` at least so it would work in `ejscreenit()` or `ejscreenit_for_ejam()` 
  |@ParkerJanMalek putting back on your radar to discuss with Mark.","
reconcile/ consolidate ratios calculations in doaggregate() and  calc_ratios_to_avg() and maybe ejscreenit_for_ejam() and some in ejscreenit()
and include states too and include demog subgroups too
where relevant.
Note calc_ratios_to_avg() was drafted for ejscreenapi
Note the averages and ratios (at sites overall and by site)
```
  zzz = ejscreenit_for_ejam(testpoints_10[1,], calculate_ratios = F)
 grep(""average|avg"", names(zzz), ignore.case = T, value = T)
```

Note the averages by usa are in
```
 usastats[usastats$PCTILE == ""mean"", names_d_subgroups]`
```
and also  avg.in.us (but no state version of that)
  
Note the averages by state are in
``` 
  statestats[statestats$PCTILE == ""mean"" & statestats$REGION %in% c(""DE"", ""RI""), names_d_subgroups]
```
",https://api.github.com/repos/USEPA/EJAM/issues/499/comments,8/29/2024,11/22/2024,ejanalysis,none,0,0,0,FALSE
35,496,open,Implement custom formulas for aggregation of user-provided indicators,enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,2,,"Not in the current plan for EJAM|@ejanalysis further discussion needs to be involved on this as implementation would lead to potential messiness downstream. (e.g., issues with reporting template). Are you envisioning instead this being a function for power users?","calc_ejam() -- At least new, custom, user-defined calculations could be done in this separate function, to be used by doaggregate() or just a custom_ version of it, so the code to do the calculation (aggregation) could be based on the drafted function [calc_ejam()](https://usepa.github.io/EJAM/reference/calc_ejam.html) which importantly relies on a separate table of formulas like those in [formulas_d] or formulas_all. This is better in the sense that it is flexible/ generic, useful for updating and calculating user-defined indicators, etc. However, it was primarily designed to handle one formula specific to one variable, so you need to write out repetitive formulas, one per indicator -- it is not designed to run a bunch of weighted means for a whole set of indicators. Although there is a datacreate_formulas_ script that automates that for simple cases and it might work for new indicators to use simple sums or wtd means when appropriate and only custom formulas to aggregate in special cases? ",https://api.github.com/repos/USEPA/EJAM/issues/496/comments,8/28/2024,10/22/2024,ejanalysis,none,0,0,0,FALSE
36,491,open,Refactor use of  names_d  etc. to get rid of the 85 data objects,refactor|urgency low,6208400114|6227891676,8F13A1|cfd3d7,Rewrite how code works or break into smaller pieces|,2,,"Please set up a mtg with me to discuss how to proceed, if / when someone starts to work on this. The notes above may not reflect the latest thinking, and it is complicated and would be a substantial change to the code throughout.|@DougMoy reassigning to you. 
CC: @sarasoko "," Consider alternative approach to things like names_e, names_d, etc.  
  To avoid having 85 objects like names_d, names_e, etc. that get lazyloaded as 85 separate datasets
  and avoid 85 data_names_xyz.R files to document them all!

This supersedes issues #20 and #41 

 Instead of always using code like
```
  c(names_d, names_health)
```
 we could simply refactor to use new function(s) like v(), vc(), vq(), vqc()
   where ""v"" means variables, ""c"" is like the c() function, and ""q"" means quoted.
```
     c( names_d,  names_health)     # The old way; how we have been getting vectors of names of variables

 v(  c( names_d,  names_health)  )  # A new way, but using nonstandard evaluation (no quotes) has pros / cons.

 vc(    names_d,  names_health   )  # less useful approach probably.

 vq( c(""names_d"",""names_health"") )  # Useful way and avoids nonstandard evaluation, but just would need more edits to convert to this approach. short alias for  names_from_varlist(c(""names_d"", ""names_health""))  # and if names_d etc are still data objects it would be same as # as.vector(unlist(sapply(c(""names_d"",""names_e""), get)))

 vqc(  ""names_d"",""names_health""  )  # less useful approach probably.

 v(c(names_d, names_health))
 vc(names_d, names_health)
 vqc(""names_d"", ""names_health"")
 vq(c(""names_d"", ""names_health""))
```
see http://adv-r.had.co.nz/Computing-on-the-language.html#substitute 
```
v <- function(x) {
  
  ##  to replace 
  #   c(names_d, names_health)   
  ## by doing this:
  #   v( c(names_d, names_health) ) 
  ## and to replace
  #   myvarlists = c(names_d, names_health)
  ## by doing this:
  #   myvarlists = v( c(names_d, names_health) )
  
  y = as.character(substitute(x))
  y = y[y != ""c""]
  return(vq(y))  
}
################################################### #

vc <- function(...) {
  
  # vc(names_d, names_health)
  
  # takes any number of arguments (like sum() works),
  #   each a character string like ""names_d"" 
  #   finds them in map_headernames$varlist
  #   returns a vector of the rname that are of that type i.e., in that list
  #   according to map_headernames
  #   by using names_from_varlist()
  
  dots <- function(...) {
    eval(substitute(alist(...)))
  }
  arglist2charvector <- function(...) {
    gsub('""|\'','', sapply(dots(...), FUN = function(x) {deparse(x)}))
  }
  x = arglist2charvector(...)
  names_from_varlist(x)
}
################################################### #

vq <- names_from_varlist # alias
#   vq(c(""names_d"", ""names_health""))
################################################### #

vqc <- function(...) {
  
  # vqc(""names_d"", ""names_health"")
  
  # takes any number of arguments (like sum() works),
  #   each a character string like ""names_d"" 
  #   finds them in map_headernames$varlist
  #   returns a vector of the rname that are of that type i.e., in that list
  #   according to map_headernames
  #   by using names_from_varlist()
  
  dots <- function(...) {
    eval(substitute(alist(...)))
  }
  arglist2charvector <- function(...) {
    gsub('""|\'','', sapply(dots(...), FUN = function(x) {deparse(x)}))
  }
  x = arglist2charvector(...)
  names_from_varlist(x)
}
################################################### #
```
Try them out:
 ```
 v(c(names_d, names_health))
 vc(names_d, names_health)
 vqc(""names_d"", ""names_health"")
 vq(c(""names_d"", ""names_health""))
```

Note another option that had been considered but probably should drop now:
 `   c(namez$d, namez$health)  `
but that continues to duplicate info from map_headernames, and other metadata is there.
 ",https://api.github.com/repos/USEPA/EJAM/issues/491/comments,8/25/2024,2/10/2025,ejanalysis,DougMoy,0,0,0,FALSE
37,470,open,Rename & consolidate functions like fixcolnames... vs fixnames... ,refactor|urgency low,6208400114|6227891676,8F13A1|cfd3d7,Rewrite how code works or break into smaller pieces|,2,,Reassigning to @DougMoy  CC: @sarasoko |@DougMoy revisit when we restart refactoring code,"**Rename & consolidate functions like fixcolnames... and fixnames...** 

functions included these: 

-fixcolnames()
-fixcolnames2related()
-fixcolnames_aliases()
-fixcolnames_infer()

-fixnames()
-fixnames_to_type()
-fixnames_aliases()


- [ ] Use just fixnames or fixcolnames as the basic name (probably ""fixnames"")
- [ ] Use just ""2"" or ""_to_"" (probably ""2"")
- [ ] Consolidate the ..._aliases() functions.
- [ ] Consolidate the fixnames() and fixcolnames()
- [ ] Maybe consolidate all of them or most of them using parameters. 



",https://api.github.com/repos/USEPA/EJAM/issues/470/comments,8/5/2024,12/2/2024,ejanalysis,DougMoy,0,0,0,FALSE
38,465,open,"for excel formatting, see ""remove this when ready to switch"" in app_server and resolve",refactor|urgency low|server,6208400114|6227891676|7384237694,8F13A1|cfd3d7|25B9F0,Rewrite how code works or break into smaller pieces||removing code from app_server.R,1,,@DougMoy please look into reassigning.,"for excel formatting, had almost finished switching approach to using a function instead of similar script within app_server",https://api.github.com/repos/USEPA/EJAM/issues/465/comments,7/27/2024,11/22/2024,ejanalysis,none,0,0,0,FALSE
39,454,open,Security - prevent DoS attacks by ensuring everywhere a user can upload or specify anything we use a cap to ensure it does not take too long to execute,urgency medium|security,6227894519|7222916258,FBCA04|D937F7,|,4,,"@mlfurman3, part of this is successfully governed through default_max_mb_upload - file cannot be two large. There are two more aspects - long running/many simultaneous requests can exhaust the CPU - the option here is to spawn multiple processes (configured by hosting company) or run multiple instances with a sticky load balancer (again hoster needs to configure this). There is a second attack vector - multiple concurrent connections with a slow data transfer, essentially keeping the socket open/busy. That also falls to the hosting party to mediate; shiny does not seem to have a setting for this.|@mlfurman3 will send an email|@mlfurman3 will investigate use of ShinyValidate package|See issue #444 ","Denial of service (DoS) attacks are the issue to check for vulnerability to.

Especially in the API code it is important but also once the shiny app is public facing. 

For example, make sure we prevent large uploads, uploads that are complex enough that it would make ejamit() or other functions slow down too much, etc., etc. We already have done this in most places but someone should check to ensure it is comprehensively done. 

",https://api.github.com/repos/USEPA/EJAM/issues/454/comments,7/18/2024,1/21/2025,ejanalysis,mlfurman3,1,0,0,FALSE
40,447,open,Add back in URLs to ACS report,enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,3,,Reassigning to @saradelessio-abt cc: @ParkerJanMalek |@mlfurman3 Which URLs is this referring to|Related to #136,,https://api.github.com/repos/USEPA/EJAM/issues/447/comments,7/10/2024,11/26/2024,leeeddie424,mlfurman3,0,0,0,FALSE
41,444,open,NOTES on SPEEDING UP app & functions (incl load testing!),enhancement|speed / performance (see #444)|urgency high-ish but not a bug,4538805068|6535412240|7539794549,cfd3d7|e99695|B9463A,"New feature or request|related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.|for high urgency enhancements, to rank them just below high urgency bugs",1,,My biggest concern would be if there are problems with the public deployed app when multiple users try to use it concurrently.,"Use cases   
- **INITIAL LAUNCH OF APP/ LOAD TIME!!**
- **30k points at 3.1 mile (5 km) radius**
- 1K points at 31 miles (50 km) radius
- 10K large polygons?
- an extreme case of all 1 million+ active FRS sites at 6.2 miles radius (10 km)

## Also see this repo's list of [ISSUES RELATED TO SPEED/PERFORMANCE](https://github.com/USEPA/EJAM/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22speed%20%2F%20performance%20(see%20%23444)%22) 

## GENERAL STEPS IN TRYING TO SPEED UP A SHINY APP OR R CODE IN GENERAL

**1. Identify/prioritize slow actions _from user point of view_.**

Try using the app (basic steps seem sluggish like maps, short report, knitting, etc.). 
From user's perspective, Why speed is critical: If a site takes longer than 3 seconds to load, 53% of mobile users will abandon the site. If a site takes more than 5 seconds to load, the abandonment rate jumps to 90%. A one-second delay in page load time can lead to a 7% decrease in conversions, a 16% decrease in customer satisfaction, and an 11% decrease in page views. 84% of customers will abandon a website or app if they experience slow load times or other performance issues, sources: https://drive.google.com/file/d/1qngIJToQxE_LExuqgjXXtoV25z2Ri1uQ/view  

**2. Identify/ prioritize slow, key lines of code.**

 Do profiling of bottlenecks, before optimizing code - find out what key functions or steps are slow. 
 Mostly see `getblocksnearby()` and especially `doaggregate()` in particular. 
 e.g., in doaggregate(), the 1 line of code that does this:  `sites2blocks_overall <- ` is very slow.  
 e.g., in doaggregate(), optimizing percentiles function that looks up what percentile each raw indicator score   (IT IS SLOW)
 - See http://adv-r.had.co.nz/Profiling.html#improve-perf  (but make sure viewing the latest edition of book!)
 - Use **`EJAM:::speedtest()`,** a wrapper that automates checking multiple radii and counts of points. But note it still relies on system.time({}) which gives a different answer each time and gives only total time overall. Can use it like this: 
```
   speedseen_all <- EJAM:::speedtest(
       n = c(100, 500,  1000, 5000),
       radii = c(1, 3.106856, 5, 10), logging = TRUE)
```
 - ***Use `profvis::profvis()`,*** which provides details on which steps are slow unlike `speedtest()`, but does not automate checking sensitivity to multiple distances and counts of points.
 - ***Use `microbenchmark::microbenchmark()` later***, only to check/ compare timing of tiny chunks of code within a function

**3. Optimize code and app only after profiling - see ideas below.**

**4. Do load testing and optimize server settings and code for load.**

- [Scaling and Performance Tuning in Posit Connect](https://support.posit.co/hc/en-us/articles/231874748-Scaling-and-Performance-Tuning-in-Posit-Connect)
- see [shinytest2 package](https://rstudio.github.io/shinytest2/)  and/or  [shiny::testServer()](https://shiny.posit.co/r/reference/shiny/1.6.0/testserver) They are [compared in this article](https://www.r-bloggers.com/2024/08/how-to-write-tests-with-shinytestserver-similar-to-shinytest2/).   and see EJAM branches called dev_shinytest2 or https://github.com/USEPA/EJAM/tree/dev_ejscreen2.3_shinytest2
- see [Hadley's performance testing discussion](https://mastering-shiny.org/performance.html) covering [shinyloadtest package](https://rstudio.github.io/shinyloadtest/) etc.
- see [ShinyProxy vs Posit Connect: Benchmark Test for Scaling Shiny Apps from appsilon.com](https://appsilon.com/shinyproxy-vs-posit-connect/) and optimize further based on that. async methods probably needed when concurrent users. Do load testing and modify code to ensure app is highly responsive under anticipated load. 
- see [Server function testing article](https://shiny.posit.co/r/articles/improve/server-function-testing/) 

## TIPS/ TECHNIQUES FOR SPEEDING UP A SHINY APP OR R CODE IN GENERAL
 
Consider strategies such as these (roughly in order of priority or feasibility): 
Again, it is critical to do profiling and load testing to confirm what are bottlenecks, first, before trying to optimize anything!  
 
**SHINY-SPECIFIC: tips, articles and resources on speeding up a shiny app:** 

- https://www.appsilon.com/post/blazing-fast-shiny-apps  **looks very useful as an overview of key points on speed of app**
- see _Mastering Shiny_ [book's chapter on performance](https://mastering-shiny.org/performance.html)
- https://appsilon.com/speeding-up-r-shiny/
- https://appsilon.com/scaling-and-infrastructure-why-is-my-shiny-app-slow/
- https://www.r-bloggers.com/2023/04/lessons-learned-with-shiny-benchmark-improving-the-performance-of-a-shiny-dashboard/
- use new **shiny::[ExtendedTask()](https://shiny.posit.co/r/articles/improve/nonblocking/index.html)** or callR for async work in separate process (see #99 )
- adjust settings on server (number of processes, etc. #231 )
- **Use the new feature, [ExtendedTask()](https://rdrr.io/github/rstudio/shiny/man/ExtendedTask.html)**
- **Use the new feature, [useBusyIndicators()](https://rdrr.io/github/rstudio/shiny/man/useBusyIndicators.html)** to offer spinner/ progress bar where relevant, at least until speed improves.
- **Use  [callr](https://callr.r-lib.org/)**
- Have fast basic elements of webpage/ tab load asap, then slower ones afterwards.
- Remove nonessential features/stats if they are bottlenecks per profiling. 
- Use **reactive** programming optimally - have the minimum of things refresh, like other tabs, using isolate() and bindcache functions, etc., use debouncing of sliders, etc.
- profiling/ testing:
  - do **load testing using shinytest2** etc. to check performance when we get multiple users (and see #231)
  - do profiling if needed to find bottlenecks in shiny app (especially initial loading/ issue #231). profvis etc.
  - do profiling to find bottlenecks in functions (first or only where app or key functions seem a bit slow). microbenchmark etc.
- caching
  - **caching plots** via shiny::renderCachedPlot() since plots are often a slow step.
  - **caching results in shiny** with shiny::bindCache() or caching function results via memoise package... see [useful discussion about bindCache](https://shiny.posit.co/r/reference/shiny/latest/bindcache) including section about session-specific caches vs  a cache that is shared across multiple R processes!
- make each user's browser do more of the work: ([explained here](https://www.youtube.com/watch?v=vhhBG8GzMmE))
  - e.g., DuckDB WASM (DuckDB is like SQLite but more for analytics work, and wasm is like assembly code in browser where you compile R to wasm and it runs in browser not on server; DuckDB + WebAssembly = extremely fast queries of a database despite many users.
  - e.g., Use javascript/browser to do more work so R/server can do less work. e.g., observable plot API is like ggplot2 (similar in spirit, style) but for JS. It is flexible and expressive like ggplot2. has tool tips now too. 
- maybe consider future and promises packages for asynch processing (see #99 )
 
**NON-SHINY / GENERAL**

- General tips on datasets, algorithms, etc.
  - Consider how datasets are designed and used in the code, to avoid some joins or use memory more efficiently or avoid loading nonessential columns, etc.
  - Fix where doing the same thing twice - some code seemed duplicative in doaggregate(). 
  - Get rid of for loops - Use vectorized functions (and not the apply family of functions). getblocksnearby() still has non-vectorized portions, and so does doaggregate() ! (But confirm this actually speeds it up)
  - Find algorithm improvements/ change in approach (as opposed to how the code implements that algorithm)
  - See tips on unit testing: https://www.r-bloggers.com/2023/04/unit-testing-analytics-code/
- **Cache and/or Precalculate**
  - **Preload** all large datasets early while user is not waiting (maybe using `callr` [callr](https://callr.r-lib.org/) to do it in a separate process). Decide if it is better to load large datasets at package attach time, via .onAttach() instead of when user does a query that triggers slow lazyloading? Wait will be either when pkg loads or when query is first done, right? These are the big ones: quaddata (168 MB), blockgroupstats  (54 MB), blockpoints (86 MB) and blockwts (31 MB), blockid2fips (20 MB) files
  - Cache prior requests in earlier sessions (e.g., default radius analysis of sample data like testpoints_10)
  - Cache prior requests in current session. memo-izing?  shiny::bindCache()  etc.
  - **Precalculate constants** or intermediate values if that saves time.
  - Consider **precalculating results** / being able to quickly offer final results for anticipated common queries! maybe 1 standard distance for most likely FRS sites?
  - Consider **precalculating sites2blocks tables** at some large distance for many FRS sites, and have `getblocksnearby()` be able to use that info when appropriate, filtering by the new specified distance, instead of doing the full recalculation of sites2blocks for a new specified distance.
  - Consider **precalculating slow step(s) within doaggregate().** It creates a new index vec and does some math that might be things that could be stored as data on FRS sites, eg.?
- **Use `data.table` package optimally**
  - Avoid code that makes copies of data.tables (e.g., x <- df[asdf]) and instead use setorder, setcolumns, setnames, and `:=`() to change everything by reference (same topic is discussed in collapse package now too)
  - Use data.table properly to do faster select/filter/join via the best approach (using keys properly, etc). 
-   **Use `collapse` package optimally** (along with data.table:: and maybe other fastverse pkgs, but not dplyr/tibble/data.frame), espec. for these operations:
    - See benchmarks comparing collapse, data.table, other packages: https://arxiv.org/pdf/2403.05038 
    - See article about collapse package: https://duckdblabs.github.io/db-benchmark/
    - Use the optimized versions of functions like fmean, fmin, fmax, funique (and maybe even could use fdist?)
    - Grouping/by=   see if faster to do grouping via collapse:: versus via data.table:: 
    - `cbind(data, someFUN(data[,cols])`   replace it with   `add_vars(data) <- someFUN(get_vars(data, cols))`
    - `cbind(data1, data2, data3, ...)` is slow, 
    - collapse::add_vars(data1, data2, data3, ...) much faster and preserves attributes of data1. 
    - collapse::add_vars(data) <- someFUN(get_vars(data, cols, pos= ))  efficiently appends data with *computed* columns.
    - `data[cols] <- someFUN(data[cols])`  replace with 10x more efficient `collapse::get_vars(data, cols) <- someFUN(get_vars(data, cols)) `
    - `x <- DT[ ]`       replace it with  something from collapse:: ?
    - `get_vars(<-)` is around 2x faster than `[.data.frame` and 8x faster than `[<-.data.frame` 
    - From collapse documentation:    https://sebkrantz.github.io/collapse/reference/select_replace_vars.html   
    - `data[sapply(data, is.numeric)] `or `data[sapply(data, is.numeric)] <- value` ... replace with `num_vars(data)` and `num_vars(data) <- value `
    - dplyr::select() is slow and `collapse::fselect` is about 100x faster 
    - weighted.mean() etc., replace with `collapse::fmean(x, w= )` and see fmin, fmax, funique, etc. - mostly done. 
    -    See https://sebkrantz.github.io/Rblog/2021/08/13/fastverse/

- **Parallel** processing. But consider if it requires each process has a full copy of the large block datasets.

- **Asynchronous** coding
  - Async coding is pretty hard to do well but probably essential for a couple of steps. async methods probably needed when concurrent users. There are multiple ways to add async programming to your Shiny app:
    1. callr to  Call R from R.  callR can speed it up for a single user at least. Simplest is to use **`callr `pkg**, e.g. to knit rmarkdown in background, to create localtree and do data(blockpoints), or maybe run getblocksnearby() and doaggregate() in background, etc. 
    2.  futures and promises, hard to use! but helps prevent other users from being slowed down by one users computations.  Unified Parallel and Distributed Processing in R and a promise library for R ?
    3. coro - Coroutines for R.
  - see very good overview of options here: ""Say goodbye to unnecessary waiting: mastering asynchronous programming in Shiny: Veerle van Leemput"" at https://drive.google.com/file/d/1qngIJToQxE_LExuqgjXXtoV25z2Ri1uQ/view for slides or Appsilon youtube channel.
  - see https://drive.google.com/file/d/1qngIJToQxE_LExuqgjXXtoV25z2Ri1uQ/view ?",https://api.github.com/repos/USEPA/EJAM/issues/444/comments,7/9/2024,1/21/2025,ejanalysis,none,0,1,1,FALSE
42,412,open,Code solutions for huge analyses relates to #163,enhancement|urgency low|speed / performance (see #444),4538805068|6227891676|6535412240,cfd3d7|cfd3d7|e99695,"New feature or request||related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.",0,,,"**Code solutions for huge analyses** to handle those cases where radius is > current RMAX and/or points count is > current NMAX -- this is an enhancement and is less urgent, but very useful to be able to run an analysis of radius of 6 miles or even 31 miles (50km), and also useful to be able to run 30,000 or 100k or 1.5 million facilities at once rather than needing to manually create batches.

https://github.com/USEPA/EJAM/issues/163",https://api.github.com/repos/USEPA/EJAM/issues/412/comments,6/17/2024,6/17/2024,leeeddie424,none,0,0,0,FALSE
43,410,open,Warn Users huge run would be slow - relates to #163,enhancement|speed / performance (see #444)|urgency high-ish but not a bug,4538805068|6535412240|7539794549,cfd3d7|e99695|B9463A,"New feature or request|related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.|for high urgency enhancements, to rank them just below high urgency bugs",2,,Assigning ticket to @saradelessio-abt |is doing this just waiting for #408 to be done?,"**warn users** about the RSLOW and NSLOW where it slows down enough to be concerning but has not yet hit the caps RMAX and NMAX where it is so bad we don't allow them to do it at all.

https://github.com/USEPA/EJAM/issues/163",https://api.github.com/repos/USEPA/EJAM/issues/410/comments,6/17/2024,1/10/2025,leeeddie424,saradelessio-abt,0,1,1,FALSE
44,408,open,Test bounds re:  huge/slow runs - relates to #163,bug|urgency medium|speed / performance (see #444),4538805065|6227894519|6535412240,d73a4a|FBCA04|e99695,"Something isn't working||related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.",3,,"@mlfurman3 please reassign|Still investigating limits and arrow capabilities.|@DougMoy re-assigning ticket to you
cc: @sarasoko","**test bounds** to learn at what points the various components start to fail (THIS STEP IS SOMEWHAT URGENT & is essentially a bug - need to know what the boundaries are for what should be allowed or warned about, until we have time to handle pushing those bounds). The problems probably start to occur when you have a combination of large R and large N, and probably scales linearly with N but as the square of R since the number of block points grows with area which is proportional to R squared.

https://github.com/USEPA/EJAM/issues/163",https://api.github.com/repos/USEPA/EJAM/issues/408/comments,6/17/2024,2/10/2025,leeeddie424,DougMoy,1,0,0,FALSE
45,396,open,"Consider NSPS, GACT, other codes as extra ways to pick facilities( not just MACT codes). ",enhancement|urgency low|datasets/ pins/ AWS/ etc.|SectorsReport,4538805068|6227891676|6343736234|6954012580,cfd3d7|cfd3d7|0E8A16|C5A39F,"New feature or request||related to data files via pins board, AWS, dataload_ etc.|Report comparing categories of facilities (by NAICS etc)",0,,,"NSPS, GACT, etc. could be used to expand or parallel ""mact"" subpart selection approach. There are over 100k facilities in the ICIS air program subparts database and we could add those other codes as additional ways one can specify groups of facilities. We already pull MACT subpart codes from there. We could use GACT and NSPS and other info. 
- Discuss whether it is useful and worth the effort. Would need to consider an efficient way to add the functionality. e.g., more selection lists just like MACT codes but for NSPS codes and area source codes etc. is easy to code but cluttered and can't combine across groups. A unified list would require redoing how MACT etc. are selected - would need to specify the code and the code group, like code=""WWW"", group = ""NSPS"" ? or is each code unique to a group? The app UI and functions are designed just for MACT or just NAICS or just SIC etc., so this might require not-insignificant refactoring to implement.
- Discuss if users may want entire sets like all GACT or ""all NSPS,"" not just one or more codes within that (e.g., ""NSPS WWW"").

WHAT HAS BEEN IN MACT TABLE IN EJAM:
```
mact_table[order(mact_table$N,decreasing = T), c(""subpart"", ""title"", ""N"")]

 subpart                                                                        title     N
     ZZZZ                  STATIONARY RECIPROCATING INTERNAL COMBUSTION ENGINES (RICE) 25996
        M                                               DRY CLEANERS PERCHLOROETHYLENE  8763
        A                                                           GENERAL PROVISIONS  5052
       HH                                    OIL AND NATURAL GAS PRODUCTION FACILITIES  3656
   HHHHHH                PAINT STRIP & MISC SURFACE COATING OPERATIONS AT AREA SOURCES  3169
    DDDDD  MAJOR SOURCES: INDUSTRIAL/COMMERCIAL/INSTITUTIONAL BOILERS & PROCESS HEATER  2737
   CCCCCC                                               GASOLINE DISPENSING FACILITIES  1700
        T                                                 HALOGENATED SOLVENT CLEANING  1255
        N                                                      CHROMIUM ELECTROPLATING  1185
  (etc etc)

sum(mact_table$N)
                  68,185
```

What could be added from ICIS database -- OTHER TYPES OF FACILITIES BEYOND JUST THE ""MACT"" subparts:
```
x = read_csv_or_xl(""~/../Downloads/ICIS-AIR_PROGRAM_SUBPARTS.csv"")

cbind(table(x$PROGRAM_DESC))

# [MACT Standards] (40 CFR Part 63)                                                               68,375  # The only type in EJAM so far

# [GACT Standards] (40 CFR Part 63) Area Sources                                                  19,350  # AREA SOURCES (GACT)

# New Source Performance Standards                                                                85,801  # NSPS MAJOR - huge list
# New Source Performance Standards (Non-Major)                                                     3,357  # NSPS MINOR 

# National Emission Standards for Hazardous Air Pollutants (40 CFR Part 61)                        5,202 # part 62
# Part 62 - State and Federal Plans for Control of Designated Pollutants from Existing Facilities     22 
# State Implementation Plan for National Primary and Secondary Ambient Air Quality Standards           3
# The Mandatory Greenhouse Gas Reporting Rule                                                        152
```
",https://api.github.com/repos/USEPA/EJAM/issues/396/comments,5/28/2024,5/28/2024,ejanalysis,none,0,0,0,FALSE
46,391,open,do faster uploads of very large user spreadsheets via SheetReader-r,enhancement|urgency low|speed / performance (see #444),4538805068|6227891676|6535412240,cfd3d7|cfd3d7|e99695,"New feature or request||related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.",0,,,"fhenz/SheetReader-r is an R-Package for parsing Excel files very quickly - bare bones reading but fast.

https://github.com/fhenz/SheetReader-r

Benchmarks on files of roughly 200,000 rows by 100 columns indicate SheetReader to be about 
3x faster with 20x less memory usage than readxl, and 
15x faster with 10x less memory than openxlsx. 

",https://api.github.com/repos/USEPA/EJAM/issues/391/comments,5/23/2024,5/23/2024,ejanalysis,none,0,0,0,FALSE
47,390,open,"consider adding ""geopackage"" format as an option for inputs and outputs of shapefiles",enhancement|urgency low|shapefile-related,4538805068|6227891676|6343756696,cfd3d7|cfd3d7|C2E0C6,New feature or request||related to polygons/ shapefile/ GIS data/ buffers,0,,,"e.g. see 
https://mapscaping.com/shapefiles-vs-geopackage about pros and cons of formats

https://mapping-in-r-workshop.ryanpeek.org/02_import_export_gpkg  using the sf package  import/export of gpkg format

https://cran.r-project.org/web/packages/gpkg/vignettes/intro.html  using another package to do this
",https://api.github.com/repos/USEPA/EJAM/issues/390/comments,5/21/2024,5/21/2024,ejanalysis,none,0,0,0,FALSE
48,386,open,consider new features like Env Health Data Viz tool has,enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,0,,,"Env Health Data Viz tool won awards and has high visibility. It offers some nice features to consider adopting for EJAM:

- user can export just selected data like a list of selected counties
- user can pick 1 state from pulldown to zoom to and view filtered to that state
- offers many layers of data (>70 indicators). API pulls in lots of county data layers on the fly, and maybe for block groups too.
- side by side maps -people seem to like them
- app is very responsive - it updates maps and lists and plots very quickly
",https://api.github.com/repos/USEPA/EJAM/issues/386/comments,5/16/2024,5/16/2024,ejanalysis,none,0,0,0,FALSE
49,384,open,revisit slider increment size ,enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,0,,,"if we want to allow high radius precision (stepradius = 0.05), should probably use a Shiny throttle/debounce so that maps don't get redrawn so often.
or see issue #211 about offering option to type in radius in which case slider increments could be made bigger like 1 mile",https://api.github.com/repos/USEPA/EJAM/issues/384/comments,5/16/2024,5/16/2024,ejanalysis,none,0,0,0,FALSE
50,383,open,switch to Quarto for the long report (static word doc template TSD on outputs of an analysis),enhancement|urgency medium|LongReport_output,4538805068|6227894519|6954028026,cfd3d7|FBCA04|304702,New feature or request||static word doc TSD on results of ejam run - via Quarto template,0,,,,https://api.github.com/repos/USEPA/EJAM/issues/383/comments,5/15/2024,5/15/2024,ejanalysis,none,1,0,0,FALSE
51,381,open,"ejam2barplot() should let you specify one site (or more than 1?) to plot stats from, not just use results_overall",enhancement|urgency low|plots-graphs-related,4538805068|6227891676|6235793514,cfd3d7|cfd3d7|C2E0C6,"New feature or request||related to plotting/graphing like histo, bar, box, scatter",0,,,"`ejam2barplot()` and `plot_barplot_ratios_ez()` need a sitenumber parameter that would tell function instead of using
` out$results_overall`
that it should use
`out$results_bysite[ejam_uniq_id == sitenumber[1], ]`
where sitenumber has to be only 1 number.

... or maybe even allow for multiple sites that would need to get aggregated _somehow_
`out$results_bysite[ejam_uniq_id %in% sitenumber, ]`

",https://api.github.com/repos/USEPA/EJAM/issues/381/comments,5/14/2024,5/14/2024,ejanalysis,ejanalysis,0,0,0,FALSE
52,365,open,let shiny app user download a file identical to output of ejamit()... or a way to convert xlsx to that,enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,0,,,"Provide a way a shiny app user can download a file (maybe .rda format?) that is identical the output of ejamit(), that they can then use in RStudio in the various functions designed to work with ejamit() output. 

Alternatively, provide a function that can convert the excel spreadsheet into that format, a list of tables etc. exactly like the output of ejamit() would have been. This would be like the inverse of ejam2excel(), essentially. 
",https://api.github.com/repos/USEPA/EJAM/issues/365/comments,5/8/2024,9/4/2024,ejanalysis,none,0,0,0,FALSE
53,360,open,"Excel overall tab Unused columns should have ""NA"" and hide",enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,0,,," Those placeholder empty columns can be made very narrow or even hidden on the overall tab -- hidden but retained, so formats of tab are identical. (ejam_uniq_id, urls, etc.) ",https://api.github.com/repos/USEPA/EJAM/issues/360/comments,5/8/2024,5/8/2024,ejanalysis,none,0,0,0,FALSE
54,359,open,plot tab in excel with demographic ratios should have both ratio to us and ratio to state plots.,enhancement|urgency medium|plots-graphs-related,4538805068|6227894519|6235793514,cfd3d7|FBCA04|C2E0C6,"New feature or request||related to plotting/graphing like histo, bar, box, scatter",0,,,"similar to issue #358 but important because demographics and state comparison are important.

The plot tab in excel with demographic ratios should have both ratio to us and ratio to state plots. can use this:
```
plot_barplot_ratios_ez(out, c(names_d_ratio_to_state_avg, names_d_subgroups_ratio_to_state_avg), 
  main = ""Demographic Indicators at Analyzed Sites Compared to Statewide"")

plot_barplot_ratios_ez(out, c(names_d_ratio_to_avg, names_d_subgroups_ratio_to_avg), 
  main = ""Demographic Indicators at Analyzed Sites Compared to Nationwide"")

```",https://api.github.com/repos/USEPA/EJAM/issues/359/comments,5/8/2024,6/10/2024,ejanalysis,none,1,0,0,FALSE
55,358,open,"new function for envt barplots? and new tab in excel called ""plot envt""",enhancement|urgency medium|plots-graphs-related,4538805068|6227894519|6235793514,cfd3d7|FBCA04|C2E0C6,"New feature or request||related to plotting/graphing like histo, bar, box, scatter",0,,,"new tab in excel called ""plot envt"" should have copy of barplots group showing ratios to US avg for all envt indicators as usavg, siteavg, person avg. That plot should be made available as a function broken out from the shiny server code. HOWEVER, it could simply be the output of these two plot functions:
```

plot_barplot_ratios_ez(testoutput_ejamit_100pts_1miles, names_e_ratio_to_state_avg, 
  main = ""Environmental Indicators at Analyzed Sites Compared to Statewide"")

plot_barplot_ratios_ez(testoutput_ejamit_100pts_1miles, names_e_ratio_to_avg, 
  main = ""Environmental Indicators at Analyzed Sites Compared to Nationwide"")


```",https://api.github.com/repos/USEPA/EJAM/issues/358/comments,5/8/2024,5/8/2024,ejanalysis,none,1,0,0,FALSE
56,357,open,"tab in excel called ""plot"" should be renamed to be ""plot %demog""",enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,0,,,,https://api.github.com/repos/USEPA/EJAM/issues/357/comments,5/8/2024,5/8/2024,ejanalysis,none,1,0,0,FALSE
57,356,open,improve format/resolution of plot_distances tab in excel,enhancement|urgency low|plots-graphs-related,4538805068|6227891676|6235793514,cfd3d7|cfd3d7|C2E0C6,"New feature or request||related to plotting/graphing like histo, bar, box, scatter",0,,,"The plot saved in the plot_distances tab should be formatted better so text is larger, etc. Existing and possibly better version are attached. But text labels ideally would be slanted to fit better, as done in other barplot already.

![worse plot](https://github.com/USEPA/EJAM/assets/8205979/59d01621-bb59-476c-a24a-31d52c597dd5)

![better plot](https://github.com/USEPA/EJAM/assets/8205979/423abc4b-0304-462e-9b6f-e3d528e22f1f)
",https://api.github.com/repos/USEPA/EJAM/issues/356/comments,5/8/2024,5/8/2024,ejanalysis,none,0,0,0,FALSE
58,355,open,doaggregate() - consider changes to results_bybg_people ,bug|enhancement|good first issue|urgency low,4538805065|4538805068|4538805069|6227891676,d73a4a|cfd3d7|7057ff|cfd3d7,Something isn't working|New feature or request|Good for newcomers|,2,,@ejanalysis further discussion is needed.|@ejanalysis what is the latest on this issue?,"1. **The pop count** might need better calculation in the table created by ejamit() or doaggregate() that is called results_bybg_people ...
This shows that pop seems identical regardless of which site the bg is near but it should vary and show only the fraction of the bgid pop count that is near that particular site (ejam_uniq_id). That number is calculated in doaggregate() somewhere but seems not to be put into results_bybg_people. This shows the issue: 
`
 testoutput_ejamit_1000pts_1miles$results_bybg_people[53:60, .(ejam_uniq_id, pop, bgid)]
` 

2. **results_bybg_overall**  should be returned or made available as an option somehow, not just the slightly different table that shows it bybg bysite (which has been named results_bybg_people, which is not very clear - if it were renamed it would be results_bybg_bysite).

### notes on How to get Distribution of Indicator Scores and Average, in each Demog group 

Want each Demog's DISTRIBUTION OF DISTANCES or ENVT for
   - Envt indicators, and for
   - Dist/proximity/sitecount stats.
  
Also, want 
    - %D as function of distance
    - Distance (mean) as function of Demog group
  
   We have each blockgroup near each site, which means some small % of those bgs are duplicated in this intermediate (not returned) table:
     `sites2bgs_plusblockgroupdata_bysite`
    and for those stats we would want to take only unique blockgroups from here,
    using the shorter distance I think, so the distribution of distances does not doublecount people.
  
   Sometimes we want this info OVERALL (not by site)
    Sometimes we want to see that distribution of **distances by D** *for just 1 site*
     And also want to see the **%D as a function of continuous distance** *at just 1 site*
    So although it would be simpler, clearer to return just all unique blockgroups NOT by site,
     just to retain flexibility this function currently reports all instances of blockgroup-site pairing.
  But, 
   ### we could return BOTH tables that provide 2 versions of info bybg: 
     - **bybg_bysite** (every blockgroup by site) plus 
     - **bybg_overall** (all blockgroups overall)
   Also note we could return both as blocks (for a higher resolution stepwise almost continous distance distribution):
     - **byblock_bysite** (like sites2blocks from getblocksnearby, but maybe with bg indicators joined? not efficient but convenient?) 
     - **byblock_overall** (like sites2blocks from getblocksnearby, but maybe with bg indicators joined? not efficient but convenient?) 
  
 see  archived file  /inst/notes_MISC/**NOTES_IDEA_OUT_BY_BG_SHOWS_DISTRIB_OVER_PEOPLE.R**",https://api.github.com/repos/USEPA/EJAM/issues/355/comments,5/7/2024,1/7/2025,ejanalysis,mlfurman3,0,0,0,FALSE
59,351,open,make names of test data consistent,documentation|refactor|urgency low,4538805066|6208400114|6227891676,C5DEF5|8F13A1|cfd3d7,Improvements or additions to documentation|Rewrite how code works or break into smaller pieces|,0,,,"This provides a useful list of test/sample data objects in key packages:
```
x <- EJAM:::datapack(simple = FALSE); cat(""\n\n"") 
x <- x[order(x$Package, x$Item), ] 
x[grepl(""^testp"", x$Item), ]  ; cat(""\n\n"")
x[grepl(""^test_"", x$Item), ]  ; cat(""\n\n"") 
x[grepl(""^testout"", x$Item), ]  ; cat(""\n\n"") 
x[grepl(""^test[^op_]"", x$Item), ]
```
The ones that have names starting with ""testpoints"" or ""testoutput"" are fine.
**The others should all be renamed to start with ""testinput_"" (instead of test_ or testdata_ or testids_ )** -- for example, test_address_table should become testinput_address_table.

To do this, 
- use global searches in ALL file types _in all 3 packages_, to make the changes (carefully) inside .R, .Rmd, and other files in various folders, then 
- rename the relevant files (e.g., EJAM/R/data_test_regid.R),  and datacreate_ files, and maybe .xlsx files?
-  redo devtools::document() 
-  install package and  
- rebuild vignettes and 
- update pkgdown site
- rebuild source package for github installs
- etc.",https://api.github.com/repos/USEPA/EJAM/issues/351/comments,5/3/2024,5/3/2024,ejanalysis,none,0,0,0,FALSE
60,346,open,offer user option to try running an example dataset ,enhancement|urgency medium|datasets/ pins/ AWS/ etc.,4538805068|6227894519|6343736234,cfd3d7|FBCA04|0E8A16,"New feature or request||related to data files via pins board, AWS, dataload_ etc.",0,,,"Where a user can select a file to upload, give them 2 options if they need help or are not sure how to start or don't have a file ready to go:
1. have a way they can click on some button or link to simulate the upload of a built-in sample dataset without having to upload anything themselves (like testpoints_100 should be something it would look like they just uploaded and then they can adjust radius and click start).
2. have a way they can click a link to download a zipped set of folders containing testdata similar to what is in the EJAM/inst/testdata/ but is currently stored here in a place anyone inside the network/on VPN should be able to reach it:
[Download Examples of files you can analyze in EJAM](https://usepa.sharepoint.com/:u:/s/EJAMWorkgroup/ETYFT6Y_W-lAlm_dH0GtiMABkgoIKXRFy-w8RcQ8cOrMUQ?e=UNFrur) - zipped set of files available from SharePoint (for trying out the EJAM app  files to download to your computer and then try uploading to EJAM for analysis)
 ",https://api.github.com/repos/USEPA/EJAM/issues/346/comments,4/24/2024,4/24/2024,ejanalysis,none,1,0,0,FALSE
61,345,open,shiny app shapefile upload process should also let user select a whole folder or .gdb or .zip,enhancement|shapefile-related|urgency high-ish but not a bug,4538805068|6343756696|7539794549,cfd3d7|C2E0C6|B9463A,"New feature or request|related to polygons/ shapefile/ GIS data/ buffers|for high urgency enhancements, to rank them just below high urgency bugs",3,,"Current change located on shapfefile-functions branch. 

shapefileUpdate: zip uploads containing valid files (.shp, .shx, .dbf, .prj) are able to upload and process. Limited to only functioning when these files are present. A warning is given otherwise.

 Functionality to upload geodatabases are available, but we will need to consider all of the permutations of how these can be presented in a zip file. Currently, gdb.zip functionality is available in shapefile_xyz, but additional investigations are needed to identify how to process/identify layers for zips of geodatabase folders and of geodatabases. The UI interface will likely need to be changed to allow a user to identify a specific polygon layer that can be used for processing, for example.   |@ParkerJanMalek is this on the development branch?|@leeeddie424 

> @ParkerJanMalek is this on the development branch?

Zip uploads are currently active on development. The gdb portion requires a bit more hooking up and testing to ensure that the application can correctly process geodatabase inputs of varying type quality. For example, many times geodatabases contain multiple layers. A robust upload method for complex gdb's like this may require some front end additions that allow users to choose the layer they want to see displayed. Additional checks for whether the layers are valid shapefile uploads would also need to be considered. Some of this functionality may be already applied in the shapefile_xyz.R script.
","In fixing this, try to use updated versions of shapefile_from_any(), ..._validize(), or related functions.

shiny app shapefile upload process should also let user select a whole _folder_ (with .shp,.dbf,etc.) _or gdb or .zip_ (where .zip has either .shp etc, or .gdb, or a whole folder (with .shp,.dbf,etc.)).

Revise the UI's shapefile upload instructions text and the app's error msg/warning text accordingly.

Also see #344  about better upload process for .shp,.dbf,etc.",https://api.github.com/repos/USEPA/EJAM/issues/345/comments,4/23/2024,10/22/2024,ejanalysis,ParkerJanMalek,0,1,1,FALSE
62,344,open,shiny app shapefile uploads of .shp/.dbf should work more robustly,enhancement|shapefile-related|urgency high-ish but not a bug,4538805068|6343756696|7539794549,cfd3d7|C2E0C6|B9463A,"New feature or request|related to polygons/ shapefile/ GIS data/ buffers|for high urgency enhancements, to rank them just below high urgency bugs",2,,"Seems mostly or entirely finished? Check if this should be closed. Tests pass after these changes made:
addressed by https://github.com/USEPA/EJAM/pull/369 and https://github.com/USEPA/EJAM/pull/442 
**Just need to confirm new functionality is also available from within ejamit() and from within shiny app/server/ui.**|@ParkerJanMalek is this issue okay to close?","In fixing this, try to use updated versions of shapefile_from_any(), ..._validize(), or related functions.

The app was telling user they must upload all 4 files .shp .dbf, etc. but then it allowed user to select only 1 instead of all 4 (and did not help user know how to select all 4) - and then it would not be able to start run - a hard-to-see warning said not all 4 files were provided.

What it should do now if trying to provide .shp/.dbf/etc. is this: 
Let a user select and upload any of these combinations:
- just .shp
- just .dbf
- .shp plus any 1 or more of the other types
- .dbf plus any 1 or more of the other types

Revise the UI's shapefile upload instructions text and the app's error msg/warning text accordingly.

Also see _related_ issues about allowing other filetypes (gdb, zip) and selecting just a whole folder.",https://api.github.com/repos/USEPA/EJAM/issues/344/comments,4/23/2024,1/13/2025,ejanalysis,ParkerJanMalek,0,1,1,FALSE
63,340,open,check/fix CRS throughout shapefile-related functions - should it be NAD83 or WGS84 to match EJScreen and data sources of lat/lon?,good first issue|urgency medium|maps-related|calculate/validate to EJScreen,4538805069|6227894519|6228710425|6343712128,7057ff|FBCA04|C2E0C6|FBCA04,"Good for newcomers||related to maps|related to errors in numbers, replicating EJScreen stats",0,,,Check with Alex H,https://api.github.com/repos/USEPA/EJAM/issues/340/comments,4/22/2024,9/5/2024,ejanalysis,ParkerJanMalek,1,0,0,FALSE
64,339,open,fix bug in batch.summarize() ,bug|good first issue|urgency low,4538805065|4538805069|6227891676,d73a4a|7057ff|cfd3d7,Something isn't working|Good for newcomers|,2,,"@DougMoy please look into |The problem is in the function batch.summarize in EJAMbatch.summarizer() which is called in ejamit. The number of elements in the variable rowfun is generated such that there are two times the number of elements in the input threshgroups. This is a problem because the variable bywhat only has 7 elements hard coded in it in the function batch.summarize, so in the forloop starting around line 400 that loops through the number of elements in rowfun, if there are more than 7 elements in rowfun, it will access something that is out of index in bywhat.  This is why the first input works because there are only 3 elements in threshgroups so it will not access anything past the 6th index, while the second input fails because it tries to access the 8th index in bywhat, which doesn't exist.

I am not sure what the possible fix is. I can include checks that stop the function running if it tries to access something out of bounds on bywhat, but that doesn't really address the problem of an input of more than 3 elements in threshnames not working. I am not sure about the purpose of this function and all the variables, but either the for loop needs to be addressed at line 400, or there needs to be more elements added to bywhat. If this function is supposed to work with any number of inputs, bywhat would have to be dynamically created based on the number of inputs in threshgroups. Feel free to reach out if there are any questions about my explanation.","Using an updated version of ejamit() which has the params below, 
this works:
```
x = ejamit(testpoints_10,    threshold = list(50, 80,   95),
threshnames = list( names_ej_pctile, names_ej_pctile,  names_ej_pctile),
threshgroup = list(""EJ US"", ""EJ US"", ""EJ US"" ))
```
but this fails somehow:   
```
x = ejamit(testpoints_10,    threshold = list(50, 80, 90, 95),
threshnames = list( names_ej_pctile, names_ej_pctile, names_ej_pctile, names_ej_pctile),
threshgroup = list(""EJ US"", ""EJ US"", ""EJ US"", ""EJ US"")) 
```",https://api.github.com/repos/USEPA/EJAM/issues/339/comments,4/22/2024,11/25/2024,ejanalysis,mlfurman3,0,0,0,FALSE
65,331,open,Update proximity score calculations in proxistat and related code,enhancement|good first issue|urgency medium|distance-related|calculate/validate to EJScreen|distance-adjustment for short dist,4538805068|4538805069|6227894519|6343333395|6343712128|7306076633,cfd3d7|7057ff|FBCA04|C2E0C6|FBCA04|ACC27C,"New feature or request|Good for newcomers||related to distances variables or calculations or plots|related to errors in numbers, replicating EJScreen stats|related to distance adj where 0 to 5 block pts are in circle",2,,@ejanalysis are these changes integrated yet?|see #143 also,"Proximity Score changes to be made April/May 2024 in EJScreen and in EJAM::proxistat()

1. Distance cut-off for **proximity** calculations (10km for BGs,  for blocks within block groups within 10km) - this applies only to determining how many NPL sites are nearby or when EJScreen or EJAM creates a proximity score for each blockgroup in the US. Does not affect aggregation within some circular buffer, but suggests larger than 10km radius is not a great idea?
2. proximity score handling of which blocks are near which NPL/RMP/etc. sites
  - Distance **proximity** is measured from RMP (or other site) point or NPL polygon boundary to block group boundary (not bg centroid). 
  - then all blocks within those flagged block groups get included in the universe for calculation. 
  - proximity score Block-based calculations are still measured at centroid when summing 1/d even if the d is slightly larger than 10km. [this affects how the new proximity scores are created, like in proxistat() but not how doaggregate() would work]
3. Wlil start using polygon not point to represent each NPL in creating the NPL **proximity** scores [does not affect EJAM]
4. Changes to the **proximity** calculations for proximity to X where X are polygons (to accommodate the NPL polygons or others):
  - if block point is inside the NPL polygon then that block's 1/d value is fixed at 1/d = 11.  
  - any distance < 0.1 km gets rounded up to be 0.1 km.

Should check how v2.3 does short distance adjustment if at all (where d < effective block radius) for creating proximity scores.",https://api.github.com/repos/USEPA/EJAM/issues/331/comments,4/18/2024,1/22/2025,ejanalysis,ejanalysis,1,0,0,FALSE
66,329,open,"add ""% women of childbearing age"" as a calculated indicator (everywhere % female is shown)",enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,1,,"```

# SCRIPT TO GET 
# PERCENT OF POPULATION THAT IS WOMEN OF CHILD BEARING AGE
# FOR ALL US BLOCK GROUPS FROM ACS (but missing PR, VI, other Island Areas probably!)
# Use ages 18-49, not the more widely used 16-49, since ages 15-17 are all in a single bin.

library(data.table)
library(tidycensus) # NEED API KEY POSSIBLY, FOR LARGE QUERIES AT LEAST

x <- tidycensus::load_variables(2022, ""acs5"")
# print(x[grepl(""b01001_"", x$name, ignore.case = T) & grepl(""Female"", x$label) & grepl(""group"", x$geography), ], n = 25)
allstates <- list()

for (i in 1:length(state.abb)) {
  MYST <- state.abb[i]
  y <- get_acs(geography = ""block group"",  variables = c(""B01001_001"", paste0(""B01001_0"", 31:39)), state = MYST)
  setDT(y)
  bgs     <-  y[variable != ""B01001_001"" , .(age1849 = sum(estimate)), by = ""GEOID""]
  totals  <-  y[variable == ""B01001_001"" , .(pop = sum(estimate)),     by = ""GEOID""]
  bgs <- merge(bgs, totals, by = ""GEOID"")
  setDT(bgs)
  bgs[ , pct1849f := age1849 / pop]
  bgs[is.na(pct1849f), pct1849f := NA] # to be NA instead of NaN 
  allstates[[i]] <- bgs
}

allstates <- data.table::rbindlist(allstates)
pctfemale_18_to_49 <- allstates
rm(allstates, x, MYST, bgs, totals, i, y)

save(pctfemale_18_to_49, file = ""pctfemale_18_to_49.rda"")

```
16-49 is the age range most often used to define this but this paper notes complexities in that:
https://www.cdc.gov/nchs/data/series/sr_02/sr02_157.pdf

Count data are available from Census ACS table B01001, which lets one collect totals for ages 18-49 rather than 16-49, by block group nationwide.  Variables to sum are B01001_031 through B01001_039. Denominator would be total population in B01001_001.

```
Label	United States!!Estimate
18 and 19 years	4424350
20 years	2208387
21 years	2192443
22 to 24 years	6438019
25 to 29 years	11099035
30 to 34 years	11181154
35 to 39 years	10869175
40 to 44 years	10304569
45 to 49 years	10086469
```",(contact M with any questions on this),https://api.github.com/repos/USEPA/EJAM/issues/329/comments,4/11/2024,5/16/2024,ejanalysis,ejanalysis,1,0,0,FALSE
67,327,open,Explain blockcount in map popups,urgency medium|maps-related,6227894519|6228710425,FBCA04|C2E0C6,|related to maps,0,,,"in `mapfast(testpoints_n(300))`, it says in the map popup eg ""blockcount: 22"". explain what does this mean, as better label at least

This is similar to feedback from multiple user sessions that map popups are too cluttered and not explained fully.
",https://api.github.com/repos/USEPA/EJAM/issues/327/comments,4/11/2024,4/11/2024,mlfurman3,none,1,0,0,FALSE
68,324,open,Consolidate unit conversion code,refactor|urgency low,6208400114|6227891676,8F13A1|cfd3d7,Rewrite how code works or break into smaller pieces|,0,,,"EJAM::convert_units(5, 'km', 'miles') is overlapping units::units() & maybe want to use same syntax but more synonyms or maybe just use the units pkg.


",https://api.github.com/repos/USEPA/EJAM/issues/324/comments,4/11/2024,4/11/2024,mlfurman3,none,0,0,0,FALSE
69,323,open,"Test ""installing"" vignette for non-EPA public users",documentation|urgency medium|dependencies-related,4538805066|6227894519|6228701467,C5DEF5|FBCA04|C2E0C6,Improvements or additions to documentation||related to dependencies,1,,see #579 ,"Test that EJAM ""installing"" vignette (https://usepa.github.io/EJAM/articles/1_installing.html) works for non-EPA public users, including handling all dependencies.",https://api.github.com/repos/USEPA/EJAM/issues/323/comments,4/11/2024,12/19/2024,mlfurman3,none,1,0,0,FALSE
70,320,open,check and fix examples,bug|documentation|good first issue|urgency medium,4538805065|4538805066|4538805069|6227894519,d73a4a|C5DEF5|7057ff|FBCA04,Something isn't working|Improvements or additions to documentation|Good for newcomers|,6,,"If this is going to take a lot of time, you should remove some or all examples or at least failing ones? for now and save them and build documentation without at least the bad ones, and push to new github pages - don't want help docs to have failing examples in them!|This code that produces this may be found here: a_pkgdown_site_setup_script|@ejanalysis reassigning to you please let us know if you need any input. cc: @alex-silverman |@ejanalysis what is the current status on this ticket?|@ejanalysis is this resolved or still having issues building?|I have not had time to work on this at all. It is not as high priority as deployment, speed/performance of load time of shiny app as deployed, any other high urgency bugs. But there very well may be examples that are obsolete and would fail.
Anyone trying to use the package and documentation of functions would have problems with broken examples of course. 
And being able to submit to CRAN requires working examples for all exported functions, I believe. ","all the examples should be run and checked to see which ones do unexpected things or fail, and fix those.
One way is to build vignettes with the examples option on, so you can see outputs easily:
but careful to do this only in a new branch for that purpose! 
```
pkgdown::build_site_github_pages(
  dest_dir = ""docs"",
  examples = TRUE, 
  lazy = FALSE
) 
```


```
Warning messages:
1: Failed to parse example for topic 'distance_by_group1'
2: Failed to parse example for topic 'distance_by_group_plot'
3: Failed to parse example for topic 'distance_cdf_by_group_plot'
4: Failed to parse example for topic 'distance_mean_by_group'
5: Failed to parse example for topic 'ejscreen_vs_ejam'
6: Failed to parse example for topic 'ejscreen_vs_ejam_see1'
7: Failed to parse example for topic 'ejscreen_vs_ejam_see1map'
8: Failed to parse example for topic 'ejscreen_vs_ejam_summary'
9: Failed to parse example for topic 'map_blockgroups_over_blocks'
10: Failed to parse example for topic 'naics_from_any'
11: Failed to parse example for topic 'plot_distance_cdf_by_group'
12: Failed to parse example for topic 'plot_distance_mean_by_group'
13: Failed to parse example for topic 'plot_vs_us'
14: Failed to parse example for topic 'table_xls_from_ejam'
15: Failed to parse example for topic 'url_frs_report'
```",https://api.github.com/repos/USEPA/EJAM/issues/320/comments,4/4/2024,1/10/2025,ejanalysis,ejanalysis,1,0,0,FALSE
71,311,open,consolidate DT::datatable() code from server and ejamit() as a standalone function,refactor|urgency low|server,6208400114|6227891676|7384237694,8F13A1|cfd3d7|25B9F0,Rewrite how code works or break into smaller pieces||removing code from app_server.R,1,,see new ejam2tableviewer() function that can provide this now at least for use by ejamit() but unclear if shiny app could use it,"remove `DT::datatable()` code from server and `ejamit()`, and consolidate as function(s) to create a DT::datatable() view of site by site results. 

- in app_server.R, it is around line 2644 and starts with  `DT::datatable(dt_final`,
- in ejamit(), it is around the end of the function and starts with      `DT::datatable( out$results_bysite`

Those overlap and need to consolidate them to use best features of each and to provide a helper function that can be used by both ejamit() and the server code, but also could be used in console by a user who wants to quickly see a tabular view of results.
It could be something like  `ejam2datatable()`. 
Also note the table-related functions like table_xyz

",https://api.github.com/repos/USEPA/EJAM/issues/311/comments,3/25/2024,9/1/2024,ejanalysis,none,0,0,0,FALSE
72,310,open,"results_summarized$rows percentiles info needs debugging, or stop using it",bug|good first issue|urgency medium,4538805065|4538805069|6227894519,d73a4a|7057ff|FBCA04,Something isn't working|Good for newcomers|,2,,"Made fixes to the results_summarized$cols portion of this, on 4/21/24. 

Quantiles via probs were not checked. 

results_summarized$rows  were not checked.|@DougMoy  please look into this to see if it is still occuring.","`EJAMbatch.summarizer::batch.summarize()` was used to create summary stats (summarizing across indicators and summarizing across sites or people). This occurs both in ejamit() and in shiny app app_server.R, but seems to have problems (maybe).

**The $rows part has summary stats for each indicator, across all sites and people**:
```
> rownames(x$results_summarized$rows)
[1] ""Average site""   ""Average person"" ""Median site""    ""Median person""  ""Min""            ""Max""            ""Sum""
```

**The $cols part has summary stats for each site, across a group of indicators**:  
The number of variables above some threshold is supposed to be how many of EJ indexes are >= Nth percentile, but the numbers seemed wrong. 

In app_server.R the summary info is stored in the reactive `data_summarized()` and comes from 
```
EJAMbatch.summarizer::batch.summarize(
        sitestats = data.frame(data_processed()$results_bysite),
        popstats =  data.frame(data_processed()$results_bysite),
        ## user-selected quantiles to use
        #probs = as.numeric(input$an_list_pctiles),
        threshold = list(input$an_thresh_comp1) # compare variables to 90th %ile or other percentile, like threshold1 param in ejamit()
      )
```
In ejamit() the summary info is stored in  `results_summarized$rows`  and `results_summarized$cols`


This was at the end of ejamit() to print some info to console, but the numbers looked incorrect:
   ```
    # cat(""\nWhich Demog groups or Envt stressors are highest (relative to States overall): \n\n"")
    #
    # if (subgroups_type == 'nh')    { subratvarnames <- names_d_subgroups_nh_ratio_to_state_avg}
    # if (subgroups_type == 'alone') { subratvarnames <- names_d_subgroups_alone_ratio_to_state_avg}
    # if (subgroups_type == 'both')  { subratvarnames <- c(names_d_subgroups_nh_ratio_to_state_avg, names_d_subgroups_alone_ratio_to_state_avg)}
    #
    # grps <- list(
    #   names_d_ratio_to_state_avg,
    #   subratvarnames, #names_d_subgroups_ratio_to_state_avg,   #   edited to flexibly use nh, alone, or both types
    #   names_e_ratio_to_state_avg
    # )
    # for (somenames in grps) {
    #   # somenames <- grep(""ratio.to.state"", names(out$results_summarized$rows), value = TRUE)
    #   # cat(""Score as Ratio to State Average:\n"")
    #   someinfo <- t(out$results_summarized$rows[ , somenames])[ , c(1,2,6)]         # disabled in ejam lite package ***
    #   someinfo <- data.frame(someinfo)
    #   rownames(someinfo) <- fixcolnames(somenames, 'rname', 'long')
    #   colnames(someinfo) <- c(""Avg resident overall"", ""at site with max ratio"", ""Avg site"")
    #   print(
    #     round(someinfo[order(someinfo[,""Avg resident overall""], decreasing = TRUE), ], 1)
    #   )
    #   cat(""\n\n"")
    # }
    ###################################### #
    # site counts and distance minima
    # print(  round(tail(t(out$results_summarized$rows)[ ,1:7],7),1)  )
    # cat(""\n\n"")
```",https://api.github.com/repos/USEPA/EJAM/issues/310/comments,3/25/2024,11/25/2024,ejanalysis,DougMoy,1,0,0,FALSE
73,305,open,Remove NA console messages from `doaggregate`,enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,0,,,"For NA indicator scores, too many messages are printed to the console. Remove from `doaggregate()` the messages to console about ""Among these results, all raw scores were NA (so percentiles will be reported as NA) in zone = MT for proximity.rmp""  -- done in a branch",https://api.github.com/repos/USEPA/EJAM/issues/305/comments,3/21/2024,3/21/2024,mlfurman3,none,0,0,0,FALSE
74,304,open,Enable printing reports of analysis speed to console,enhancement|urgency medium|speed / performance (see #444),4538805068|6227894519|6535412240,cfd3d7|FBCA04|e99695,"New feature or request||related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.",0,,,"getblocksnearby() and doaggregate() and ejamit() should print speed reports to console, reporting time spent, places done, and rate in terms of how many places per hour.

This is related to #302 ",https://api.github.com/repos/USEPA/EJAM/issues/304/comments,3/21/2024,7/9/2024,mlfurman3,none,1,0,0,FALSE
75,303,open,Include results map and demog barplot in `ejam2report`,enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,1,,see #462 ,"`ejam2report()` should also have the results map and demographic barplot like the shiny app community report does. but without duplicating code - consolidate. 

Related: can we use `mapfast()` and `plot_barplot_ratios_ez()` in both `ejam2report()` and in app server?",https://api.github.com/repos/USEPA/EJAM/issues/303/comments,3/21/2024,8/27/2024,mlfurman3,none,1,0,0,FALSE
76,302,open,Show number of places analyzed in `ejam2report`,enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,0,,,`ejam2report()` should say how many points got analyzed or places. server does it already. use and consolidated existing drafted code that is already available.,https://api.github.com/repos/USEPA/EJAM/issues/302/comments,3/21/2024,3/21/2024,mlfurman3,none,1,0,0,FALSE
77,300,open,Create public repo with large EJAM datasets included,enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,1,,"**Public bundle and/or open-source repo sharing EJAM , 
Notes on questions, cleanup to do, etc. - notes as of 12/24**

**How to Install** 
- Confirmed one can use 
`x = build(vignettes=FALSE, manual=FALSE, clean_doc=T, binary=F)`
- Confirmed one can use
`install.packages(""https://github.com/USEPA/ejscreen-multisite-open/archive/refs/tags/v2.32-public.tar.gz"")` for public branch installation
- see https://github.com/USEPA/EJAM-open/archive/refs/tags/v2.32.tar.gz for full / main branch open source version of full pkg/main branch 12/2025
- Must update the installation instructions in the pkgdown ghpages website/article, etc.
   

**The short idea now is this:**  We can keep the EJAM repo private and place onto some public repo(s) a  .tar.gz file(s) letting anyone install the EJAM package (built from the MAIN branch and/or from the PUBLIC-EJSCREEN branch). This lets us deploy to the public server from a public repo, right? And this lets us keep EJAM as the internal repo (so our branches, issues, etc. are preserved and links in them work), while still sharing with public an installable package named EJAM and giving them access to the public pkgdown pages that talk about the package being named EJAM. 

In other words, ASAP

1) we create a minimal public repo that has just an installable source bundle of an EJAM package that is a copy of the essential branch/parts of the EJAM package, as .tar.gz   via build() made from a cleaned-up copy of the PUBLIC-EJSCREEN branch, a new public repo called whatever, like ejscreen-multisite-open Then DMAP could deploy to public server from that???  Would that work as a way to instantly fix the challenges of migrating to public facing production server?

2) we finally share the package just enough to make it easy to install for a public user, to install the MAIN branch version, -- we do essentially the same thing as above, but build an installable source tar.gz from todays MAIN branch, and host that on a new public repo, maybe called EJAM-open  The package bundled and saved there would still be called EJAM   It would be just the built source package so it would have no other branches, no issues, no extra folders and notes and no datacreate etc. for now. Just a way someone can use the R package (and run the app locally if they want to). That at least would let anyone use the package in R.

Later,
 To provide a true open source development repo we can work that out soon/later, but need to figure out the naming issue, and which if any branches and issues to include there. 

_The key thing that would not work is the public trying to click links that point to the still-private EJAM repo.  The problem with links and repo names is that I think if we want to keep branches and issues private/internal, but have the pkgdown and R-based documentation public, we cannot have it both ways  either all the Issues and commit history info/branch can work and still point to a repo called EJAM  or else  all the manuals/.Rd/pkgdown help docs can work and still point to a repo called EJAM  but I dont see how to share public documentation but keep private the history of branches and issues. But I think if the package name is EJAM then even if the bundle is hosted somewhere else they can install and use the EJAM package and the only links that will fail will be the ones that refer to the internal github repository called EJAM. Links for documentation and pkgdown site would work._

more / older notes:

**GOALS/STAGES/ OVERALL APPROACH** - make sure we understand purpose of sharing bundle just so they can install the app and run LOCAL web app or use in console, versus something appropriate for them to host themselves for the public (epa logos e.g. would be a problem), versus sharing full source code essential to build from source (why), versus full source code so they can do some development/ modify/ do pull requests, such as providing vignettes, tests, functions that are draft/not yet used, etc.; and for them to have access to everything else.

**BINARY , SOURCE , KEY BRANCHES , FOLDERS , or FULL REPO?**  Before we are ready to make an entire repo public even with just one branch of source code, even with no issues or git history, we should just host/share source bundle (or binary if we do that) of the cleaned up package. But is there even a way to offer an installable package that does not give them the full source code, in case they want to just use the package but do not need to have the source folders? Does a binary do that except it requires making a binary for win, macos, linux each separately? Will everything in the package even work in that case, just without ability to edit source? You can still see the source code without comments if you have only the installed pkg, but all the datacreate, etc. documentation would be left out. Do we want to first offer a version people can use but not show them the complete set of folders yet? 

**REPOSITORIES - WHICH SHOULD HOST WHAT?**
Ideas for repositories to create and which to be public vs internal, have just source bundle vs just source vs full set of branches and issues:
- **`ejscreen-multisite-open`**  public repo - did a release, just to share .tar.gz source bundle that is built from cleaned up source snapshot PUBLIC-EJSCREEN branch. no code, branches, issues, etc. Just that tar.gz file. No .arrow files in data folder before built.
- **`EJAM`**  or else **`EJAM-open`**  1) for source snapshot bundle built from cleaned up MAIN branch, AND 2) open source for developers- clarify what to include... start with no issues, only main and development branches, but possibly also PUBLIC-EJSCREEN? But if this public repo is not named EJAM, the pkgdown site at a minimum would need to be redone and before that all the help docs as roxygen .Rd files would have to get redone so links work, and all the references to the package name, etc.
- **`EJAM`**  or else **`EJAM-dev`**  full internal development repo with all branches and issues and pkgdown site etc. etc. Not built, not public. But if this internal repo is not still named EJAM, all the links to issues or files or commits or etc. would be messed up as they try to point back to the original EJAM repo etc. 

**BRANCHES** - when we share a public repo, we want to start with only one or very few branches, but which ones? maybe just one, maybe also a dev branch?
Do not make the bundle from the main branch or development branch, for now - for now, create a new branch that is opensource and use that version to clean up folders, files, etc. that will be included in the shared public source bundle

**ISSUES** - when we share a public repo, we want to start with zero issues, or possibly some important ones where we actually want to solicit open source dev contributions? easiest is start with zero issues.

**EPA LOGO** - how to handle the EPA logos? code about them? in header of website but also in community report, etc. We might need a switch/file similar to public vs internal version controls, that controls if it is a branch/release that is suitable for the public to run themselves  particularly in regards to the EPA logos since we maybe do not want them to publish a hosted app that still has our epa logos in it? but if they run it locally the epa logo makes sense! and simply dropping the logos does not make sense since we want attribution/credit - maybe just need to ensure the license and instructions make clear how/if they can use the EPA logo?

**isPublic:**  I do not think we want default options to be isPublic=FALSE for the open source / shared package?we want EPA staff and developers to be able to easily use the full app. but if they want to host the app we need to make sure we emphasize caution on that.

**DELETE / clean up** these or some of them, before sharing bundle snapshot of package public open source, HOWEVER some of the things below will automatically get excluded from a build/ bundle so the only reason to delete them would be if the entire repository is open that has all these source folders, not if just the built bundle itself is the only thing shared.
	manifest.json
	make sure data folder does NOT have all the .arrow files, before build
	NEWS.md
	plumber folder for now
	any hard coded ip addresses like for internal EPA servers such as might be in the code for ejscreenapi app
	vignettes folder since we build them and publish them via ghpages
	written report folder. code about it?
	global search for corr, mysource, internal, private, public, Abt, SAIC, OEJ, OP, EJAMbatch.summarizer, EJAMejscreenapi, etc.
	OEJ is mentioned in report.Rmd, the 3 README files, and doaggregate.R
	github.com/USEPA is mentioned in DESCRIPTION, global.R, doaggregate.R, README.MD and .Rmd, NEWS.MD 1_installing.Rmd, 2_quickstart.Rmd, EJAM.Rd, app_ui_EJAMejscreenapi.R, CONTRIBUTING.md
	testdata examples_of_output should get updated? 
	testdata/examples_of_output/*.xlsx files all seem to contain metadata about author and last saved by = Mcorrale and 2 testpoints_ files have abt listed?  can we edit EJAM code that saves xlsx files to somehow ensure that field is left empty?
	EJAM logo and references to it??
	man folder contents .Rd files if they would get recreated during any install from source operation?
	maybe the draft UNUSED or OBSOLETE functions? acs_bybg.R, acs_bycounty.R, dataload_from_aws, ..
	code that mentions  https://github.com/USEPA/webcms/blob/main/utilities/r/OneEPA_template.R  such as in global.R, and in app_ui_EJAMejscreenapi.R
	the EJAM/www folder in root is confusing and might get mixed up with the one in source folder EJAM/inst/app/www so if it is true that we do not need the former, we should delete it from all branches.",,https://api.github.com/repos/USEPA/EJAM/issues/300/comments,3/21/2024,12/21/2024,mlfurman3,ejanalysis,1,0,0,FALSE
78,299,open,Show estimated runtime for analysis code - relates to #163,enhancement|good first issue|speed / performance (see #444)|urgency high-ish but not a bug,4538805068|4538805069|6535412240|7539794549,cfd3d7|7057ff|e99695|B9463A,"New feature or request|Good for newcomers|related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.|for high urgency enhancements, to rank them just below high urgency bugs",3,,"there is already some relevant code drafted in one of the repositories... maybe speedtest or something like that ... maybe in the EJAMejscreenapi pkg. |@sarasoko see more details in #560 & #410 etc|@DougMoy re-assigning ticket to you
cc: @sarasoko","getblocksnearby() and doaggregate() and ejamit() should predict how long it will take to run and if >5 or 10 seconds, should print estimated time needed to console (and in shiny app somehow if they are expected to have to wait long).",https://api.github.com/repos/USEPA/EJAM/issues/299/comments,3/21/2024,2/10/2025,mlfurman3,DougMoy,0,1,1,FALSE
79,298,open,Compare run times for functions with and without `include_ejindexes = TRUE`,enhancement|urgency low|speed / performance (see #444),4538805068|6227891676|6535412240,cfd3d7|cfd3d7|e99695,"New feature or request||related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.",0,,,"Note: The EJAM shiny app currently has a default of include_ejindexes = TRUE for its analyses

Check how much it slows down the shiny app load time and run times if we change default in ejamit() and I guess also in doaggregate() to include_ejindexes = TRUE, -- that slows it down since it needs to get bgej dataset OR as an alternative, test carefully to ensure presence of EJ indexes is checked for in all other functions that have presumed those fields are in output of ejamit or doaggregate, and vignettes, and function examples.",https://api.github.com/repos/USEPA/EJAM/issues/298/comments,3/21/2024,12/12/2024,mlfurman3,none,0,0,0,FALSE
80,292,open,Detailed Table UI Filtering improvements,urgency low,6227891676,cfd3d7,,0,,,"Right now, the filters are functional, but there are some display issues to note:

- The column sizes can't be changed, so when filtering State, long names get truncated into two or three lines
![image](https://github.com/USEPA/EJAM/assets/48810301/c8bf30d9-1719-4f1a-b1f4-55852044f085)

- Numeric column sliders are behind other filter boxes 
![image](https://github.com/USEPA/EJAM/assets/48810301/f3d65eb2-e9fa-43da-bb8a-1e2535c7fdb6)

- Default filter of 'All' gets truncated if the columns are not sufficiently wide 
![image](https://github.com/USEPA/EJAM/assets/48810301/f406cf07-3ebb-4989-8d61-92a5cc9b6f9f)

- Sometimes when selecting a filter, it will re-center the column in the horizontal scroll, which can be visually confusing",https://api.github.com/repos/USEPA/EJAM/issues/292/comments,3/19/2024,3/19/2024,sarasoko,none,0,0,0,FALSE
81,291,open,"in map_headernames, consider adding info re: in which tables/ popups/ xls/ etc. should given indicator be included",urgency low|popups-related|datasets/ pins/ AWS/ etc.,6227891676|6228696683|6343736234,cfd3d7|C2E0C6|0E8A16,"|related to map popups|related to data files via pins board, AWS, dataload_ etc.",0,,,"we could add metadata in the map_headernames info that says which indicators should appear where by default 
Having all indicators in all those places is too much and this might be a way to organize that.
Places to consider here: 
- the map popups, 
- the interactive site by site web table, 
- the excel output tables
- each type of plot 
  - barplot of summary report web and 
  - barplot of summary report download 
  - barplot of summary report in excel, 
  - excel plot1
  - excel plot2
  - detail plots comparing bars
  - detail plots of histogram info
  - etc.
- some optional extra indicators to show at bottom of the summary report tables

",https://api.github.com/repos/USEPA/EJAM/issues/291/comments,3/19/2024,3/19/2024,ejanalysis,none,0,0,0,FALSE
82,290,open,popup in summary report map has too many indicators?,enhancement|urgency low|popups-related,4538805068|6227891676|6228696683,cfd3d7|cfd3d7|C2E0C6,New feature or request||related to map popups,0,,,"summary report map popup has too many indicators? (and/or can they be grouped- better but more work and unsure worthwhile).
",https://api.github.com/repos/USEPA/EJAM/issues/290/comments,3/19/2024,3/19/2024,ejanalysis,none,0,0,0,FALSE
83,289,open,make Demog. section of summary report table more visually prominent,enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,0,,,"In summary report, instead of Envt and Demog being all under one blue header, use 2 separate blue headers but very thin (not use up lots of space) for Envt versus Demog - those 2 groups are very different. Or just make a more visually strong distinction but without using up more vertical space. EJScreen report has them all together but we don't have to. 
",https://api.github.com/repos/USEPA/EJAM/issues/289/comments,3/19/2024,3/19/2024,ejanalysis,none,0,0,0,FALSE
84,287,open,Excel's new tab with upload needs cap on size,enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,0,,,"
For the tab that will contain user uploaded/specified table, have a cap and warning related to how many columns can be pulled into the output xlsx, just in case they uploaded a huge spreadsheet and it would slow down the excel download and we are not sure we really want to save that entire table in our output excel file. When they try to download excel results, it should warn user that only the 1st 50 columns of their uploaded table will be saved in downloaded excel, or maybe prompt user to warn them it will only include 1st 50 but they can override that just before download. 

Default & actual cap like 50 columns would be set in global and a parameter adjustable in advanced tab, similar to caps on numbers of points.",https://api.github.com/repos/USEPA/EJAM/issues/287/comments,3/19/2024,3/19/2024,ejanalysis,none,0,0,0,FALSE
85,286,open,Excel needs new tab with uploaded places or facilities found,enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,0,,,"Excel needs new tab with uploaded places or facilities found - This will be very useful.

Add a tab that will provide the user's uploaded or specified/found places, and ensure it also has ejam_unique_id and exact row count and sort order matching the results_bysite info in the by site tab. 

Note this must be done with awareness that uploads lacking valid lat/lon currently fail to appear in output tables - make clear how we handle it and ensure bad or missing lat/lon uploads are in both tabs or neither tab. 

What to call the tab: 
1) Call this new tab, ""Uploaded table of places"" if they uploaded latlon or regids or programids, or uploaded FIPS, or uploaded shapefile info (or street address once that works). 
2) If they selected NAICS/SIC/ Program/ MACT, however, then I think it would be most useful to call the tab ""Facilities found by Category"" or instead of ""category"" use one of (NAICS/SIC/Program/MACT). In that case, put in the tab the frs table info that was pulled up, which would include ... names(frs) ... ""lat"", ""lon"", ""REGISTRY_ID"", ""PRIMARY_NAME"", ""NAICS"", ""SIC"", ""PGM_SYS_ACRNMS"". ",https://api.github.com/repos/USEPA/EJAM/issues/286/comments,3/19/2024,3/19/2024,ejanalysis,none,1,0,0,FALSE
86,284,open,UPDATES - automate frequent updates of the frs and sic and naics datasets + others,enhancement|urgency medium|datasets/ pins/ AWS/ etc.,4538805068|6227894519|6343736234,cfd3d7|FBCA04|0E8A16,"New feature or request||related to data files via pins board, AWS, dataload_ etc.",0,,,"(This is one of the issues under the umbrella of #285 and #338)

Automate the creation of frequently updated datasets, including posting them to pins board and or AWS or wherever they end up being stored.

0) clarify list of datasets that need to be updated often. see  ` EJAM:::datapack(""EJAM"")`
1) find scripts /code that creates each dataset (some in EJAM/R/ functions, some in EJAM/data-raw/ scripts). BUT NOTE THAT FRS is also available via API as a new/different approach to consider, that could replace downloading a snapshot of it.
2) confirm it still works entirely correctly, maybe writing tests for it
3) maybe consolidate that code in one place, one repo (if not done already)
4) maybe put all that code in one script, or package it somehow so it is clear and easy to run regularly -- most is already consolidated via frs_update_datasets() but some pieces may still be elsewhere like scripts in data-raw folder.
5) combine it with some code that would save a copy of each on pins board and/or AWS or public repo (see some code in EJAM/data-raw/datacreate_0_UPDATE_ALL_DATASETS.R for example)
6) also add some code that writes updated metadata as needed in pins board and AWS (see EJAM/data-raw/datacreate_0_UPDATE_ALL_DATASETS.R etc.)
7) decide how often to update each (weekly?) - check how often ECHO and FRS and EJScreen update FRS info, and how. There is some EPA updating service via geoplatform too? And FRS is also available via API as a new/different approach.
8) decide and then implement mechanism to use for the recurring job(s). Mechanisms could be:
  - **manual** run of R script on a schedule with someone responsible for that (easiest to start with but not a good fix for very long)
  - **recurring Server event mechanism** that EPA's Posit Connect Server offers
  - **github actions** (set up to occur every x days)

These may change daily or **weekly**:

See
-  EJAM/data-raw/datacreate_frs_.R which uses frs_update_datasets()
-  EJAM/data-raw/datacreate_frs_by_mact.R
-  EJAM/data-raw/datacreate_frs_by_sic.R
-  EJAM/data-raw/datacreate_epa_programs.R
-  EJAM/data-raw/datacreate_sic_counts.R
- and other related scripts

to create/update these:

- frs, frs_by_mact, frs_by_naics, frs_by_programid, frs_by_sic 
- naics_counts (how many of latest listing of FRS sites are in each NAICS)
- naicstable
- sictable
- epa_programs
- frsprogramcodes
- mact_table
- Because they are supposed to contain actual examples of or results from real facilities, all the test... objects see #334  like testpoints..., testoutput..., test_regid, etc.plus ""sites2blocks_example100pts_1miles"", ""sites2blocks_example10pts_1miles"" 
- Plus the .csv or .xlsx etc. files in testdata/regid/ and other testdata/ subfolders
- the testthat files that check for expected results and use those test input and output files
- plus  sharepoint   EJAMWorkgroup   datasets  folder has copies of .arrow for convenience until datasets easier to access. Those need to be updated too, if used. 
Also, every 3 years: The actual NAICS codes are changed? (and SIC?) 
- NAICS, SIC


See the separate issue about objects that change ANNUALLY - #285 
",https://api.github.com/repos/USEPA/EJAM/issues/284/comments,3/19/2024,1/2/2025,ejanalysis,ParkerJanMalek,1,0,0,FALSE
87,283,open,Replicating EJScreen: Distances to block points in circular buffers should replicate those in EJScreen,bug|good first issue|urgency medium|distance-related|calculate/validate to EJScreen,4538805065|4538805069|6227894519|6343333395|6343712128,d73a4a|7057ff|FBCA04|C2E0C6|FBCA04,"Something isn't working|Good for newcomers||related to distances variables or calculations or plots|related to errors in numbers, replicating EJScreen stats",2,,"SEE MORE RECENT COMMENT|AH confirmed that EJAM-EJScreen as of 4/23/24 have **a very small but consequential discrepancy in estimated distance** from sitepoint to blockpoint (which then causes a difference in pop count and other stats):
EJAM's estimated distances for 100 points were often half a meter but up to 4 (or even 6 in one case) meters smaller than EJScreen/ESRI distance estimates (at radius of 1 mile or 1609 meters) and sometimes up to 1 meter larger than the ESRI estimate. EJAM was  compared to esris geodesic distance method. Thats causing the slight difference in results.

AH's suggestion:
  EJScreen is measuring geodesic and [it seems that EJAM is] measuring them planar, so
**... try using this package to see if you can replicate EJScreens distances:**
https://cran.r-project.org/web/packages/geodist/geodist.pdf

This is the engine esri uses to calculate geodesic length:
https://developers.arcgis.com/javascript/latest/api-reference/esri-geometry-geometryEngine.html#geodesicLength

And if youre buffering anything, this is the geodesic buffer engine:
https://developers.arcgis.com/javascript/latest/api-reference/esri-geometry-geometryEngine.html#geodesicBuffer

more details, probably not needed:
Details on code for EJScreen finding nearby block points:

EJScreen uses the function called ""`esriSpatialRelEnum.esriSpatialRelIntersects`""
to do what EJAM does in `EJAM::getblocksnearby()` or `EJAM::get_blockpoints_in_shape()`
The ESRI function is very briefly mentioned in these pages:
https://developers.arcgis.com/enterprise-sdk/api-reference/net/esriSpatialRelEnum/
https://help.arcgis.com/en/sdk/10.0/java_ao_adf/api/arcobjects/com/esri/arcgis/geodatabase/esriSpatialRelEnum.html

Code samples to demonstrate how EJScreen finds nearby block points using VB.NET
and the intersection function from ESRI to intersect the circular buffer or the polygon of whatever shape) with the set of all Census block internal points, 
with the function called
`esriSpatialRelEnum.esriSpatialRelIntersects`

The EJScreen code samples are in a file saved as ""0_EJSCREEN_ej_buffer_steps.pdf""
in an older commit in a dev folder, and later removed. It explains how EJScreen does the following: 

Use the analysis polygon to perform a spatial query on block centroid points. This returns all block centroids in the study area. Each centroid point has the Blockgroup ID it is part of and the population percentage it contains.

[Note the difference between simpler Euclidean distance or buffering and complex but accurate Geodesic buffering. As explained here https://www.esri.com/news/arcuser/0111/geodesic.html  for small distances both approaches are almost identical. For distances of 500 miles, e.g., the difference between methods is huge.]
 ```
geomArrayOut = iGS.BufferGeodesic(
aoGeom.SpatialReference, aoGeom.SpatialReference, da, 0.0#, 
iGS.FindUnitsByWKID(""EPSG"", unitValue), False, geomArrayIn)
aoPoly = geomArrayOut.Element(0)

Dim pSpatialFilter As ISpatialFilter = New SpatialFilter
pSpatialFilter.Geometry = aoPoly
pSpatialFilter.GeometryField = fcWeight.ShapeFieldName
pSpatialFilter.SpatialRel = esriSpatialRelEnum.esriSpatialRelIntersects
fCurs = fcWeight.Search(pSpatialFilter, False)
```
","see #113 for the full outline of all steps in replicating.

**Goal:** 

Modify `EJAM::getblocksnearby() `and related functions...to fix any discrepancy in which blocks are identified as within X miles.

**Problem:**

There often is a 1 OR 2 BLOCKS DIFFERENCE IN WHAT EJAM and EJScreen identify as WITHIN 3 MILES OF A POINT. Out of a few dozen or hundreds of blocks within 3 miles, EJAM often agrees on all but 1 or 2. Testing a small set points for a 3.1 mile radius in EJScreen vs EJAM shows a difference of plus or minus 1 block very often, and sometimes 4 or 5 blocks. In every case checked, the discrepancy in pop count was entirely explained by the discrepancy in blocks considered inside vs outside the circle. That in some cases is a 2% error in population count vs EJScreen's, but on average might be an absolute error of 0.2% in population count within 3.1 miles.

**Solutions:**

Try each and run comparison code after each, to see if that was the issue:

0) As of 8/2024, getblocksnearby() removed default distance adjustment for small distances, which might now better reflect what EJScreen does! see explanation in other issues and changes to getblocksnearby() circa 8/8/24.

1) !!! **The problem is (mostly) in the exact distance calculation step** !!! try replacing `pdist()` by trying a different method -- **see the comments added below about the geodist package!!** (probably slower but more accurate, as might be sf::st_something) to find exact distance to each nearby block -- only after getblocksnearby() has narrowed it down (quickly identified those nearby).

2) We already made sure that the main problem is not **coordinates/ projections issues**: see SAIC code (on github now) for EJScreen details on local coordinates projections that EJScreen uses before doing proximity analysis like getblocksnearby does. Initial conversations suggested these differences in map projections could explain some EJAM-EJScreen differences in population count inside each circular buffer. But, this is done now - see comment on this issue. Did not see any obvious difference related to coordinate system/projection! May still need to fix EJAM assumptions about CRS being either NAD83 or WGS84, in the shapefile functions, but not sure that has much impact on distances between lat/lon-specified facilities and blocks. 

3) Make sure a minor problem is not in the **`rectLookup()` step**. In getblocksnearby functions, **try expanding the rectangle created by SearchTrees::rectLookup() to be something like 1% or 3% larger, just in case it was missing some block points that EJScreen actually considers to be inside the radius. Does that fix it?**

4) **Rounding or accuracy / precision** is NOT the issue.",https://api.github.com/repos/USEPA/EJAM/issues/283/comments,3/19/2024,9/11/2024,ejanalysis,ejanalysis,1,0,0,FALSE
88,275,open,"clarify what ""N places"" really means & report on the selection type (in summary report etc.)",enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,0,,,"We need to improve the communication of
1. how many places were specified/ valid/ analyzed/ reported as having results
2. what are ""places"", i.e., how the ""places"" were specified (places/ points/ etc. via file of latlon/NAICS x/etc.)

**The best fix I can think of is to improve the description (e.g. in report header) and then put a footnote marker after the site count, to refer to a footnote we will add.** The footnote would explain the counts.

This info needs to be improved in 
- webpage version of summary report 
- downloaded version of summary report
- Excel notes tab 
- long word doc
- text output to console from ejamit(), or any metadata it may produce similar to the excel notes tab
- anywhere else? do plots refer to the count of sites?

Relevant code may include
- build_community_report()
- ejam2report()
- table_xls_from_ejam() aka ejam2excel()
- table_xls_format()
- app server/ ui

In the header/ excel notes, instead of something vague like ""any of the 386 selected points"" for example, it should say 
1. something tailored to the method of specifying places 
3. slightly more accurate description of what the count represents, and 
4. a star referring to a clarifying footnote

**Header text might be something like this:**

> Residents in any of the N ... 
>
> - areas specified (SHP) [if SHP shapefiles] OR
> - Counties/Census units selected [if census units]
> 
> OR 
>
> Residents within XYZ mile(s) of any of the N ... 
>           
> - {points provided}  [ if uploaded only lat/lon ]   OR
> - {facilities in NAICS xyz/ mact xyz/ sic xyz / xyz program} [if category or facility IDs]  
>
> - that were analyzed?  
> - that could be analyzed? 
> - with valid location data?
> - with any residents (""nearby"", if for points not shp/fips) ?

**Footnote text might be something like this:**

> Of the locations provided/ specified,
> - 409 total were {provided for analysis / found in specified EPA databases? (e.g., 409 facilities were found in EPA's facility registry services that were classified as NAICS 32411 - Petroleum Refineries) 
> - 386 had valid location (lat/lon) data and were analyzed, (23 lacked valid latitude and longitude information {in that database/ in the uploaded table / etc.})
> - 350 had demographic data (N returned no results due to estimated zero nearby residents, i.e., no nearby Census block points)


some other details:

In the summary report header etc., it now says for points, ""_...any of the 386 selected points_"" for example. But it is not clear what 386 represents and what ""selected points"" means. One source of confusion is that the upload page says how many are invalid in the sense of bad or missing lat lon, while the summary report says how many are valid in the sense of those issues AND the issue of zero population or block points nearby -- so the numbers seem to disagree. Try this example:
```
pts <- structure(list(`original row` = c(1, 2, 3), lat = c(""39.746490000000001"", 
"" 37.838648"", ""36.068006526329597""), lon = c(-74.20121, -109.655858, 
-5.17031658322482), notes = c(""valid with signif pop within 1 mile"", 
""valid but zero pop within 1 mile"", ""nonUSA latlon"")), row.names = c(NA, 
-3L), class = ""data.frame"")
out <- ejamit(pts, radius = 1)
# or try it in the shiny app
```

Also, confirm that the difference in those numbers is solely due to missing lat lon or invalid lat lon as opposed to good latlon but no results due to very small radius relative to local block size, for example, or zero population in nearby block, or other factors. 
",https://api.github.com/repos/USEPA/EJAM/issues/275/comments,3/14/2024,3/14/2024,ejanalysis,none,0,0,0,FALSE
89,272,open,change \dontrun to \donttest in all documentation,documentation|urgency low,4538805066|6227891676,C5DEF5|cfd3d7,Improvements or additions to documentation|,0,,,,https://api.github.com/repos/USEPA/EJAM/issues/272/comments,3/12/2024,3/12/2024,ejanalysis,none,0,0,0,FALSE
90,271,open,"Add missing @return info to each function where it is missing info on outputs, where  #' @return  is missing",documentation|urgency low,4538805066|6227891676,C5DEF5|cfd3d7,Improvements or additions to documentation|,0,,,"CRAN requires each exported function (or documented ones?) include info about what is returned.

Look at which functions are still missing the roxygen2 documentation line that says what the output of the function is
such as 
`#' @return REQUIRED INFO ABOUT RETURNED OBJECT GOES HERE`

```
x = checkhelper::find_missing_tags()
cbind( (as.vector(x$functions[x$functions$not_empty_return_value == FALSE & x$functions$has_export, 'topic']))$topic)

## or to see even non-exported ones:
# cbind( (as.vector(x$functions[x$functions$not_empty_return_value == FALSE, 'topic']))$topic) 
```",https://api.github.com/repos/USEPA/EJAM/issues/271/comments,3/11/2024,3/11/2024,ejanalysis,none,0,0,0,FALSE
91,265,open,Enable shiny.telemetry log file that is not just a text file on server,enhancement|urgency medium|datasets/ pins/ AWS/ etc.,4538805068|6227894519|6343736234,cfd3d7|FBCA04|0E8A16,"New feature or request||related to data files via pins board, AWS, dataload_ etc.",0,,,"dev_telemetry branch sets up ability to track user names logged in, clicks, etc.
but as drafted it would save info in log file that is a .txt file in the working directory. 
That might not work once deployed?
Even if it works deployed, it would get erased each time the app was redeployed,
and would get written to pkg home folder in source pkg while being used locally,
and then would get tracked by github unless in .gitignore",https://api.github.com/repos/USEPA/EJAM/issues/265/comments,2/24/2024,2/24/2024,ejanalysis,none,1,0,0,FALSE
92,264,open,Fix (or remove?) references to ejampackages data object,refactor|urgency low,6208400114|6227891676,8F13A1|cfd3d7,Rewrite how code works or break into smaller pieces|,0,,,"`ejampackages` is a utility/convenient data object in EJAM pkg, that just stores names of some relevant packages for while doing development to refer to them all at once easily. If removing it from the pkg, do global search to see where it had been used in scripts, though.

Is it or is it not an exported object?
Seems like cannot refer to it as `EJAM::ejampackages` (at least when pkg is not loaded/attached)
and supposedly should use` :: `or` :::` when it is used as a default param value (cant recall why but maybe to ensure examples or tests or load_all work?)

It was created in data-raw folder file called datacreate_etc  like this:

```
ejampackages <- names(
  grep(""EJAM.*"", installed.packages()[,'Package'], value=TRUE)
  )
# ejampackages <- ejampackages[ejampackages != ""EJAMfrsdata""]
usethis::use_data(ejampackages, overwrite = TRUE)
```

It is referred to in these snippets, to be checked/fixed:

- `datapack <- function(pkg=ejampackages, len=30, sortbysize=TRUE, simple = TRUE) {`

- `dupenames <- function(pkg = EJAM::ejampackages, sortbypkg=FALSE, compare.functions=TRUE) {`

- `metadata_check <- function(packages=EJAM::ejampackages, which=c(`




",https://api.github.com/repos/USEPA/EJAM/issues/264/comments,2/24/2024,2/24/2024,ejanalysis,ejanalysis,0,0,0,FALSE
93,262,open,"Enable higher resolution analysis than getblocksnearby() does, via Dasymetric mapping",enhancement|urgency low|maps-related|shapefile-related,4538805068|6227891676|6228710425|6343756696,cfd3d7|cfd3d7|C2E0C6|C2E0C6,New feature or request||related to maps|related to polygons/ shapefile/ GIS data/ buffers,0,,,"https://www.epa.gov/enviroatlas/dasymetric-toolbox
https://github.com/USEPA/Dasymetric-Toolbox-OpenSource
",https://api.github.com/repos/USEPA/EJAM/issues/262/comments,2/23/2024,2/23/2024,ejanalysis,none,0,0,0,FALSE
94,261,open,"enable an Add Data tool or otherwise harmonize with geoplatform, ejscreen, enviroatlas, echo, etc. to view or link to other layers",enhancement|urgency low|shapefile-related,4538805068|6227891676|6343756696,cfd3d7|cfd3d7|C2E0C6,New feature or request||related to polygons/ shapefile/ GIS data/ buffers,1,,"Note the [existing functions in EJAM that start with the word ""shape""](https://usepa.github.io/EJAM/reference/index.html#specify-places-by-shapefile) such as shapefile_from_any() 
 ","For example, 
- EJScreen lets you add layers in various ways (although you cannot ""analyze"" them it seems, i.e., get summary stats for a specified area based on that layer).
<img width=""300"" alt=""image"" src=""https://github.com/USEPA/EJAM/assets/8205979/bbcb606e-3f35-454e-93e0-cef63ab9da95"">   <img width=""300"" alt=""image"" src=""https://github.com/USEPA/EJAM/assets/8205979/bcfff076-6df3-4eeb-9f9a-03ed031c937e"">

- EnviroAtlas and other tools let you add layers as file, URL, directly from GeoPlatform, etc.:
https://enviroatlas.epa.gov/enviroatlas/interactivemap/
The Add Data tool allows users to add their own online or local data layers to the EnviroAtlas interactive map.
Tabs provide three different ways to add data to the EnviroAtlas map:
**Search**  search for **data layers in EPA's GeoPlatform, the Federal GeoPlatform, or [ArcGIS Online** [Exit EPA]](http://doc.arcgis.com/en/arcgis-online/reference/what-is-agol.htm) and add the layers to the EnviroAtlas interactive map.
**URL**  add **dynamic map services (e.g. image, feature, or tiled services) as well as Open Source WMS and KML services** to the EnviroAtlas interactive map from a known URL.
**File**  _upload zipped shapefiles, CSV (comma-separated variables), GeoJSON, KML, or GPX files_ from a local drive to the EnviroAtlas interactive map.
Once added, you may view the layer and its legend in the Layer List.
<img width=""397"" alt=""image"" src=""https://github.com/USEPA/EJAM/assets/8205979/9eff1691-38b1-4a39-86f3-91c5508c1306"">
<img width=""317"" alt=""image"" src=""https://github.com/USEPA/EJAM/assets/8205979/a468d5b5-c6b5-4262-bb36-f57273b6b8e2"">

<img width=""289"" alt=""image"" src=""https://github.com/USEPA/EJAM/assets/8205979/ac20127b-6bc0-479a-80f1-d13de60b2406"">
<img width=""503"" alt=""image"" src=""https://github.com/USEPA/EJAM/assets/8205979/459cd0c3-051e-4dda-a70f-d477b2e0af3d"">
",https://api.github.com/repos/USEPA/EJAM/issues/261/comments,2/23/2024,5/5/2024,ejanalysis,none,0,0,0,FALSE
95,258,open,enable selecting a folder as way to upload shapefile(s),enhancement|urgency low|shapefile-related,4538805068|6227891676|6343756696,cfd3d7|cfd3d7|C2E0C6,New feature or request||related to polygons/ shapefile/ GIS data/ buffers,0,,,"Now, user has to use shift key to select a range of files including .shp, etc. to specify the shapefile.
Issue #257 is about adding ability to upload 1 file that is a .zip and relevant functions to use are noted there. 

This issue is about adding ability to navigate to a folder and specify that whole folder (without needing to navigate into it), and have app look in folder to get the .shp etc. files needed. 

This may be a bit tricky since right now the upload is written to expect one or more files not a folder, and not sure how to make it flexible enough so a user can do either one as needed. When a user selects a folder right now, and tries to click on button to say they are done selecting, it just opens the folder since it is expecting file(s) not folder as the selection.  

Relevant code is in `app_server.R` at this reactive: 
`data_up_shp <- reactive({`",https://api.github.com/repos/USEPA/EJAM/issues/258/comments,2/20/2024,2/20/2024,ejanalysis,none,0,0,0,FALSE
96,256,open,"confusing UI: a user names the analysis #1, then forgets to change title when runs 2d analysis",enhancement|good first issue|urgency medium,4538805068|4538805069|6227894519,cfd3d7|7057ff|FBCA04,New feature or request|Good for newcomers|,1,,"Currently, the title is the only input that can be changed without rerunning the analysis, so its not obvious whether the analysis was rerun or not.

To avoid this, I suggest we only display the new title in the results if the user runs a new analysis.","somehow help them with this - confusing to see old title on new run.
not sure how to alert them ?",https://api.github.com/repos/USEPA/EJAM/issues/256/comments,2/20/2024,11/26/2024,ejanalysis,saradelessio-abt,1,0,0,FALSE
97,253,open,"confusion in UI: if user tries a second analysis by uploading new stuff, they sometimes click on See Results instead of reclicking ""Start Analysis"" ",enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,0,,,somehow help remove this confusion,https://api.github.com/repos/USEPA/EJAM/issues/253/comments,2/20/2024,2/20/2024,ejanalysis,none,1,0,0,FALSE
98,249,open,make latlon_from_naics() and other naics-related functions consistent with others like frs_from_naics(),refactor|urgency low,6208400114|6227891676,8F13A1|cfd3d7,Rewrite how code works or break into smaller pieces|,3,,"For example, compare these unexpected different results:

```
 #  NAICS columns are very different in these two functions outputs:
frs_from_naics(3273 )$NAICS
# [1] ""003273, 327320"" ""003273""         ""003273, 327320"" ""003273""        
latlon_from_naics(3273 )$NAICS 
# [1] 3273 3273 3273 3273

latlon_from_naics(3273)      # only 4 sites
frs_from_naics(3273)           # only 4 site

frs_from_naics(3273, children=TRUE)   # returns about 10,567 sites.
# And, a user would not realize children param exists if trying to hit tab while typing function because it was defined as function(naics_code_or_name, ...) and should be redone to make all params visible.

latlon_from_naics(3273, children=TRUE) 
# fails because children param was not even enabled/added in this function as written

latlon_from_naics(naics_from_any(3273, children = TRUE)$code)
# is what you would need to do which is complicated

# These provide useful outputs, but Based on function name, user might expect to get back vector of naics codes?
naics_from_any(3273)
naics_from_any(3273, children = TRUE)
naics_from_any(3273, children = TRUE)$code

```


|Some of these are getting fixed in early June edits. |note this has some relationship with #638 perhaps","The function names are not explicitly communicating what inputs are allowed and what outputs are allowed. Even if that is not fixed via renaming them all, the following should be fixed, and **similarly for other naics-related, sic-related, mact-related functions:**

`frs_from_naics(""Textile Mills"", children=T)`
returns a table since it allows code or text, and it has a param called children

but

`latlon_from_naics(""Textile Mills"", children=T)`
fails since it lacks children param

`latlon_from_naics(""Textile Mills"" )`
fails since it expects a code not text",https://api.github.com/repos/USEPA/EJAM/issues/249/comments,2/17/2024,1/2/2025,ejanalysis,none,0,0,0,FALSE
99,246,open,Automate updates/builds of the pkgdown site,documentation|urgency medium,4538805066|6227894519,C5DEF5|FBCA04,Improvements or additions to documentation|,0,,,"
**See https://pkgdown.r-lib.org/articles/how-to-update-released-site.html  !!** 



What worked for a simple example but is an awkward workflow:
- Deploy from branch, deploy from Master branch, use docs folder, are the 3 settings to specify in [github settings page for Pages]( https://github.com/USEPA/EJAM/settings/pages 
)
- MAYBE but not sure do usethis::use_pkgdown() but not usethis::use_pkgdown_github_pages() since the defaults were not what was needed!
- MAYBE do  pkgdown::build_site_github_pages() once at least to set it up.
- put a .nojekyll file in the docs folder ! jekyll issue made it fail to build on github
- remove docs folder from the items in .gitignore file ! that had been put there by one of above functions, and if publishing from docs after building locally via build_site(), you have to push that folder to github for it to get published. (unless using a gh action to do the whole thing, build site on github as notes down below suggest, in which case you do not need to always upload local docs folder)
- manually do pkgdown::build_site() to do each update, after which must commit and push the docs folder changes
- see https://github.com/USEPA/EJAM/actions to watch the site get republished after built locally and pushed 
(see a working simplistic site here:
browseURL(""https://github.com/ejanalysis/ejscreendata/actions"")
browseURL(""https://github.com/ejanalysis/ejscreendata/settings/pages"")
browseURL(""https://ejanalysis.github.io/ejscreendata/"")


- If interested in created an **automated workflow** e.g. see EPA example here: https://github.com/USEPA/TADA/blob/develop/.github/workflows/pkgdown.yaml to update the site automatically whenever you make changes (e.g. when you merge in a pull request)? 
- Or do you want to **run code to update the site** outside of an automated workflow; i.e., run: `pkgdown::build_site()` see: https://pkgdown.r-lib.org/ ? 

Another EPA team had to get the auto-build site workflow approved by our EPA org GitHub admins first (they maintain a list of all approved automated github workflows), but it is approved now so anyone can use it. It should be fairly easy to update the .yaml example for your package.

examples 
- https://usepa.github.io/EJAM
- https://usepa.github.io/EJSCREENBatch
- https://usepa.github.io/TADA/ 

-----------------------------------------

More notes from https://usethis.r-lib.org/reference/use_github_pages.html
`use_github_pages(branch = ""gh-pages"", path = ""/"", cname = NA)`

2 common options for branch and path for the site source:
This function anticipates two specific usage modes:

1. NOT USED BY EJAM: Publish from the **_root_** directory of a gh-pages branch, which is assumed to be only (or at least primarily) a remote branch. Typically the gh-pages branch is managed by an automatic ""build and deploy"" job, such as the one configured by [use_github_action(""pkgdown"")](https://usethis.r-lib.org/reference/use_github_action.html).
- The **default of branch = ""gh-pages"" and path = ""/""** reflects **strong GitHub support for this configuration:** when a gh-pages branch is first created, it is automatically published to Pages, using the source found in ""/"". If a gh-pages branch does not yet exist on the host, use_github_pages() creates an empty, orphan remote branch.

2. USED BY EJAM: Publish from the ""/docs"" directory of a ""regular"" branch, probably the repo's default branch. The user is assumed to have a plan for how they will manage the content below ""/docs"".
- The most common **alternative is to use the repo's default branch, coupled with path = ""/docs"".** It is the user's responsibility to ensure that this branch pre-exists on the host.
",https://api.github.com/repos/USEPA/EJAM/issues/246/comments,2/16/2024,9/30/2024,ejanalysis,ejanalysis,1,0,0,FALSE
100,244,open,increase readability of fonts in plot_distance_mean_by_group,enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,1,,opened after closing issue #195,"When using the advanced setting for including the plots in the excel download output, the fonts of the plot on sheet 'plot_distance' is illegible",https://api.github.com/repos/USEPA/EJAM/issues/244/comments,2/14/2024,9/5/2024,sarasoko,none,1,0,0,FALSE
101,243,open,Add info message to radius slider label on hover/click,enhancement|urgency low|distance-related,4538805068|6227891676|6343333395,cfd3d7|cfd3d7|C2E0C6,New feature or request||related to distances variables or calculations or plots,0,"As first described in #191, a hover info msg should provide additional context for the slider.
#### Potential text: 
""Distance changes the size of each area to include in the analysis. For analysis of sites defined by lat/lon coordinates, the distance is the radius of a circle around each point, such as the circle that includes everyone within 3 miles of a facility. For analysis of places defined by shapefiles, distance is the width of the buffer that can be added along the edges of each polygon, such as the area that includes anyone within 3 miles of any part of the property defined by the polygon.""",,,https://api.github.com/repos/USEPA/EJAM/issues/243/comments,2/14/2024,2/14/2024,mlfurman3,none,0,0,0,FALSE
102,241,open,Add missing columns to shiny app outputs (excel) - things provided in EJScreen Community Report and/or API,enhancement|good first issue|urgency medium|calculate/validate to EJScreen,4538805068|4538805069|6227894519|6343712128,cfd3d7|7057ff|FBCA04|FBCA04,"New feature or request|Good for newcomers||related to errors in numbers, replicating EJScreen stats",1,"This is one piece of issue #113 

The Community Report and/or **ejscreenit()** provides some useful outputs missing from **ejamit()**
and some of them could be added to ejamit and shiny app outputs. Add all other EJScreen community report reported indicators -- and any other API outputs -- that are not yet in EJAMshiny app outputs (or at least not in Excel download) yet:

1. vars already in output of doaggregate() and/or ejamit() but that just did not get coded to go into excel (if any)
2. vars we can easily add as outputs of doaggregate() etc. because we already had the necessary variables to calculate the score in doag (or via some calc_ejam etc approach)
3. vars we can add by using the indicator data the API provided and Abt scraped
4. vars we need to calculate on the fly via intersects with nonattainment, tribal, CJEST/IRA,
5. vars we need to calc on the fly via counts of point data nearby (schools, hospitals, churches, etc.)
6. others?

some examples
- [ ] counts of schools etc., see work in progress on something like countsitesnearby() or getfrsnearby() ?
- [x ] valid message (is it there?)
- [ x] EPA Region
- [ ] flag if overlaps with CJEST area etc.
- [ ] Area of Circular Buffer in Square Miles (is it there?)
- [x ] Percent of population speaking X at home (possibly a naming issue?)
- [ ]    Heart Disease, etc.  
- [ ] + the US and State Averages of those and US and State Percentiles of those?

This helps see which columns are provided by the **ejscreenit()**  API  outputs,
but are missing from **ejamit()** outputs:

```
setdiff(
   names(

      testoutput_ejscreenit_5$table) , 

   fixcolnames(names(

      ejscreenit_for_ejam(testpoints_10[1,],radius = 1)

    ), 'r', 'long'))  

Analyzing 1 sites, for residents living within a radius of 1 miles from each site.
Rate of 1,443 buffers per hour: 1 lat/long pairs took 2 seconds    Finished  
 
```","
what I see missing is mostly this:

- square miles?  aka  inputAreaMiles  
- ""names_health"", and related _( like ""names_health_avg"", ""names_health_pctile"", ""names_health_state_avg"", ""names_health_state_pctile"")_
- ""names_climate"", and related
- ""names_criticalservice"", and related
- Counts or flags for nearby things: ""names_featuresinarea"",  ""names_sitesinarea"",  ""names_flag"" 
- detailed language info?

```
42                                num_school               names_featuresinarea
43                              num_hospital               names_featuresinarea
44                                num_church               names_featuresinarea

75                                 count.NPL                  names_sitesinarea
76                                count.TSDF                  names_sitesinarea
77                              num_waterdis                  names_sitesinarea
78                               num_airpoll                  names_sitesinarea
79                            num_brownfield                  names_sitesinarea
80                                   num_tri                  names_sitesinarea

45                              yesno_tribal                         names_flag
46                            yesno_cejstdis                         names_flag
47                              yesno_iradis                         names_flag
48                           yesno_airnonatt                         names_flag
49                           yesno_impwaters                         names_flag


34                            pctlan_english                   names_d_language
35                             pctlan_french                   names_d_language
36                       pctlan_rus_pol_slav                   names_d_language
37                           pctlan_other_ie                   names_d_language
38                         pctlan_vietnamese                   names_d_language
39                        pctlan_other_asian                   names_d_language
40                             pctlan_arabic                   names_d_language
41                        pctlan_non_english                   names_d_language

```",,https://api.github.com/repos/USEPA/EJAM/issues/241/comments,2/13/2024,1/2/2025,ejanalysis,none,1,0,0,FALSE
103,237,open,latlon_from_anything() and maybe supporting validation functions fail to mark as invalid some invalid inputs,bug|urgency medium,4538805065|6227894519,d73a4a|FBCA04,Something isn't working|,3,"`latlon_from_anything(data.frame(lat=1,lon=1))`
returns a table with column showing valid = FALSE, as expected. 
However, these should also do that and fail to do so:
`latlon_from_anything(data.frame(lat=1,b=1))`
`latlon_from_anything(data.frame(a=1,b=1))`
`latlon_from_anything(testoutput_getblocksnearby_10pts_1miles)`
They confusingly return the table with a column indicating each row is valid, even when there are not latlon values at all. ","See related issue #208 - will investigate jointly

|Added NULL check to `latlon_is.valid` via commit dc51db2 that should fix this. Now merged into development.|Confirmed that the tests are now resulting in valid=FALSE",,https://api.github.com/repos/USEPA/EJAM/issues/237/comments,2/11/2024,2/14/2024,ejanalysis,ParkerJanMalek,1,0,0,FALSE
104,235,open,MODULE: Point layer MODULE (specify URL of service with point data),enhancement|refactor|urgency medium|server,4538805068|6208400114|6227894519|7384237694,cfd3d7|8F13A1|FBCA04|25B9F0,New feature or request|Rewrite how code works or break into smaller pieces||removing code from app_server.R,0,"**Point layer module**  Create a module (server/UI) and supporting function(s) that let user specify points by providing a URL of a layer of points (feature/map service?) like from EJScreen point layers or from geoplatform, such as schools locations, etc.  Relevant especially to the ""schools counter"" feature in a separate issue.

",,,https://api.github.com/repos/USEPA/EJAM/issues/235/comments,2/9/2024,8/27/2024,ejanalysis,none,1,0,0,FALSE
105,234,open,MODULE: Points table upload MODULE,refactor|urgency low|server,6208400114|6227891676|7384237694,8F13A1|cfd3d7|25B9F0,Rewrite how code works or break into smaller pieces||removing code from app_server.R,0," **Point table upload module:**  Create a module (server/UI module) that lets a user upload a set of points stored as coordinates (latlon) in a table (similar to how latlon upload works). This would be based on existing functions like latlon_... etc., and the module would replace the server/UI code that enables upload of lat lon points. This would also be usable for purposes other than latlon upload for analysis near facilities - it would also work for upload of points to count, such as schools or hospitals, to be used in a ""schools counter"" feature described elsewhere. Note there was also an issue for typing in latlon that is another method relevant.

",,,https://api.github.com/repos/USEPA/EJAM/issues/234/comments,2/9/2024,8/27/2024,ejanalysis,none,0,0,0,FALSE
106,233,open,"""Schools Counter"" functionality needed (to count schools or other features in each place)",enhancement|refactor|urgency medium|distance-related|shapefile-related,4538805068|6208400114|6227894519|6343333395|6343756696,cfd3d7|8F13A1|FBCA04|C2E0C6|C2E0C6,New feature or request|Rewrite how code works or break into smaller pieces||related to distances variables or calculations or plots|related to polygons/ shapefile/ GIS data/ buffers,1,"""Schools Counter"" - Add ability to count the schools at each site (but really, to count any type of specified points, not just schools): 

Also see separate issues #234 and #235 on creating modules for points upload and using points feature services, to specify a set of points like schools.

- [ ] **New functions:** `countpoints_nearby(), countpoints_in_shape(), countpoints_in_fips()`  etc. Provide functions similar to getblocksnearby(), get_blockpoints_in_shape(), getblocksnearby_from_fips() to be able to count how many of those user-provided points are inside each zone, for nearby (latlon), for in polygon (shapefiles), for in FIPS (e.g., a county), and any other zone types we use.
   - [ ] Do QA/QC to ensure it counts correctly, e.g. compare to EJScreen reports that report number of NPL or other sites nearby.

- [ ] **Enable `doaggregate() and ejamit()` to use those functions** to include those counts 
  - in the site by site outputs of doaggregate() and `ejamit()`
  - in the overall outputs of same

- [ ] **Enable all other functions** to include that info in the web views of short report & site by site report, downloaded short report, downloaded excel site by site and overall, the long word doc, etc. Include unit tests.

- [ ] **Edit web app** to show that new info.

- [ ] Add functions to **visualize (plot)** that info somehow. 

 ","related to proxistat-new branch and the planned ""facility density tool"" etc.",,https://api.github.com/repos/USEPA/EJAM/issues/233/comments,2/9/2024,12/12/2024,ejanalysis,ejanalysis,1,0,0,FALSE
107,232,open,"Develop options for defining the Reference Zone or Ref. Group - avg person vs bg vs ""other 3-mile circles"" - in rural, county, user-defined etc.",enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,0,"Develop options for defining the Reference Zone or Ref. Group - avg person vs bg vs ""other 3-mile circles"" - in rural, county, user-defined etc.

At least 2-3 issues to work on, discuss: 
1. Comparing the avg person vs avg facility (or site) vs avg block group - There is not apples to apples consistent comparison in columns or ratios or percentiles, currently. The state averages in EJScreen for example and the percentiles all are for avg block group or bg percentile, not avg person. Ideally they would be apples to apples, like pop wtd percentiles and averages compared to pop avg near sites, etc. We probably want to allow comparison of ""sites"" not just entirely focus on ""average resident"" but those give very different answers and need to be communicated carefully. 
2. Isn't it technically incorrect to compare scores for avg person within X miles of a site to avg person elsewhere like avg person in state or us? For an apples to apples comparison, you need to compare scores in 3mile circles here versus scores in 3mile circles elsewhere, since avg in a large circle is always less variable than for avg of all residents or avg block, e.g. A score is not drastically different for avg bg in US vs avg person in US, but for larger radius or large FIPS or polygon it can matter a lot! A 10-mile circle or a whole county will never have a very extreme score, while a single block group sometimes will.
3. allow a few **other predefined geo zones** to be the reference zone, not just state and USA, like 
  - county, 
  - rural areas, and 
  - maybe even ""all other places suitable for this type of industry"" or 
  - where other EPA-regulated facilities of all types are located (or versus other residents of US who also live near any type of regulated facility as opposed to the type being analyzed)
4.  allow functions to calculate avg among all other places, everyone else, in state and in US, instead of only using state or us average of everyone -- ""everyone"" includes the analyzed people and places, which should not be in the reference zone or group, especially if the analyzed is a signif fraction of the total state or US or group -- this criticism / suggestion is in the june 2024 SAB comments in their self initiated review of EPA EJ analysis topics, in fact.
5. allow user-defined reference zones? 
5. **Reference Groups** could be used, such as average distance among 
  - group D versus non-D (e.g., Hispanic versus among non-Hispanic), or 
  - versus among one reference group such as NonHispanic White,  or just 
  - versus everyone as a whole, or 
  - not using any reference group for this type of information.",,,https://api.github.com/repos/USEPA/EJAM/issues/232/comments,2/8/2024,6/28/2024,ejanalysis,ejanalysis,1,0,0,FALSE
108,231,open,Minimize startup load time of deployed app / speed / performance,bug|good first issue|urgency high|datasets/ pins/ AWS/ etc.|speed / performance (see #444),4538805065|4538805069|6227890498|6343736234|6535412240,d73a4a|7057ff|D93F0B|0E8A16|e99695,"Something isn't working|Good for newcomers||related to data files via pins board, AWS, dataload_ etc.|related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.",8,"The app as deployed on the posit server takes 5-10 seconds for the UI to appear and be usable. Need to diagnose what is causing this issue and find solutions to cut down on this time as much as possible.

Could be related to 
- EJAM package loading
- pins dataset loading
- server lag time

Can also provide a load screen to indicate that the app is still loading, at least as a short-term solution.","Labelled this as a ""bug"" just to emphasize its priority.|**see more notes at issue #99** |This is still very slow to load from the posit connect server. Unclear if that is always or sometimes. **We have to change it to immediately load an initial web page** while all the other activity gets going like loading packages, loading datasets, building the index, etc.  |When we last investigated this, it seemed to load significantly slower for the first session after a new deployment than for later ones. Perhaps something (data, packages, etc.) gets loaded in the background the first time.

Will take another look and suggest some options.|2024/05/13 15:12:58.434574904 [rsc-session] Content GUID: .....
2024/05/13 15:13:01.123595470 Adding Packrat library to R_LIBS and .libPaths: /opt/rstudio-connect/mnt/app/packrat/lib/x86_64-pc-linux-gnu/4.2.3
2024/05/13 15:13:01.200669367 shiny version: 1.8.0
2024/05/13 15:13:02.256942672 Starting R with process ID: '2138'
2024/05/13 15:13:02.257522947 Shiny application starting ...
2024/05/13 15:13:02.349568890 Loading required package: EJAMbatch.summarizer
2024/05/13 15:13:02.785633567 Loading required package: EJAMejscreenapi

   **[ ALMOST 8 SECONDS USED HERE - just loading EJAMejscreenapi took that much time? or what? why ? ]**

2024/05/13 15:13:10.051838375 Now running .onAttach(), as part of attaching the EJAM package.
...
2024/05/13 15:13:10.599301248 **Successfully connected to Posit Connect pins board.**
2024/05/13 15:13:10.606041889 blockpoints   - is NOT in memory. Checking local disk... blockpoints  is NOT found locally on disk at /opt/rstudio-connect/mnt/packrat/4.2.3/v2/library/EJAM/a9e6b81632161bcddbc73ec353de10b7/EJAM/data/blockpoints.arrow 
2024/05/13 15:13:10.606629390 
2024/05/13 15:13:10.606767757 blockpoints  is NOT found locally on disk at NOTCHECKINGLOCAL/blockpoints.arrow 
2024/05/13 15:13:10.606806159 trying to load blockpoints  from EJAM/blockpoints.rda 

  ** TOOK ALMOST 5 SECONDS JUST TO LOAD blockpoints  -- why is it loading the .rda version not .arrow pins board version?** 

2024/05/13 15:13:15.097785402 
2024/05/13 15:13:15.098032603 blockwts      - is NOT in memory. Checking local disk... blockwts    is NOT found locally on disk at /opt/rstudio-connect/mnt/packrat/4.2.3/v2/library/EJAM/a9e6b81632161bcddbc73ec353de10b7/EJAM/data/blockwts.arrow 
2024/05/13 15:13:15.098130878 
2024/05/13 15:13:15.098252003 blockwts    is NOT found locally on disk at NOTCHECKINGLOCAL/blockwts.arrow 
2024/05/13 15:13:15.098287513 trying to load blockwts  from EJAM/blockwts.rda 

**[ ABOUT 2.5 SECONDS USED HERE LOADING THE .rda VERSION OF blockwts ??? WHY NOT pins board .arrow ?? ]**

2024/05/13 15:13:17.295810259 
2024/05/13 15:13:17.296333457 quaddata      - is NOT in memory. Checking local disk... quaddata    is NOT found locally on disk at /opt/rstudio-connect/mnt/packrat/4.2.3/v2/library/EJAM/a9e6b81632161bcddbc73ec353de10b7/EJAM/data/quaddata.arrow 
2024/05/13 15:13:17.296471528 
2024/05/13 15:13:17.296600454 quaddata    is NOT found locally on disk at NOTCHECKINGLOCAL/quaddata.arrow 
2024/05/13 15:13:17.296630190 trying to load quaddata  from EJAM/quaddata.rda 

**[ABOUT 10 SECONDS USED UP HERE loading another .rda file  !]**

2024/05/13 15:13:36.087016356 Building index of Census Blocks (localtree)...
2024/05/13 15:13:37.557423341   Done building index.
2024/05/13 15:13:37.597073486 For help using the EJAM package, try ?EJAM or see https://usepa.github.io/EJAM/index.html

  **[ ABOUT 3 SECONDS HERE --    WHY]**

2024/05/13 15:13:40.952196321 
2024/05/13 15:13:40.952226203 Attaching package: EJAM

2024/05/13 15:13:41.036864601 Listening on http://127.0.0.1:34001

  **[ ABOUT 8 SECONDS HERE -   WHY? Maybe the shiny app itself starting up? but 8 seconds is a LOT - figure out why ]**

2024/05/13 15:13:49.522932710 shiny.testmode == TRUE
2024/05/13 15:13:49.556322011 current_upload_method reactive is  latlon 

  [ ABOUT 30 SECONDS HERE IS PROBABLY JUST THE USER STARTING TO UPLOAD THEIR POINTS FILE ]

2024/05/13 15:16:01.415632131 ROW COUNT IN FILE THAT SHOULD provide lat lon:  1857 |Closing |Reopening the issue now that it is deployed to production & load time is again an issue. |My concern now would be if there are problems with the public deployed app when multiple users try to use it concurrently.",,https://api.github.com/repos/USEPA/EJAM/issues/231/comments,2/7/2024,1/10/2025,mlfurman3,none,0,1,0,TRUE
109,221,open,"in web app, add ways to analyze multiple radii at once or even continuous radius",enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,1,"Needs to be in web app.  This is already possible in functions like [ejamit_compare_](https://usepa.github.io/EJAM/reference/ejamit_compare_distances.html)
as in the examples shown at https://usepa.github.io/EJAM/articles/4_advanced.html#how-to-analyze-proximity-using-ejam  

How we might show results:
- see examples in the article/vignette ... show about 3 radii side by side in a new type of table and plot of just 1 or a few key indicator results.
- interactively explore sensitivity to radius?
- the code figures out sensitivity and summarizes what distance shows max disparity, e.g., and flags whether results are highly sensitive to distance, etc.

How people might specify and use it:  (not final decisions but ideas) and how to efficiently implement each:
- **Preselected Distances and points**:  app could offer only/mostly some preselected cached distances and results for FRS sites like ECHO does - faster and easier for user and discourages overly short radii. Use preselected cached distances and results for FRS sites (like ECHO does). custom radius or custom point would be separate feature. no code exists yet for this idea but ultimately would provide a better user experience since so fast.
- **2 or 3 key distances**:  The easy-to-implement, simple way is we only analyze 2-3 radii, and analyze each discrete distance on the fly separately as via  `ejamit_compare_distances()`  - This is already coded but not in web UI, but kind of inefficient since it repeats work as it analyzes each radius separately. functions already exist. see https://usepa.github.io/EJAM/articles/4_advanced.html#within-multiple-distances---comparing-radius-choices  a) User could specify 1 max radius, and then tool would check subsets of that (discrete like 2,3,4 miles or else ""continuous"" distance via bybg) b) User could specify 2-5 discrete radii at once.
- **Explore various discrete distances on the fly?:** another related option is they specify one max radius and we run that and save the huge sites2blocks output of getblocksnearby() so we/they can then compare results for smaller radii after the fact, by on-the-fly using doaggregate's radius parameter to aggregate just subsets of all blocks found earlier. would want to check how much faster that really is. That approach allows us to show block-level resolution of what happens as function of continuous distance. at the BLOCK resolution by retaining the info in sites2blocks from getblocksnearby() ...  to retain all the output of getblocksnearby() which is huge but then could filter it to run doaggregate on various subsets - but that only saves the time of running getblocks and still means running doagg for each distance...
- **Block Groups for stepwise distance**: another option is they specify one max radius and run doaggregate on the full distance, saving the bybg table that stores info on each blockgroup -- then on the fly they can see results for a subset radius and/or  as a somewhat-continuous distribution of all radii - maybe interactively adjusting radius, or just in plots showing how X changes depending on the radius (like we already can do via the results_bybg_people at the blockGROUP resolution).
- **BLOCKS for Continuous Distance:** another option is higher-resolution more ""continuous"" block resolution, on the fly - this is like what is done by plot_distance_by_pctd() already. see https://usepa.github.io/EJAM/articles/4_advanced.html#how-demographics-at-one-site-vary-as-a-continuous-function-of-distance 
","There are at least 3 separate questions here: 
**1. When to calculate or retain big tables of distance info:** when/ whether to precalculate or cache or just retain for some process steps, like while an analyst is working with one set of places.
2. **Resolution: blocks vs bg vs bins**: do we save all the details like sites2blocks table versus just blockgroup rollup of distance of avg person per bg. Possibly even retaining binned distances only, like info about those 0-1 miles away, 1-2 miles away, etc.
3. **How to summarize** the info, what to show in plots of various kinds and in tables. Showing continuous distribution of distance? Showing bins of distance? Cumulative versus at each distance (annular/ ring view)? Showing distance by group versus %D or E by distance, or both? ",,https://api.github.com/repos/USEPA/EJAM/issues/221/comments,2/2/2024,12/13/2024,ejanalysis,ejanalysis,1,0,0,FALSE
110,219,open,still too slow when running 10k points like the program egrid facilities,enhancement|refactor|urgency low,4538805068|6208400114|6227891676,cfd3d7|8F13A1|cfd3d7,New feature or request|Rewrite how code works or break into smaller pieces|,0,,,,https://api.github.com/repos/USEPA/EJAM/issues/219/comments,2/2/2024,2/2/2024,ejanalysis,none,0,0,0,FALSE
111,218,open,"analysis of FIPS is too slow, espec for whole counties like all 3 in Delaware takes 15 seconds",enhancement|urgency low|shapefile-related|speed / performance (see #444),4538805068|6227891676|6343756696|6535412240,cfd3d7|cfd3d7|C2E0C6|e99695,"New feature or request||related to polygons/ shapefile/ GIS data/ buffers|related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.",0,"profile to see where is bottleneck.
we could greatly speed up doaggregate or replace it since we don't need to work with blocks at all for analysis of counties as places
we could cache some info like which block groups form each county, 
we could avoid using getblocks... entirely
",,,https://api.github.com/repos/USEPA/EJAM/issues/218/comments,2/2/2024,9/5/2024,ejanalysis,none,0,0,0,FALSE
112,216,open,find a way to map more polygons (than just 159 cap),enhancement|urgency medium|maps-related|shapefile-related,4538805068|6227894519|6228710425|6343756696,cfd3d7|FBCA04|C2E0C6|C2E0C6,New feature or request||related to maps|related to polygons/ shapefile/ GIS data/ buffers,0,there should be a way to fuzz up the polygons to show approximated low res versions of them in a preview map and maybe the final map too. the sf package can do that - can't recall name of that operation or function,,,https://api.github.com/repos/USEPA/EJAM/issues/216/comments,2/2/2024,2/2/2024,ejanalysis,none,1,0,0,FALSE
113,215,open,allow user to see the newer more flexible barplot ratios functions and to interactively change parameters so they can plot whatever variables etc.,enhancement|urgency medium|plots-graphs-related,4538805068|6227894519|6235793514,cfd3d7|FBCA04|C2E0C6,"New feature or request||related to plotting/graphing like histo, bar, box, scatter",0,,,,https://api.github.com/repos/USEPA/EJAM/issues/215/comments,2/2/2024,2/2/2024,ejanalysis,none,1,0,0,FALSE
114,214,open,set up alerts that monitor and alert staff when the app goes down - ensure available,enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,2,,Some info here: [https://docs.posit.co/connect/user/scheduling/#failure-notifications](https://docs.posit.co/connect/user/scheduling/#failure-notifications)|Not applicable to current application,,https://api.github.com/repos/USEPA/EJAM/issues/214/comments,2/2/2024,2/10/2025,ejanalysis,none,1,0,0,FALSE
115,212,open,enable other units like kilometers for entry of radius,enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,0,"make it possible to enter radius in kilometers as an option, not just miles. short term fix is issue #211 
Many people want to enter 5 km, for example, or 10 or 50 km.",,,https://api.github.com/repos/USEPA/EJAM/issues/212/comments,2/2/2024,2/2/2024,ejanalysis,none,1,0,0,FALSE
116,211,open,allow user to type in radius not only use slider,enhancement|good first issue|urgency high-ish but not a bug,4538805068|4538805069|7539794549,cfd3d7|7057ff|B9463A,"New feature or request|Good for newcomers|for high urgency enhancements, to rank them just below high urgency bugs",6," 

Something like this approach below (from https://github.com/USEPA/EJAMejscreenapi/blob/main/R/app_ui.R ) should be used in EJAM to allow users to provide radius as either a slider or typed in number, _while still carefully retaining all the logic (probably spread out in a few spots) that changes or limits the radius for cases like FIPS, Shapefile, vs other._

```

## pick a radius ####
	        
	        conditionalPanel(
	          condition = ""input.slider_vs_text_radius == 'use_slider'"",
	          shiny::uiOutput('radius_slider')
	        ),
	        conditionalPanel(
	          condition = ""input.slider_vs_text_radius == 'type_in'"",
	          shiny::uiOutput('radius_textbox')
	        ),
	        shiny::radioButtons(""slider_vs_text_radius"",  label = NULL, choices = list(`Type in radius` = ""type_in"", `Use slider` = ""use_slider""), inline = T), # 

```","people have asked for this and often need to use a value that is exactly 5 kilometers which they can only do if they can type in 3.11 miles. (longterm we probably want to enable other units like kilometers for entry of radius - will create issue #212 .)|What do we all think about 
- slider only versus 
- typed in radius only versus (better than slider if you have to pick just one??)
- offering both options (ejscreenapi shiny app has code for this... that lets you flip between typing and slider.)

Pros and cons

- Slider is nice as 
  - you can see how it looks as you adjust it at one site. 
  - And the max and min are visible/more obvious.
- Typing is nice in that 
  - decimals in precise values can be used without making the slider increment small and needing debounce and
  - no fiddling needed to specify exact number you want like 3.106856 miles which is 5 km
- Both is nice because you get all that, but it makes the interface slightly less simple and clean looking|@saradelessio-abt going to need UI input on this ticket.|@leeeddie424 

The rShiny slider doesn't include a text input, but we could consider showing the slider by default since that is the most common use case, and allow users to switch to the text input if they need to enter more precise values. Like this:

<img width=""767"" alt=""Screenshot 2024-08-15 at 12 41 00 PM"" src=""https://github.com/user-attachments/assets/d09c03af-3c39-4f1f-96c5-6f92e206aa73"">
|CC: @mlfurman3 |@saradelessio-abt will revisit with you at some point",,https://api.github.com/repos/USEPA/EJAM/issues/211/comments,2/2/2024,11/26/2024,ejanalysis,saradelessio-abt,0,1,1,FALSE
117,210,open,web app timeout is too short/fast,bug|good first issue|urgency low,4538805065|4538805069|6227891676,d73a4a|7057ff|cfd3d7,Something isn't working|Good for newcomers|,3,"server settings control this - connection timeout is supposedly set at 3600 seconds, which is 60 minutes, but it seemed to timeout within a couple of idle minutes. confirm that and fix if needed.","timeout after 5 minutes of idle is too fast but leaving session open for >15 minutes of idle seems wasteful? If that is preventing others from using the app concurrently then make it timeout at 15 minutes. If open idle sessions do not matter then leave it open for 20-30 minutes.|@ejanalysis we set the configurations to be the same as the staging server, are there still problems?|Not applicable to current application.",,https://api.github.com/repos/USEPA/EJAM/issues/210/comments,2/1/2024,2/10/2025,ejanalysis,mlfurman3,0,0,0,FALSE
118,202,open,"improve use of global environment, data files, global.R, and maybe even param/config settings ",refactor|urgency low|datasets/ pins/ AWS/ etc.,6208400114|6227891676|6343736234,8F13A1|cfd3d7|0E8A16,"Rewrite how code works or break into smaller pieces||related to data files via pins board, AWS, dataload_ etc.",0,"
A very long list of global variables/objects and also ""parameters"" are loaded or set, and in a many different ways 
1. Many variables are set up by the global.R files from 2 pkgs (EJAM and EJAMejscreenapi), via a workaround sourcing them from run_app()
2. Others are set up by dataload_from_pins(). 
3. Others are lazy loaded because they are files in EJAM/data/ 
4. Some code checks if an object exists and might be checking specifically only in the global environment.
5. options() might be used (as is done in app.R)
6. golem's config file might get used? see  app_sys(""golem-config.yml"") 
7. Environment variables might be used? by local Rprofile or Renviron files? by Posit Connect server?
8. some settings are handled via parameters in .Rmd yaml headers
9. some settings are handled via the advanced tab
10. some settings are handled via each function's default values for its parameters 
11. Some ""settings"" are the metadata in the xlsx that creates map_headernames, such as the desired sort order of indicators on a report, how many decimal places to use, etc.

This seems complicated and messy and has some disadvantages:
- In general, people suggest global variables should be avoided where possible.
- A package with a lot of MB of data in /data/*.rda  is too large to quickly rebuild, share, submit to CRAN, etc.
- They are hard to keep track of because they are created in at least 3 different ways, making code error prone (and debugging is more complicated)
- updates and changes to settings or behavior is harder (not as clear where you would look to make a given change)
- documentation is harder/ complicated
- It creates challenges if an analyst wants to use the package without the app, since they might require some variables that are only created when the app sources global.R 
- it could create a lot of objects that can clutter the RStudio analyst's envt, espec if they run the app locally and then stop to do some work in RStudio console. 

Ideas:
1. One option is just leave this all as-is, because changing any of this takes effort and would need to be worth it.
2. These issues are spread out across the EJAM package, and ejscreenapi modules in EJAM pkg, and code in EJAMejsceenapi. Most could be consolidated into one package. That seems relatively easy. map_headernames in particular seems out of place being outside EJAM package.
3. Larger datasets, actual tables etc., should all be in one place, probably, such as pin board not /data/ etc.?
4. These could be consolidated into fewer approaches, like phasing out use of global.R. Or maybe phasing out use of files in /R/data/ ?
5. Should we use a special environment to put global variables into, rather than global env?  See  `cat(""\n\n"", paste0(example(topic = ""sys.source"", give.lines = TRUE), collapse = ""\n""))`  Good overview of environments is here: https://adv-r.hadley.nz/environments.html 
6. maybe the .Rmd yaml parameters should depend entirely on some other unified source of parameters/settings, so we never need to update anything within the .Rmd docs.
7. not sure if there are pros/cons of using golem-config.yml, or options() or environment variables.
8.  there probably are more/better ideas for these issues.",,,https://api.github.com/repos/USEPA/EJAM/issues/202/comments,1/28/2024,1/28/2024,ejanalysis,none,0,0,0,FALSE
119,201,open,"add FIPS option to  ejscreenapi1, ejscreenapi, ejscreenapi_plus(), ejscreenit,  etc.",enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,0,"**add FIPS option to  ejscreenapi1, ejscreenapi, ejscreenapi_plus(), ejscreenit,  etc.**

FIPS works at the lowest level functions in EJAMejscreenapi like these:
`ejscreenRESTbroker()` already has parameters that allow a query of 1 blockgroup instead of 1 latlon point, such as
`ejscreenRESTbroker(fips = ""360810383010"")`  for a blockgroup, compiled like this:
`ejscreenRESTbroker2table(ejscreenRESTbroker(fips = ""360810383010""))`

But, that is needed in the next level up of functions, and should be vectorized to handle multiple FIPS just like it handles multiple points.
Need is for these functions:  ejscreenapi1, ejscreenapi, ejscreenapi_plus(), ejscreenit,  etc.
Perhaps the parameters could be similar to how ejamit() already handles this via `EJAM::ejamit(fips = )
`
Also note that 
`url_ejscreen_report()` already can handle FIPS, such as
`browseURL( url_ejscreen_report(areatype = ""county"", areaid = ""36081"") )` for a county
and
`url_ejscreen_report(areatype = ""blockgroup"", areaid = ""360810383010"")` for a blockgroup
but they should have used fips as the parameter name to be consistent, not areaid that the API itself uses.",,,https://api.github.com/repos/USEPA/EJAM/issues/201/comments,1/28/2024,9/4/2024,ejanalysis,none,0,0,0,FALSE
120,197,open,EJAM & EJScreen report on avg PERSON generally but State Average or US Avg shown is avg BLOCK GROUP ! Decide how to reconcile this.,bug|good first issue|urgency low|calculate/validate to EJScreen,4538805065|4538805069|6227891676|6343712128,d73a4a|7057ff|cfd3d7|FBCA04,"Something isn't working|Good for newcomers||related to errors in numbers, replicating EJScreen stats",1,"**The Issue**

- In EJAM we display the **State Avg and US Avg** values (as reference columns and as ratio denominators and maybe on plots) as taken from usastats or statestats, which actually provides averages that are for the avg _Blockgroup_ not avg person. 
- In EJAM when we calculate and display the **Average Overall or for 1 site analyzed**, we have been showing numbers on the _average resident_, via pop wtd avg of each indicator. 
- In **EJScreen if you run a report** on site near a point, it does use the wtd mean like EJAM does... the population (or other denominator like residents age 25+ or households) weighted average of each indicator, NOT the average Blockgroup.
- In EJScreen if you run a report on a County, check what it reports.

For a circular buffer, this distinction is not obvious on a report, but even so the comparison of avg person near site versus avg block group in the State is not really a ""fair"" comparison. At least it is misleading. Especially if you use Ratio of avg person here to avg block group in US, or avg bg in State.  

The problem is also very obvious and confusing _if you run an analysis comparing all the counties in 1 State_, such as 
x <- ejamit(fips = fips_counties_from_statename(""Alabama"")) or in shiny using the Alabama counties test data. In that case, you see two columns side by side that both should be the Alabama average, but they are noticeably different numbers.

The problem is broader actually, since it applies to _percentiles_ also - all percentiles shown are as percent of blockgroups not people. That probably will NOT be changed in EJAM, since it is not a huge difference except in tails, I believe and is hard to explain. Worth discussing with EPA analysts. 

**What to do?**
- At a minimum we need a footnote explaining why averages differ at least when someone analyzes all places that comprise a state, like all counties compared. 
- We might want that explanation all the time
- Alternative is to show State Avg column that is Avg Resident in State, which is better but not what EJScreen report shows. Communication problem. I'm leaning towards showing true average resident not the EJScreen approach. 
- For RATIOS to State or US Average, we should use avg person not blockgroup. But that argues further for not even showing the avg blockgroup numbers.



**Details**
- confirmed that average column on report is drawn from and identical to 
 ` t(statestats[statestats$REGION == ""AL"" & statestats$PCTILE == ""mean"",  ""traffic.score""])`
- Did this:
```
 x <- ejamit(fips = fips_counties_from_statename(""Alabama"")) 

> x$results_overall$traffic.score
[1] 67.32871
> weighted.mean(x$results_bysite$traffic.score, w = x$results_bysite$pop, na.rm = TRUE)
[1] 67.32871
> mean(blockgroupstats$traffic.score[blockgroupstats$ST == ""AL""],na.rm = TRUE)
[1] 79.12364
> statestats[statestats$REGION == ""AL"" & statestats$PCTILE == ""mean"", 'traffic.score']
[1] 79.12364

> mean(blockgroupstats$traffic.score[substr(blockgroupstats$bgfips,1, 5) ==  ""01073""], na.rm = T)
[1] 164.7956
>     weighted.mean(blockgroupstats$traffic.score[substr(blockgroupstats$bgfips,1, 5) ==  ""01073""], w = blockgroupstats$pop[substr(blockgroupstats$bgfips,1, 5) ==  ""01073""])
[1] 129.5103
data.frame(x$results_bysite$traffic.score, x$results_bysite$pop)[ 37, ]

browseURL(url_ejscreen_report(areatype = ""county"", areaid = ""01073""))
```
Also, fyi, confirmed population totals for state reported are what is expected, `sum(blockgroupstats$pop[blockgroupstats$ST == ""AL""])`",@ejanalysis is this ticket okay to be closed or is there further action required?,,https://api.github.com/repos/USEPA/EJAM/issues/197/comments,1/23/2024,1/7/2025,ejanalysis,ejanalysis,0,0,0,FALSE
121,193,open,"globally in all packages change ""longname_tableheader"" to just ""longname"" and ""shortlabel"" to ""shortname""",refactor|urgency low,6208400114|6227891676,8F13A1|cfd3d7,Rewrite how code works or break into smaller pieces|,0,"- change in xlsx, 
- rerun datacreate_map... etc., reinstall to use that new map_headernames data object
- change in vignettes, 
- in R code, especially in fixcolnames() and related functions fix... 
- redo devtools::document(), 
- redo pdf help, 
- redo html help, 
- etc.",,,https://api.github.com/repos/USEPA/EJAM/issues/193/comments,1/20/2024,1/20/2024,ejanalysis,ejanalysis,0,0,0,FALSE
122,192,open,"IMPROVE LONG NAMES OF INDICATORS (long/friendly names, table headers)",documentation|enhancement|good first issue|urgency medium|calculate/validate to EJScreen,4538805066|4538805068|4538805069|6227894519|6343712128,C5DEF5|cfd3d7|7057ff|FBCA04|FBCA04,"Improvements or additions to documentation|New feature or request|Good for newcomers||related to errors in numbers, replicating EJScreen stats",3,"### Redo the long/friendly names of variables used for table headers (not the short labels used in plots, etc.)

Redo the names in lists like names_d etc., in EJAM\data-raw\datacreate_names_of_indicators.R for consistency, logical naming structure/ predictability, clarity, brevity, etc.

### Goals
1) ensure 100% consistency between map_headernames$names_friendly, $varlist, $longname_tableheader, 
versus the names_xyz lists, and the namez$ approach if will keep using it; and 
2) make names more predictable/ based on a logical approach to name construction, to make it easier to find/replace/update names and make it easier to construct a name from its components for QA/QC and flexibility and ease of updates; 
3) use plain English and ensure clarity, no ambiguity (e.g., is it a count or fraction, is it US or State or other, is the denominator explicit or at least reasonably obvious, etc. However, we cannot provide a truly complete explanation of each indicator and people need to refer to documentation sometimes for details like data source, vintage, maybe the exact denominator (universe), maybe even for units? Not sure we always need to show units like for proximity scores that have long descriptions of units.
4) keep them from getting extremely long where feasible without loss of clarity.
5) retain in map_headernames the columns preserving the indicator names text copied from and exactly as labelled in: EJScreen reports, glossary, metadata in API, etc.
6) (sorting them is easier and useful? But whether US or State is the first word rather than Average or Percentile or Count, you still have metadata in map_headernames that lets you filter and sort easily.)

The datacreate file's naming of ""friendly"" labels seemed like a good starting point, since it was more consistent and careful in many cases than what was in map_headernames names_friendly column and longname_tableheader column.
The commented lines in datacreate_names_of_indicators.R that say   #  dput(
were just put there as a way to switch to using map_headernames as the source for EJAM variable name lists which would keep them consistent....  dput in datacreate names of indicators was to change all to the maphead$ longnames versions of friendly names, 

### Need to make the changes in this sequence
- In names_xyz, namez$xyz, and map_headernames (long and friendly columns), make capitalization consistent (thus simplifying global find/replace, etc.), by 1st making it all lowercase (then doing search/replace fixes below, then semi-manually fixing capitalization as the last step - lots of changes would be needed, done manually probably)
- (*****_somewhere_**?) do replacements globally (where??? ***) to fix certain words / **replacements listed below**.
- use a table of variables as created via the bit of script in EJAM/data-raw/datacreate_names_of_indicators.R datacreate_names of indicators, the table called ""out"", as a way to look at, compare, and select which to use as long/friendly and check things
- (*****_manually_**??) copy the best version of each name into the spreadsheet map_headernames (the long and friendly columns)
- run script  EJAMejscreenapi/data-raw/datacreate_map_headernames.R
- reinstall EJAMejscreenapi package
- run script  EJAMejscreenapi/data-raw/datacreate_testoutput_ejscreenit_or_ejscreenapi_plus_50.R
- reinstall EJAMejscreenapi again 
- test EJAMejscreenapi package
- run EJAM/data-raw/datacreate_testpoints_testoutputs.R ... and other related datacreate_ files   
- reinstall EJAM package
- test EJAM package 

### Global search/ replace changes to make (in both/all sources of long/friendly names)
 - make all lowercase to facilitate search/ replace and fix caps at the end of all this
 - replace percent (but not -ile not -age) with %  
 - replace percentage with % 
 - replace avg with average etc.
 - replace hhlds or hhld with households or household
 - replace ""Count of"" with ""Number of"" as plain english term and more consistent.
 - consider if/when can replace ""average for"" with ""average"" (confirm it always makes sense to do so, percentile for)
 keep ""percentile"" with ""percentile"" 
 - replace ""National"" with ""US""
 - ""Percent of population speaking"" should be ""% speaking""
 - things like ""... Average of Persons with Disabilities"" should more clearly say ""... Average of % with Disabilities"" (but keep count/number of persons with ..., and ... Average of Households without ...)
 - THERE ARE PROBABLY OTHERS THAT MAKE SENSE ... LOOK AT LISTS OF TERMS AFTER THOSE EDITS ARE DONE
","just note #20 is somewhat related|This is 95 % finished now. There are some quirks in some of the shortlabel or long versions of names in map_headernames still, so they need a final check and then this can be closed.|@mlfurman3 ",,https://api.github.com/repos/USEPA/EJAM/issues/192/comments,1/20/2024,10/7/2024,ejanalysis,ejanalysis,1,0,0,FALSE
123,190,open,include AREA (square miles area) as an output for SHAPEFILE and FIPS analyses too,enhancement|good first issue|shapefile-related|urgency high-ish but not a bug,4538805068|4538805069|6343756696|7539794549,cfd3d7|7057ff|C2E0C6|B9463A,"New feature or request|Good for newcomers|related to polygons/ shapefile/ GIS data/ buffers|for high urgency enhancements, to rank them just below high urgency bugs",0,"""Area of Circular Buffer in Square Miles"" is a column in ejscreenit()$table, and perhaps also in ejamit()$results_bysite etc tables... but what if it is an analysis of polygons or FIPS rather than circular buffers? Someone already has asked for area of polygon to be added.
- For FIPS, easiest is to sum area of all blocks or block groups in the FIPS unit, since they are all-or-nothing included.
- For Shapefile analysis, probably need to use sf::st_area() 

(Related issue #191  is that ""Area of Circular Buffer in Square Miles"" is not general enough for this usage, so see other issue for that)",,,https://api.github.com/repos/USEPA/EJAM/issues/190/comments,1/20/2024,9/30/2024,ejanalysis,ParkerJanMalek,0,1,1,FALSE
124,189,open,lat lon Latitude Longitude duplicative indicators in ejscreenit()$table,enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,0,"why are lat and lon colnames of ejscreenit()$table, and maybe other outputs like ejscreenapi(), but also Latitude and Longitude are there? duplicative? Does ejamit() etc. do that?",,,https://api.github.com/repos/USEPA/EJAM/issues/189/comments,1/20/2024,1/20/2024,ejanalysis,none,0,0,0,FALSE
125,188,open,Fix use of mapping_for_names parameter,enhancement|refactor|urgency low,4538805068|6208400114|6227891676,cfd3d7|8F13A1|cfd3d7,New feature or request|Rewrite how code works or break into smaller pieces|,0,"Fix this messy treatment of mapping_for_names parameter in both packages: 
mapping_for_names is param of ejscreenapi_plus etc. but is not passed to 
  ejscreenapi() which lacks that option as a param, and which
 assumes the presence of map_headernames directly by that name,
 AND also it calls fixcolnames() without specifying mapping of names, e.g. here:
  if (drop_redundant_indicators) {
    results <- results[, !(names(results) %in% map_headernames$api_synonym)]
  }
  if (nicenames) {
    names(results) <- fixcolnames(names(results) , ""api"", 'long') # but downstream functions mostly expect rname format
  }

",,,https://api.github.com/repos/USEPA/EJAM/issues/188/comments,1/20/2024,1/20/2024,ejanalysis,none,0,0,0,FALSE
126,186,open,valid msg per site should distinguish bad lat/lon vs no block point within radius,enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,1,"sometimes user provides invalid or NA lat/lon values.
sometimes they are valid but the location has no block point nearby since radius is small relative to block it is in. 
The message column in outputs should say which is which.","@ParkerJanMalek this should be done for non-fips, but please check.",,https://api.github.com/repos/USEPA/EJAM/issues/186/comments,1/18/2024,12/2/2024,ejanalysis,mlfurman3,1,0,0,FALSE
127,184,open,Enable download of 'Plot of Average Scores' and 'Plot Full Range of Scores' plots,urgency low|plots-graphs-related,6227891676|6235793514,cfd3d7|C2E0C6,"|related to plotting/graphing like histo, bar, box, scatter",0,Add buttons to allow downloads of the plots from the 'Plot of Average Scores' and 'Plot Full Range of Scores' tabs.,,,https://api.github.com/repos/USEPA/EJAM/issues/184/comments,1/12/2024,1/12/2024,mlfurman3,none,0,0,0,FALSE
128,183,open,downloading excel output with plots for 1000-2000 points takes 10-15 seconds,urgency low,6227891676,cfd3d7,,0,"Profile the functions to see if it's the conditional formatting or plotting that slows it down. Check to see if it happens with large datasets without plots.
",,,https://api.github.com/repos/USEPA/EJAM/issues/183/comments,1/12/2024,1/12/2024,sarasoko,none,0,0,0,FALSE
129,182,open,Update long report to use new Community Report info,urgency medium|LongReport_output,6227894519|6954028026,FBCA04|304702,|static word doc TSD on results of ejam run - via Quarto template,0,"The app creates a long word document report. As of now, it still uses old versions of indicator tables from the previous summary report. We need to adjust app_server.R and the long report Rmd document to accept the new EJScreen community report formatted tables as shown in the results page.",,,https://api.github.com/repos/USEPA/EJAM/issues/182/comments,1/10/2024,5/15/2024,mlfurman3,none,1,0,0,FALSE
130,180,open,Refactor community report functions arguments and named vectors,refactor|urgency medium|server,6208400114|6227894519|7384237694,8F13A1|FBCA04|25B9F0,Rewrite how code works or break into smaller pieces||removing code from app_server.R,4,"Based on comments to PR #170, the following changes need to take place for reformatting the community report helper functions:

- add list of columns to round using named vectors:
` x100varnames = c(names_d, names_d_avg, names_d_state_avg, names_d_subgroups, names_d_subgroups_avg, names_d_subgroups_state_avg, ""pctdisability"",  ""p_own_occupied"", ""pctunder18"", ""pctover17"", ""pctmale"", ""pctfemale""))`

- ""var_value"" is a bad choice for this parameter since it represents the R variable name (e.g., ""pm"") not the value (e.g., 7). Maybe use rname or varname. Then the friendly name could be called longname. This comment applies to a few functions in this file.

- Remove for loops in favor of vectorized code: Maybe this is not a bottleneck and profiling would reveal that, but wouldn't it be better to vectorize these functions in a more ""R-like"" fashion, so that you call it once to handle a list of indicators, and it would not use for loops at all?

- The hard-coded variables should be replaced with a generic approach, one that is easier to update each year as the lists of indicators change. One solution is there could be function parameters like
evarnames = names_e, evarlongnames = fixcolnames(evarnames, 'r', 'long'),
dvarnames = c(names_d, names_subgroups), dvarlongnames = fixcolnames(dvarnames, 'r', 'long'),
and then further down the code would say
var_values_e <- evarnames instead of listing them in the code

- ensure that all named vectors are used in proper places - multiple instances of missing indicators, such as `names_e` or `names_d_subgroups`

- replace text describing numbers of indicators with more generic text
    - ""There are thirteen EJ indexes and supplemental indexes in EJScreen reflecting the 13 environmental indicators.""
should be written to be more generic so we don't have to edit it each year they decide to revise the count of indicators:
""For each of the environmental indicators in EJScreen, there is an EJ Index and a Supplemental EJ Index.""
    - ""They combine data on percent low-income, percent linguistically isolated, percent less than high school education, percent unemployed, and low life expectancy with a single environmental indicator.""
This is likely to change in the next EJScreen update, so it would be easier to just say, ""Each one combines the Demographic Indicator with a single environmental indicator.""","Some relevant work was in progress in the community_report branch ...|@DougMoy please see **community_report** and **issue-180-report-refactoring** branches |I have a branch: https://github.com/USEPA/EJAM/tree/issue180

, but we need to add functions to a formatting function for rounding/sigfigs|@DougMoy  revisit when we restart refactoring",,https://api.github.com/repos/USEPA/EJAM/issues/180/comments,1/9/2024,12/2/2024,mlfurman3,DougMoy,1,0,0,FALSE
131,178,open,Rename community report functions with common convention,documentation|refactor|urgency low|server,4538805066|6208400114|6227891676|7384237694,C5DEF5|8F13A1|cfd3d7|25B9F0,Improvements or additions to documentation|Rewrite how code works or break into smaller pieces||removing code from app_server.R,1,"This does not have to be done immediately, but perhaps all the report-related functions can be called  `report_...` I see new functions called `build_community..` and  `fill_ ...` and `generate_...` etc.  and would like to see an issue created that notes we would like to globally rename those so that we make all related functions start with the same carefully selected word, as was done for the `latlon_` suite of functions, `fips_` functions, `table_` functions etc.  ",@DougMoy revisit during refactoring,,https://api.github.com/repos/USEPA/EJAM/issues/178/comments,1/9/2024,11/22/2024,mlfurman3,none,0,0,0,FALSE
132,175,open,Improve MACT-related  lat lon data,enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,0,"Improve MACT subpart lat lon data:  
2979/5052 sites in the MACT list lack lat/lon info. 

1. Confirm FRS really lacks those and it is finding the right sites by mact; then 
2. see if we have street addresses at least and if so, 
3. use geocoding of street addresses to obtain lat/lon info online - either
    a. Up front and saved as a dataset or
    b. on the fly as needed when user queries a particular MACT subpart (but do it in the functions supporting mact analysis, not just in the server code).

",,,https://api.github.com/repos/USEPA/EJAM/issues/175/comments,1/7/2024,1/7/2024,ejanalysis,none,0,0,0,FALSE
133,169,open,joining FIPS upload data to preview table,enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,0,"Only FIPS codes are retained from the upload file. Everything else is not displayed in the preview and does not get included in the output file. 

",,,https://api.github.com/repos/USEPA/EJAM/issues/169/comments,1/4/2024,1/4/2024,sarasoko,none,1,0,0,FALSE
134,163,open,"Enable analysis of VERY large numbers of points - test limits and code solutions like batching, etc",enhancement|good first issue|tasklist|urgency medium|speed / performance (see #444),4538805068|4538805069|6148808139|6227894519|6535412240,cfd3d7|7057ff|8E5406|FBCA04|e99695,"New feature or request|Good for newcomers|single issue containing a list of sub-tasks or sub-issues||related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.",1,"EJAM has a few points where it will fail or perform very badly / slowly once you go past 1,000 points and past 5 miles radius, for example. 

We need to 
1) **test bounds** to learn at what points the various components start to fail (**THIS STEP IS SOMEWHAT URGENT & is essentially a bug - need to know what the boundaries are for _what should be allowed or warned about_, until we have time to handle pushing those bounds)**. The problems probably start to occur when you have a combination of large R and large N, and probably scales linearly with N but as the square of R since the number of block points grows with area which is proportional to R squared. 
2) **adjust the caps**: as interim fix, put in caps that do not allow a user to run Radius > RMAX and point count > NMAX. We already have done this but might want to adjust those caps based on step 1 (testing bounds a little more methodically).
3) **warn users** about the RSLOW and NSLOW where it slows down enough to be concerning but has not yet hit the caps RMAX and NMAX where it is so bad we don't allow them to do it at all. 
4) **Use advanced tab** - the advanced settings are a place where we could allow some users to increase the default caps. Code was drafted to allow that already but would need cleaning / testing/ fleshing out. 
4) **Code solutions for huge analyses** to handle those cases where radius is > current RMAX and/or points count is > current NMAX  --  this is an enhancement and is less urgent, but very useful to be able to run an analysis of radius of 6 miles or even 31 miles (50km), and also useful to be able to run 30,000 or 100k or 1.5 million facilities at once rather than needing to manually create batches.

**Solutions ideas/examples:**
(Doing things in batches is the obvious solution, but here are some other ideas as well)
- better memory management in general, possibly explicitly doing gc() before and after a large job
- rethinking how maps should display or not display large counts of points
- rethinking how certain calculation bottlenecks are done? doaggregate() seems especially bad at very large analysis, but not sure where that problem occurs.
- batching the sites for `getblocksnearby()`, analyzing NMAX sites at a time (possibly a reasonable NMAX depends on R)
- batching the sites for `doaggregate()`, analyzing NMAX sites at a time (possibly a reasonable NMAX depends on R)
- batching the sites in outputs (**objects, files, and web views**), meaning assembling the final results only in appropriately sized batches for each given component of the displays/ outputs -- NOT assembling final results if truly large datasets are best kept in separate objects, files, and displays. For example maybe run things in batches of 10,000 points as long as radius is <5 miles and then display/save results only in groups of 1,000 or less? for interactive tables and maps, and allow spreadsheet of up to 50,000 points at a time??? Those are just hypothetical examples of cutoffs.

**Components that are likely to need fixes for larger R and N values:**

- memory limitations mean the output of getblocksnearby() will be too big to hold all the distance pairs 
- doaggregate() function scales poorly with increasing size of analysis
- maps 
- interactive datatable of site by site results 
- excel spreadsheet will not work or will be very slow to create and save
- scatter plots? other plots?
- others? there are probably others worth listing here.
","@alex-silverman @ParkerJanMalek separated this ticket into the different tasks: #408 #412 #411 #410 #409 
",,https://api.github.com/repos/USEPA/EJAM/issues/163/comments,12/22/2023,1/21/2025,ejanalysis,none,1,0,0,FALSE
135,153,open,see if qs is even faster than arrow format for big data files EJAM needs,enhancement|urgency low|datasets/ pins/ AWS/ etc.|speed / performance (see #444),4538805068|6227891676|6343736234|6535412240,cfd3d7|cfd3d7|0E8A16|e99695,"New feature or request||related to data files via pins board, AWS, dataload_ etc.|related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.",0,"
when using pins, 
type = ""qs"" uses [qs::qsave()](https://rdrr.io/pkg/qs/man/qsave.html) to create a binary R data file, like writeRDS(). This format achieves faster read/write speeds than RDS, and compresses data more efficiently, making it a good choice for larger objects. Read more on the [qs package](https://github.com/traversc/qs).",,,https://api.github.com/repos/USEPA/EJAM/issues/153/comments,11/22/2023,10/9/2024,ejanalysis,none,0,0,0,FALSE
136,152,open,"check/ fix Distance and Site Count summary stats, in doaggregate()",bug|documentation|enhancement|good first issue|question|urgency medium|distance-related|calculate/validate to EJScreen,4538805065|4538805066|4538805068|4538805069|4538805072|6227894519|6343333395|6343712128,d73a4a|C5DEF5|cfd3d7|7057ff|d876e3|FBCA04|C2E0C6|FBCA04,"Something isn't working|Improvements or additions to documentation|New feature or request|Good for newcomers|Further information is requested||related to distances variables or calculations or plots|related to errors in numbers, replicating EJScreen stats",3,"This very well may be a bug, since the formulas and results have not been checked and it is a little bit complicated. Someone just needs to methodically go through which of these metrics we want, confirm they are correctly calculated in the code, and spot check a set of results as reality checks.

doaggregate() tries to calculate various summary stats on distance from residents to sites, but not sure it provides all the useful ones, no useless ones, and is doing it exactly right. Confirm what it provides and how it calculates each is correct, useful, and correctly labelled or described accurately, since this is a bit tricky. It is tricky to keep track of and accurately name exactly what we are calculating and reporting in summary stats about DISTANCE (and similarly for summary stats about COUNTS of nearby sites). The summary stats happen at a few levels of resolution or aggregation like block, bg, etc.

Stats on Distances to sites or Counts of sites, as listed out below, can be 
  - for people in the entire population or for each demographic group's population, 
  - at resolution of block, blockgroup, buffer (site), and overall scales, and 
  - for the average or min distance or max count

(not sure all these make sense or are needed, but this spells it out)

- For this **block**
  - distance that is normally calculated by getblocksnearby() is the **avg** Distance to **each/this site** from this **block** (but now as of 8/24 actually need to distinguish if calculated for the _distance to the block centroid now rather than an ""adjusted"" distance to the avg person in a block_- adjusted distance based on block area that had been done but not done as of 8/24, and was never the true minimum like for a single hhld that is nearest), 
  - **avg** Distance to **any/all sites** from this **block** (avg of number 1 over any/all sites nearby this block)
  - **min** Distance to **any/all sites** from this **block** (min of number 1 over any/all sites nearby this block)
- For this **BLOCKGROUP** (and counting each nearby unique site only once!)
    - **avg** Distance to **each/this site** from people in this **BLOCKGROUP** (for avg person, or pop wtd avg of ...??? 
    - **min** Distance to **each/this site** from any (nearest) person in this **BLOCKGROUP** but actually it could be either the avg dist from block centroid for the avg resident in that block OR if using dist adjustment could be the avg distance for all residents in the nearest block that is in this blockgroup; = the min of number 3? or min of number 1?? 
   - avg person's Distance to **nearest site,** for this **BLOCKGROUP** - avg of min Distances?
   - avg person's Distance to **any/all sites**, for this **BLOCKGROUP** - is this useful?
   - nearest person's Distance to **nearest site**, or min Distance of anyone in this **BLOCKGROUP** to any site i.e., nearest site = min of number 5? or can get via min of num 3?
- For this **SITE** (and counting each nearby unique site only once!)
   - avg person's Distance to **site nearest them** which might not be ""this site"", of everyone in blockgroups near **this site**
  - nearest person's Distance to **nearest site**, of everyone in blockgroups near **this site**
- For all sites **overall**
   - avg person's Distance to **site nearest them**, of everyone in blockgroups near **any of the sites analyzed**
   - nearest person's Distance to **nearest site**, of everyone in blockgroups near **any of the sites analyzed**
  
AND the same stats can be done for **COUNT** of sites nearby  (and counting each nearby unique site only once!)
  - how many is the max count of sites near any one resident 
      - for this bg, 
      - for this site, 
      - and overall? 
  - how many sites are near the average person at this site, 
       - for this bg, 
      - for this site, 
      - and overall? ","@ejanalysis is there any action needed on this ticket or can we close?|@ejanalysis is there any action needed on this ticket or can we close this one?|> @ejanalysis is there any action needed on this ticket or can we close this one?

leave it open - have not had time to look back at it. ",,https://api.github.com/repos/USEPA/EJAM/issues/152/comments,11/21/2023,1/10/2025,ejanalysis,ejanalysis,1,0,0,FALSE
137,150,open,low life expectancy is calculated incorrectly?,bug|good first issue|urgency high|calculate/validate to EJScreen,4538805065|4538805069|6227890498|6343712128,d73a4a|7057ff|D93F0B|FBCA04,"Something isn't working|Good for newcomers||related to errors in numbers, replicating EJScreen stats",3,"```
x = ejamit(fips = ""10001"")
x = x$results_bysite[1,]
 round(t(data.frame(x)[, grepl('life', names(x)) ]), 3)
                              [,1]
ratio.to.avg.lowlifex        1.070
ratio.to.state.avg.lowlifex  1.043
lowlifex                     0.209
lifexyears                  70.598
pctile.lowlifex             64.000 ???
avg.lowlifex                 0.195
state.pctile.lowlifex       59.000 ???
state.avg.lowlifex           0.200
```
compare to 
https://ejscreen.epa.gov/mapper/EJscreen_SOE_report.aspx?&geometry=%7B%22spatialReference%22:%7B%22wkid%22:4326%7D,%22x%22:,%22y%22:%7D&distance=&unit=9035&areatype=county&areaid=10001&namestr=10001&f=report
`browseURL(url_ejscreen_report(areaid = fips_counties_from_state_abbrev(""DE"")[1]))`

```
Value 	 State Avg 	 State %ile 	 US Avg 	 US %ile
19% 	 20% 		 35 		 20% 		 47
```

19% versus 20.9%  seems like a small difference but it results in percentiles reported being very different since there are so many places in that narrow range of 19 to 21 percent low life score.","@DougMoy please verify to see if this has been resolved.|Issue has not been resolved, I am getting the same results as Mark's screenshot, will discuss on steps to resolve with Marschall tomorrow when hes back. |Believe this is resolved as Marschall and I discovered that EJAM and EJSCREEN handle NA's differently when doing calculations. EJSCREEN looks to be treating NAs as 0s while EJAM was getting rid of them in calculations.",,https://api.github.com/repos/USEPA/EJAM/issues/150/comments,11/21/2023,1/22/2025,ejanalysis,ejanalysis,0,1,0,TRUE
138,148,open,add links to COUNTY-LEVEL reports - on a place - from other tools/ sources,enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,1,"**Site by site views** (web table, excel table, appendix in long report, map popups, a drill down report on one site, etc.) already have links to URLs providing EJScreen reports on a given location. There are many other resources that provide useful reports on a single COUNTY, via URL-encoded link or API query. EJAM should provide links to selected sources of COUNTY reports, to provide perspective on the broader area (county) that contains the site being examined. Perhaps 2 to 5 sources of county reports? Perhaps an ""advanced/expert"" view could provide access to a longer set. 

The functions already exist: 
```
browseURL(EJAMejscreenapi::url_ejscreen_report(areaid = EJAM::fips_counties_from_state_abbrev(""DE"")[1]))

browseURL(url_countyhealthrankings(""10001""))
```
compare to 
```
x = ejamit(fips = EJAM::fips_counties_from_state_abbrev(""DE"")[1:2])
x = x$results_bysite[1,]
table_gt_from_ejamit_1site(x)
table_gt_from_ejamit_1site(x, ""envt"")
```

Candidates / examples might be:
- **EJScreen's -- and then later EJAM's -- County-level report**, for the county in which the site of interest is located. If a user is looking at EJAM results for residents within 2 miles of a specific point, there should  be a link to click that provides in a separate window the EJScreen and/or EJAM summary report (1pager) for the entire county where the point is located. (if the point is near a border and zone spans two plus counties, it is probably ok to just provide the single county that contains the point or bg or tract, or which contains most of the polygon being analyzed/ viewed). This is easy to implement quickly, especially for the EJScreen county report. 
- [countyhealthrankings.org](countyhealthrankings.org) is a good candidate for another county-level report that is useful and easy to link to. Drafted a function already - see above url_countyhealthrankings()
- https://www.countyhealthrankings.org/explore-health-rankings/data-beyond-the-rankings  has a long list of resources with reports on counties, etc. Those should be looked at and considered.
- [https://nationalequityatlas.org/](https://nationalequityatlas.org/)
",@saradelessio-abt not a high priority issue.,,https://api.github.com/repos/USEPA/EJAM/issues/148/comments,11/21/2023,12/12/2024,ejanalysis,none,0,0,0,FALSE
139,146,open,rename state_from_fips(),refactor|urgency medium,6208400114|6227894519,8F13A1|FBCA04,Rewrite how code works or break into smaller pieces|,4,"This function has an extremely misleading confusing name, and related ones may also. It seems to return ST abbrev for every single blockgroup that is contained within the supplied FIPS (which could be States or Counties full of many blockgroups). 

Compare to fips2statename() and related functions that do something related but very different. 

The naming scheme could be fixed, too. See other issues #133  about refactoring/ renaming functions. ","Named all fips-related functions to start with ""fips..."", so 

 - if func **RETURNS the fips**, named the function  fips_from_xyz() 
   -  ` fips <- fips_from_xyz(xyz)`

 - if func **STARTS from fips**, named the function  fips2xyz()
   - `xyz <- fips2xyz(fips)` 

  (NOT a naming scheme something like countyname_from_countyfips etc.)|@DougMoy please review current function names.|Should rename from state_from_fips to fips2state.  I believe the function works as intended. If you set uniqueOnly to true, it will return a list of unique states associated with all the blockgroups instead a really large list of all states that correspond to every block with a lot of duplicates.|@sarasoko please QA this ticket please",,https://api.github.com/repos/USEPA/EJAM/issues/146/comments,11/20/2023,11/22/2024,ejanalysis,none,1,0,0,FALSE
140,145,open,correctly handle cases where the adjusted distance (via block_radius_miles) is > radius the user specified,urgency low|distance-related|calculate/validate to EJScreen,6227891676|6343333395|6343712128,cfd3d7|C2E0C6|FBCA04,"|related to distances variables or calculations or plots|related to errors in numbers, replicating EJScreen stats",2,"This issue and notes below are now usually irrelevant to circular buffer reports since short distance adjustment is removed from that as of 8/24, but still might be relevant in edge cases so we should think about it when we have a chance -- Roughly 1 in 300 FRS sites had zero block points within 1 mile using unadjusted distance (could check again though).  The edge cases are about how to handle a circular buffer report where only <10 block centroids or <5 or even zero block centroids are within X miles of a site... For example if the entire circle is inside or nearly entirely inside one or two block shapes, it is not obvious what is the best way to report which blocks are ""nearby"" and a second concern is reporting stats on the average person's distance from sites -- if someone tries to rely on that stat (not reported by EJScreen but useful for some kinds of analysis!) then it can be very wrong for the block(s) that have a site inside the block or even exactly on top of the block centroid where distance would be reported as zero if unadjusted.

Notes below are from before the default short distance adjustment got removed from getblocksnearby().


EJAM must correctly handle cases where the adjusted distance (via block_radius_miles) is > radius the user specified. 

This means some of the tests for doaggregate() etc. might need to be aware of how this should be handled, since it is a tricky odd situation - user might ask for analysis of radius 1 mile, but output of getblocksnearby() will include some distances larger than 1 mile, because some blocks might have effective radius >1mile, and this is somewhat unexpected. Worth thinking about how to alert / warn user and how to handle in logic where we might have assumed the max distance found is roughly what they wanted analyzed, and what distance to use in reporting stats like average resident's distance, minimum distance, in summary stats and in plots of distance by group or %Demog within each distance, etc. 
See related issue #19 about using blockwts$block_radius_miles 



 ","Some more notes related to this issue:
the short distance adjustment and the use of avoid orphans parameter and max radius parameter ... 
 
This approach may eliminate from analysis a site that is in a very large rural block if there are no other blocks nearby and the block very large /  is so large that  getblocksnearby() reported the only distances are to the one block and that gets reported as > requested radius of analysis because even though some residents may be < radius away from the site, the avg resident in the block is > radius requested. 
and filtering again by distance having to be <radius requested would remove those sites and blocks from any analysis. 
 This case is rare, but running 20 sets of 1,000 random facilities, **at typically about 3 sites per 1,000 sites** (ranging 0 to 6 sites per each 1,000 analyzed),   **no reported distances were within the 1 mile radius requested** for analysis, as reported by getblocksnearby()  and that is a problem.

 `rad = 1
for (i in 1:20) { 

   x <- getblocksnearby(  testpoints_n(1000),   radius = rad, quiet = T)
   x[,  mind := min(distance), by = ""siteid""]
   cat(""At"", sum( x$mind > rad), ""sites of these 1k, NO DISTANCE REPORTED <= "", rad, ""mile RADIUS REQUESTED  \n"")

 }`|saved data seemed out of sync with latest results only because plot is of a sample not all blocks, but problem is seen either way:
`x = EJAM::getblocks_diagnostics(EJAM::getblocksnearby(EJAM::testpoints_100, radius = 1, avoidorphans = FALSE, quiet = T), see_distanceplot = TRUE)`
![Rplot01](https://github.com/USEPA/EJAM/assets/8205979/216cb5d2-5659-49e0-8674-dd51ac5b2fdb)

Analyzing 100 points, radius of 1 miles around each.

   Summary stats on distances reported from any sites to any nearby blocks

0.999943 miles is max. distance to block internal point (distance_unadjusted)   
1.962 miles is max. distance to average resident in block (distance reported)   
0.01569589 miles is shortest distance to block internal point (distance_unadjusted)   
0.027 miles is shortest distance to average resident in block (distance reported)   
110 block distances were adjusted (these stats may count some blocks twice if adjusted at 2+ sites)
  80 block distances were adjusted up (reported dist to avg resident is > dist to block internal point)
  30 block distances were adjusted down (reported < unadjusted)
75 unique sites had one or more block distances adjusted due to large block and short distance to block point

100 unique output sites
161 blocks are near the avg site or in avg buffer
             (based on their block internal point, like a centroid)
16,103 blocks including doublecounting in overlaps, 
             in final row count (block-to-site pairs table)
15,986 actual unique blocks total
15,869 blocks (and their residents) have exactly 1 site nearby 
117 blocks (and their residents) have exactly 2 sites nearby 
0 blocks (and their residents) have exactly 3 sites nearby 
1.007319 is ratio of blocks including multicounting / actual count of unique blocks
0.7% of unique blocks could get counted more than once 
             because those residents are near two or more sites 
             (assuming they live at the block internal point
plotting a sample of blocks since too many to easily plot them all

#--------------------------------------------------------------------------------------- 

`x = EJAM::getblocks_diagnostics(EJAM::testoutput_getblocksnearby_100pts_1miles, see_distanceplot = TRUE)`
```
   Summary stats on distances reported from any sites to any nearby blocks

0.999943 miles is max. distance to block internal point (distance_unadjusted)   
1.962 miles is max. distance to average resident in block (distance reported)   
0.01569589 miles is shortest distance to block internal point (distance_unadjusted)   
0.027 miles is shortest distance to average resident in block (distance reported)   
110 block distances were adjusted (these stats may count some blocks twice if adjusted at 2+ sites)
  80 block distances were adjusted up (reported dist to avg resident is > dist to block internal point)
  30 block distances were adjusted down (reported < unadjusted)
75 unique sites had one or more block distances adjusted due to large block and short distance to block point

100 unique output sites
161 blocks are near the avg site or in avg buffer
             (based on their block internal point, like a centroid)
16,103 blocks including doublecounting in overlaps, 
             in final row count (block-to-site pairs table)
15,986 actual unique blocks total
15,869 blocks (and their residents) have exactly 1 site nearby 
117 blocks (and their residents) have exactly 2 sites nearby 
0 blocks (and their residents) have exactly 3 sites nearby 
1.007319 is ratio of blocks including multicounting / actual count of unique blocks
0.7% of unique blocks could get counted more than once 
             because those residents are near two or more sites 
             (assuming they live at the block internal point
plotting a sample of blocks since too many to easily plot them all
```

![Rplot](https://github.com/USEPA/EJAM/assets/8205979/142064da-9292-4f17-8944-ca81ac65670d)
",,https://api.github.com/repos/USEPA/EJAM/issues/145/comments,11/19/2023,8/8/2024,ejanalysis,ejanalysis,0,0,0,FALSE
141,144,open,"for proximity score creation tool, resolve how to apply short distances formula (continuous or abrupt)",urgency low|distance-related|calculate/validate to EJScreen,6227891676|6343333395|6343712128,cfd3d7|C2E0C6|FBCA04,"|related to distances variables or calculations or plots|related to errors in numbers, replicating EJScreen stats",0,"THIS PROBABLY APPLIES ONLY TO A TOOL THAT CREATES A PROXIMITY SCORE FOR EACH BLOCK AND BLOCK GROUP IN USA, BUT WOULD BE IRRELEVANT TO getblocksnearby() etc. when those are used in the shiny app or ejamit() etc. to just do a aggregated report on existing proximity scores. The distance adjustment had been done for both but now probably will only be relevant to creating custom proximity scores nationwide (like a TSDF score but for some custom category).
--------------
resolve how to apply short distances formula (continuous or abrupt) -  confirm how the EJScreen code did it in creating proximity scores, and mirror that.  

See note below about ""2 ways considered here for how exactly to make the adjustment"" ... 
The source code of `getblocksnearbyviaQuadTree()` had these explanatory notes and steps as of 11/2023:
```
  # ADJUST THE VERY SHORT DISTANCES ####
  
  # distance gets adjusted to be the minimum possible value,  0.9 * effective radius of block_radius_miles (see EJScreen Technical Documentation discussion of proximity analysis for rationale)
  
  if (!(""block_radius_miles"" %in% names(blockwts))) {
    # if missing because not added to dataset yet then use placeholder of 100 / meters_per_mile, or 100 meters
    # not sure if this updates by reference blockwts for the remainder of this session and all users, or if this happens each time getblocksnearby... is called.
    message(""using temporary approximation of block_radius_miles"")
    blockwts[ , block_radius_miles := block_radius_miles_round_temp] # lazy load this and add it into blockwts
  }
  # Add block_radius_miles here, now to be able to correct the distances that are small relative to a block size.
  # This adjusts distance the way EJScreen does for proximity scores - so distance reflects distance of sitepoint to avg resident in block
  # (rather than sitepoint's distance to the block internal point),
  # including e.g., where distance to block internal point is so small the site is inside the block.
  # This also avoids infinitely small or zero distances.
  # 2 ways considered to do join here - may be able to optimize.
  # a) try to do join that updates sites2blocks by reference - not sure it works this way, but goal was to make join faster:
  # sites2blocks[blockwts, .(siteid,blockid,distance,blockwt,bgid, block_radius_miles), on = 'blockid']
  # b) try to do join that updates sites2blocks by making a copy? This does work:
  
  sites2blocks <-  blockwts[sites2blocks, .(siteid, blockid, distance, blockwt, bgid, block_radius_miles), on = 'blockid'] 
  
  # 2 ways considered here for how exactly to make the adjustment: 
  
  sites2blocks[distance < block_radius_miles, distance := 0.9 * block_radius_miles]  # assumes distance is in miles
  # or a more continuous adjustment for when dist is between 0.9 and 1.0 times block_radius_miles: 
  # sites2blocks_dt[ , distance  := pmax(block_radius_miles, distance, na.rm = TRUE)] # assumes distance is in miles
  
  # drop that info about area or size of block to save memory. do not need it later in sites2blocks
  sites2blocks[ , block_radius_miles := NULL]
  ########################################################################### ## 
```

also see these notes from 8/2024 on the topic:

*** STOP ADJUSTING SHORT DISTANCES -- in getblocksnearby(), ejamit(), shiny app, etc. 

- The short distance adjustment documented in EJScreen tech docs was used where the distance from sitepoint to blockpoint is smaller than the ""effective radius"" of a block (what its radius would be if that same square mileage of the block were shaped like a circle). The purpose was to make the distance reflect distance of site to average resident in block rather than to centroid of  block, so it would convert a distance of almost zero to some small but more realistic distance.
- Distances are used mostly for 2 things: 1) creating a proximity score each year for each blockgroup, such as the TSDF proximity indicator that considers which TSDF facilities are at various distances from a block centroid. 2) deciding which blocks are within X miles of a facility, for a circular buffer report to aggregate nearby residents (nearby blocks).
- We are not 100% certain EJScreen makes this distance adjustment for short distances when aggregating in a buffer. The adjustment was originally designed to handle proximity score creation, not aggregation within buffer reports. 
- EJAM was using distance adjustments in getblocksnearby() and related functions, which might not reflect EJScreen methodology.
- The v2.3 block weights file obtained from EJScreen team does not provide a column with area (square miles) so we cannot calculate effective block radius to store in the blockwts table as was needed to do the distance adjustment. V 2.2 EJAM had gotten area directly from Census 2020 using code in census2020download:: and EJAM/data-raw/datacreate_blockwts.R still is capable of that option. 
- getblocksnearby() and related functions in EJAM v2.3 will be modified to only optionally use distance adjustment and NOT adjust by default, thus removing the need for an area column in blockwts and likely conforming to EJScreen more exactly. The new parameter use_unadjusted_distance=FALSE will control this. 
- Need to adjust/add unit testing of this change. Need to ensure getblocks diagnostics functions etc. are not messed up by this.
- The datacreate_blockwts script will default to using the weights file that was provided without area and setting area to zero as a placeholder so effective radius is zero but that wont be used by default.",,,https://api.github.com/repos/USEPA/EJAM/issues/144/comments,11/19/2023,8/8/2024,ejanalysis,ejanalysis,0,0,0,FALSE
142,143,open,"Create density score /proximity score/ count-nearby functions, then provide via web app, and API",enhancement|distance-related|urgency high-ish but not a bug,4538805068|6343333395|7539794549,cfd3d7|C2E0C6|B9463A,"New feature or request|related to distances variables or calculations or plots|for high urgency enhancements, to rank them just below high urgency bugs",3,"
EJScreen uses precalculated proximity scores that summarize, for each blockgroup in the whole nation, the proximity to and number of nearby facilities of a specific type, like the RMP proximity indicator, as documented in EJScreen Tech. Doc. EJAM should have a function that creates a proximity score for every block group based on proximities of a user-specified list of facilities, calculated just like EJScreen did for RMP, TSDF, NPL sites. A draft function that was starting to work on this was called EJAM:::proxistat2() but one could start over from scratch if that is useful.  The tool would also need to create the lookup tables of percentiles to be used in reporting in terms of percentiles. That can be done via EJAM::pctiles_lookup_create() 

1. create/finish/test a function that can create a proximity score for some or all of the US blockgroups
2. provide the scores via API, so a user can specify ""proximity facilities"" as site points and get back a proximity score for every US blockgroup, or a subset like just in one state.
3. make that proximity score calculation available via web app EJAM - so user can specify points, ask for proximity score, and 
    - download that score for the whole US (every bg), OR 
    - specify two sets of points - the ""proximity facilities"" and the analyzed places (the usual EJAM sites) - EJAM would find blocks nearby the analyzed places as usual, but then calculate an EJScreen-style proximity score for those blocks based on the proximities of the ""proximity facilities"" - and then use that new score as a new indicator to aggregate in doaggregate. This would allow a user to say they want to analyze residents near refineries, eg., and see their envt scores near each refinery but also see the scores representing to what extent they have CAFOs nearby, or parks nearby, or whatever ""proximity facilities"" were specified by the user. 

It must correctly handle the formula EJScreen uses to adjust small distances based on something like blockwts$block_radius_miles

See related issue #19 

(Note some of this issue of obtaining and using the block area had been documented in an older script called 
_inst/NOTES_ON_VINTAGE_OF_CENSUS_ACS_-_EJSCREEN_FIPS_GEO_BOUNDS.txt_
 that had been in the repo of the package called  EJAMblockdata but that repo is gone now/ retired. )","There is a need for this. Started working on it via updates to proxistat() -- latest is now in `proxistat-new` branch.

 Needs supporting functions drafted like indexpoints() etc. but need to resolve whether using getblocksnearby() that is made more flexible or use a dedicated overlapping function like getpointsnearby() or what. Careful not to mess up getblocksnearby() while making it more flexible. |Confirmed on 2/28/24 via email that EJScreen will limit proximity score calculations to 10 kilometers max distance, so a block gets a score of zero if not even one facility/point is within 10 km of block internal point, and block group gets score of zero if not even one point is within 10km of any block points among those blocks in the block group. So any search for nearest one should stop at 10km.|Features to build:
- Provide these kinds of proximity scores (variants)
  - **Proximity Score** like EJScreen has (sum of 1/d values of blocks in BG), etc.
  - **Count Nearby:** The number of places (points) that are within X distance of anyone in the block group.\
  - **Density Score**: Same as count nearby, but expressed in units of count per square mile, within X miles, but need to clarify how to calculate it since it is easy if you pick just one point to represent the block group and count all within 1 mile of that point and divide by sq miles which is pi x R^2 or 3.14 sq miles, say. But if you count all within X miles of any person within the whole BG then it is not obvious what the square miles number should be and whether we mean distance from any edge of the BG (which is more like the new proximity score method in EJScreen 2.3) or distance from any block centroid which is faster and more similar to v.2.2 proximity scores.
- **UPLOAD PLACES**: 1st provide ability to upload and/or specify sites for the proximity scoring, 
- **PICK PLACE CATEGORY, FROM CURATED LIST(S)**: 2d asap provide curated list of options to pick from just like the facility picking options for analysis in EJAM but for picking sets of facilities to create proximity scores. 
- **PRECALCULATE AND CACHE**: we should store cached proximity scores based on those curated standard options by precalculating them all. So if they pick NAICS xyz, it is already done. If they pick NAICS xyz & also NAICS abc, then think about how those precalculated proximity scores might be combined rather than recalculating for the combined set - that might be possible depending on the proximity or density score and overlaps between facility lists?
- **AMENITIES**: 3d, there is also an interest from OEJECR in ability to create such scores for amenities, like proximity to or density of parks, etc. If a user already has such data as a table of lat/lon coordinates, they can upload it just like a list of facilities for this proximity score tool. But as with facilities, we will want to offer a curated list of a few amenity types, maybe with precalculated proximity scores.
- **TERMINOLOGY**: need to ensure text labels in this tool are agnostic or flexible about ""facility"" versus ""amenity"" so maybe ""points of interest"" is the general term or ""user-specified points"" or ""user-provided points"" or places. Also ensure text / terminology can work for proximity scores based on proximity to polygons not just points.
- **POLYGONS**: need to ensure the first or second version of this can handle proximity to polygons not just points.
",,https://api.github.com/repos/USEPA/EJAM/issues/143/comments,11/19/2023,1/22/2025,ejanalysis,ejanalysis,0,1,1,FALSE
143,136,open,County analysis URLS/link do not work in Excel (but do work in web table of site by site),bug|good first issue|urgency low|URL-related,4538805065|4538805069|6227891676|6228638798,d73a4a|7057ff|cfd3d7|C2E0C6,Something isn't working|Good for newcomers||relates to functions making URLs for links to reports,2,County analysis URLS/link do not work in Excel (but do work in web table of site by site). They should be using the same code to create URLs/links but apparently are not and one works but other does not. ,"Reassigning to @saradelessio-abt cc: @ParkerJanMalek |Is this ticket referring to the URLs in the EJScreen Report and EJScreen Map columns?
<img width=""198"" alt=""Screenshot 2024-08-29 at 4 13 53 PM"" src=""https://github.com/user-attachments/assets/7697ef35-5d01-4fb8-bb09-6e20aba9ccd7"">

<img width=""918"" alt=""Screenshot 2024-08-29 at 4 14 01 PM"" src=""https://github.com/user-attachments/assets/ed984def-765e-4ff4-bfd1-7801f1b3f1c2"">
",,https://api.github.com/repos/USEPA/EJAM/issues/136/comments,11/15/2023,11/26/2024,ejanalysis,saradelessio-abt,0,0,0,FALSE
144,134,open,Confirm/fix what formula to use for state percentiles in overall summary,good first issue|test|refactor|urgency low|calculate/validate to EJScreen,4538805069|6148706060|6208400114|6227891676|6343712128,7057ff|6F7271|8F13A1|cfd3d7|FBCA04,"Good for newcomers|test to be developed|Rewrite how code works or break into smaller pieces||related to errors in numbers, replicating EJScreen stats",0,"Resolve the remaining question about what is the most appropriate formula to use when reporting the state percentiles on the ""overall"" reports. 

Advise or opinions would be helpful on this. The code in doaggregate() had comments explaining the question. 

EJScreen is not going to be helpful on this since the issue never comes up in EJScreen. The problem arises when you aggregate results from two or more states. There is a formula that tries to handle this in doaggregate() but it should be reviewed/ discussed by some analytic folks. ""Percentile among what list of places?"" is the question. ",,,https://api.github.com/repos/USEPA/EJAM/issues/134/comments,11/15/2023,6/4/2024,ejanalysis,ejanalysis,0,0,0,FALSE
145,133,open,fips-related functions need consistent naming scheme and output/input formats,refactor|urgency low,6208400114|6227891676,8F13A1|cfd3d7,Rewrite how code works or break into smaller pieces|,3,"Groups of related functions need consistent naming scheme and output/input formats. The names of the suite of functions should be harmonized to be consistent about what is returned. The whole set of functions returning lat lon, regid, etc., as vectors or data.tables or data.frames, should be named consistently to indicate their input and output types, such as was done for FIPS-related functions:

Named all fips-related functions to start with ""fips..."", so 

 - if func **RETURNS the fips**, named the function  fips_from_xyz() 
   -  ` fips <- fips_from_xyz(xyz)`

 - if func **STARTS from fips**, named the function  fips2xyz()
   - `xyz <- fips2xyz(fips)` 

  (NOT a naming scheme something like countyname_from_countyfips etc.)","@DougMoy please review current function names.|Fips related functions that need to be addressed

original -> suggested new

name2fips -> fips_from_name
names2fips -> fips_from_names
getblocks_nearby_from_fips -> fips2block_data
state_from_fips -> fips2state
bgid2fips -> fips_from_bgid
blockid2fips fips_from_blockid
countyname2fips-> fips_from_countyname (Don't believe this function is actually used, but is used in documentation.)

|`bgid2fips` and `blockid2fips` are datasets rather than functions and can leave as is. `getblocks_nearby_from_fips` is related to the getblocksnearby* family of functions and is ok as is.

The others can be renamed per your suggestions:

- name2fips -> fips_from_name
- names2fips -> fips_from_names
- countyname2fips-> fips_from_countyname
- state_from_fips -> fips2state",,https://api.github.com/repos/USEPA/EJAM/issues/133/comments,11/15/2023,11/22/2024,ejanalysis,none,0,0,0,FALSE
146,131,open,plotting functions all need review/ consolidation/ improvement/ renaming/ testing,refactor|urgency medium|plots-graphs-related|speed / performance (see #444)|server,6208400114|6227894519|6235793514|6535412240|7384237694,8F13A1|FBCA04|C2E0C6|e99695|25B9F0,"Rewrite how code works or break into smaller pieces||related to plotting/graphing like histo, bar, box, scatter|related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.|removing code from app_server.R",4,"plotting functions should get a review/ consolidation/ improvement/ renaming/ testing/ etc. - 
There are various plotting functions that are 
- using a variety of underlying packages like base R, ggplot, etc., 
- providing varying types of input/ output formats, 
- using various naming schemes, and 
- working with varying degrees of speed, and 
- of varying quality/ error-checking, etc. 
 
They should be reviewed, refactored, tested, etc., essentially cleaned up in various ways. 

These are some notes about some of the plotting functions: 
```
For plots in general, see:
  - (https://echarts4r.john-coene.com/articles/themes.html)
  - (https://exts.ggplot2.tidyverse.org/gallery)
For BARPLOTS, see/ merge/consolidate:
  - output$view1_summary_plot <- renderPlot(v1_summary_plot()) and v1_summary_plot <- reactive( ) in EJAM server for Short Report if bar type
  - output$summ_display_bar <- renderPlot( ) contains its own plot code not a reactive in EJAM server for tab showing barplots in Detailed Results
  - plot_barplot_ratios() drafted function in EJAM
For BOXPLOTS, see:
  - v1_summary_plot <- reactive( ) and output$view1_summary_plot <- renderPlot(v1_summary_plot())
      - in EJAM server for SHORT report if box type, and
      - in EJAM server for LONG report passed as a parameter
  - boxplots_ratios() in EJAMejscreenapi
      - (NOT in EJAM server for Detailed Results interactive views)
  - ejscreenapi_script() code also relevant? in EJAMejscreenapi
  - box/scatter examples in ggplot, https://r-graph-gallery.com/89-box-and-scatter-plot-with-ggplot2.html
  - boxplots in base R, https://www.r-bloggers.com/2023/09/how-to-reorder-boxplots-in-r-a-comprehensive-guide
For HISTOGRAMS, see:
  - output$summ_display_hist <- renderPlot in EJAM server for interactive views
  - the histograms code and discussion in EJAMbatch.summarizer package

```","@DougMoy cleanup of plotting code used in `R/app_server.R` is needed. Please reach out to discuss.|Other related plotting issues:
#215 #244 #356 #357 #358 #359 #381|https://github.com/USEPA/EJAM/tree/issue131

I wrote standalone functions/files for create_summ_display_hist, create_summary_bar_plot, create_boxplots_ratios, create_summary_hist_ind. Also changed pre existing functions boxplots_ratios.R to match the original boxplot in app_server. I've tested the functionality and it works in the app as originally intended. 

Still need to add documentation to each of the new files I created. Hoping a developer with more experience can create the documentation at the top of each new file as it mirrors the original code very closely.|@DougMoy revisit when we restart refactoring",,https://api.github.com/repos/USEPA/EJAM/issues/131/comments,11/15/2023,12/2/2024,ejanalysis,DougMoy,1,0,0,FALSE
147,130,open,URLs / links to EJScreen reports for FIPS analysis other than counties - need these to work,refactor|urgency low|URL-related,6208400114|6227891676|6228638798,8F13A1|cfd3d7|C2E0C6,Rewrite how code works or break into smaller pieces||relates to functions making URLs for links to reports,0,"URLs / links to EJScreen reports for FIPS analysis other than counties -
in excel and in interactive datatables, EJScreen report URL to use their API for a report does now work for Census FIPS of County (and I think may work for tracts, but comparing those is likely to be a rare use case), but not sure if it works if a user wants to compare units other than counties -- **for the ones the EJScreen API supports, EJAM has to be able to create links to those report types**. Not sure what the EJScreen API itself supports - probably it only can handle areaidea / areatype being county or tract? see their documentation. **If it does accommodate FIPS of State, Places, CBSAs, etc., then EJAM should too. If not, that is a separate issue/enhancement topic to be considered elsewhere/later.**",,,https://api.github.com/repos/USEPA/EJAM/issues/130/comments,11/15/2023,11/22/2024,ejanalysis,none,0,0,0,FALSE
148,129,open,Summary report template that works for 1 site,enhancement|urgency medium,4538805068|6227894519,cfd3d7|FBCA04,New feature or request|,0,"important enhancement - Summary report template that works for 1 site
If there is a way to do this immediately, that would be very helpful, and could be provided via a button/link next to each site in any site-by-site table, similar to how we currently offer the link to an EJScreen community report. We need to be able to view the EJAM results for a single site in the same format as the summary report that shows results for all sites overall. html template approach and/or other ways tables are made in EJAM would need to be edited to facilitate this, maybe with some helper functions to make it easier. Some functions have been drafted that might be useful for this if using the gt approach, such as:
 mysiteid <- 2
 table_gt_from_ejamit_1site(testoutput_doaggregate_10pts_1miles$results_bysite[siteid == mysiteid,], type = 'demog')
 table_gt_from_ejamit_1site(testoutput_doaggregate_10pts_1miles$results_bysite[siteid == mysiteid,], type = 'envt')
",,,https://api.github.com/repos/USEPA/EJAM/issues/129/comments,11/15/2023,9/4/2024,ejanalysis,none,1,0,0,FALSE
149,127,open,URLs / links to EJScreen reports for shapefile analysis,bug|good first issue|refactor|urgency medium|URL-related|shapefile-related,4538805065|4538805069|6208400114|6227894519|6228638798|6343756696,d73a4a|7057ff|8F13A1|FBCA04|C2E0C6|C2E0C6,Something isn't working|Good for newcomers|Rewrite how code works or break into smaller pieces||relates to functions making URLs for links to reports|related to polygons/ shapefile/ GIS data/ buffers,2,"In excel and in interactive datatables, EJScreen report URL using their API for a report needs to work for shapefile-based analysis/ polygon(s) not just circular buffers or County FIPS reports. 

### Quick interim fix needed asap

Immediate interim workaround should be to replace those links in all tables with NA (or just link to map not report), when the analysis uses shapefiles!  

### Longterm fix

When you run a shapefile report in EJAM, such as using the testdata ""NJ SEWERSHEDS WITH NEEDS"" files in ""testdata/shapes/NJ Sewersheds/"", the excel spreadsheet of site by site results tries to show the usual column of links to EJScreen reports, but those links as coded do not work for a report on a polygon - the function creating those URLs was designed only to handle a circular buffer report (or a county FIPS also works) in EJScreen. The EJScreen API probably can handle a polygon input but likely must be a more complicated query like POST instead of GET and providing geometry of polygon in query body? Not sure simple URL-encoded query would make sense for that case.  

### Closely related issue - other kinds of FIPS?

As a closely related issue, the EJScreen API may only support fips that are for tract or county, but not State, Place, CBSA, EPA Region, etc., so EJAM should handle those types of FIPS-based analyses by converting those FIPS Census units into polygons/boundaries, and then asking the EJScreen API service for a report on the polygon that is the boundaries of each such Census unit. However, if this is unrealistic to query that service for such large polygons as whole States, then consider not providing that option for units/polygons above some size or of certain categories.
","Urgency high for the ""quick fix"" but medium or low for the longterm fix. |Also see #652 ",,https://api.github.com/repos/USEPA/EJAM/issues/127/comments,11/15/2023,12/16/2024,ejanalysis,ParkerJanMalek,1,0,0,FALSE
150,123,open,"Notes on R Package DEPENDENCIES - too many are being imported, etc.",documentation|refactor|urgency low|dependencies-related,4538805066|6208400114|6227891676|6228701467,C5DEF5|8F13A1|cfd3d7|C2E0C6,Improvements or additions to documentation|Rewrite how code works or break into smaller pieces||related to dependencies,1,"### Notes on **R Package DEPENDENCIES**

#### There are a few related issues: 
1. **EJAM itself** is a package via golem, unlike most shiny apps, so that creates some special considerations There are pros and cons to this approach. 
2. **Two other EJAM-related source packages**, and all 3 are not on CRAN and not on a public repository as of 11/10/23: [EJAMejscreenapi](https://github.com/USEPA/EJAMejscreenapi) and [EJAMbatch.summarizer](https://github.com/USEPA/EJAMbatch.summarizer)  But removing dependency on those entirely is slightly tricky since we would need to ensure the essential functions and data are still available, and because some code or documentation referring to those packages by name would have to be globally updated. There are pros and cons. It is useful to keep some data or code separate, maybe, but worth weighing pros and cons. If nobody ever uses any of them without the others, the only advantage to splitting them is maybe rebuilding one may be faster.
3. **DESCRIPTION file Depends vs Imports**: Any packages needed should be carefully treated via roxygen2 notes indicating they should be in Imports or Depends or Suggests parts of the DESCRIPTION file. 
4. The **data.table** package in particular and also **shiny** and **magrittr** seem to need special treatment and least during development work, so that data.table syntax will work during development, so the app will work, and so the magrittr pipe will work, without having to use library() during development work. 
5. **Too many packages?** EJAM requires dozens of other R packages as of 11/11/2023, and there would be some benefits to reducing the number needed. R CMD check warns about this.
6. **Identifying dependencies:** There are various methods of checking package dependencies, and they do not always agree 100%. Deployment from RStudio to the connect server now uses rsconnect and renv packages (and previously it used to use the packrat package) to try to figure out what R packages are needed for the app to work. But there are other ways of trying to check, noted below. 
 
#### These tools and resources may be useful to check:
- Warning on EJAM, from Check [R CMD check](https://rdrr.io/github/r-hub/rhub/man/check.html) `Imports includes 34 non-default packages. Importing from so many packages makes the package vulnerable to any of them becoming unavailable. Move as many as possible to Suggests and use conditionally.`
- See [section 'The DESCRIPTION file' in the 'Writing R Extensions'](https://cran.r-project.org/doc/manuals/R-exts.html#The-DESCRIPTION-file)
- [Hadley book _R packages_](https://r-pkgs.org/) ...  [discussion of the whole issue is here]( https://r-pkgs.org/dependencies-mindset-background.html)   and also see the [section about DESCRIPTION file etc.](https://r-pkgs.org/description.html)
- See DESCRIPTION files in EJAM, EJAMejscreenapi, EJAMbatch.summarizer, in the [GitHub versions of DESCRIPTION](https://github.com/USEPA/EJAM/blob/main/DESCRIPTION) or in the locally installed versions: `rstudioapi::documentOpen(system.file(""DESCRIPTION"", package = ""EJAM""))`
- Packrat has been soft-deprecated and is now superseded by [renv](https://github.com/rstudio/renv)! and see [rsconnect](http://rstudio.github.io/rsconnect/)
- There are notes also in the file at `EJAM/dev/notes_MISC/riskmetric_and_dependencies.R`
- Posit documentation related to this  [Connect package management](https://docs.posit.co/connect/admin/r/package-management/)
- Deployment of shiny apps chapter from  [_Engineering production grade shiny apps_ book](https://engineering-shiny.org/deploy.html)
- Deployment of shiny apps chapter from [_Mastering Shiny book_](https://mastering-shiny.org/scaling-packaging.html#deploying-your-app-package)
- One way you could see dependencies of locally installed packages even if non CRAN: [packrat:::recursivePackageDependencies](https://rdrr.io/cran/packrat/src/R/recursive-package-dependencies.R)
`packrat:::recursivePackageDependencies(""EJAM"", ignores = NULL, lib.loc = .libPaths())`
- See dependencies of CRAN packages:  [tidymodels::pkg_deps](https://rdrr.io/github/tidymodels/tidymodels/man/pkg_deps.html)
`print(tidymodels::pkg_deps(x = ""shiny"", recursive = TRUE), n = 32)`
- [pkgdepends](https://r-lib.github.io/pkgdepends/index.html)
- [devtools article about dependencies](https://devtools.r-lib.org/articles/dependencies.html)",@mlfurman3 and @alex-silverman to revisit,,https://api.github.com/repos/USEPA/EJAM/issues/123/comments,11/10/2023,2/10/2025,ejanalysis,alex-silverman,0,0,0,FALSE
151,120,open,Long Report INTERPRETER/ SUMMARIZER IN TEXT ,enhancement|urgency medium|LongReport_output,4538805068|6227894519|6954028026,cfd3d7|FBCA04|304702,New feature or request||static word doc TSD on results of ejam run - via Quarto template,0,"Create a table of rules and thresholds to describe as moderately elevated, high, very high, etc. Interpreter tool that converts raw output tables to sentences summarizing key notable findings.  see separate notes",,,https://api.github.com/repos/USEPA/EJAM/issues/120/comments,11/8/2023,6/17/2024,ejanalysis,ejanalysis,1,0,0,FALSE
152,119,open,Long Report text needed,enhancement|good first issue|LongReport_output|urgency high-ish but not a bug,4538805068|4538805069|6954028026|7539794549,cfd3d7|7057ff|304702|B9463A,"New feature or request|Good for newcomers|static word doc TSD on results of ejam run - via Quarto template|for high urgency enhancements, to rank them just below high urgency bugs",2,"Write text for the long word doc report, to confirm what points will be made in what order and phrasing. need a easy-to-use template approach, like how the glue package lets you easily insert in-line information. need to decide where the code goes that converts raw results into interpretive sentences, like the ___ indicator was __very__ high overall (average of cx%) etc. etc. 

This is urgent in the sense that it will be very valuable and can be started immediately and done in parallel with R-related work around bug fixes, replicating EJScreen numbers, deployment, etc.  As long as it does not slow down those goals, it is high urgency.

Also see other issues tagged as related to ""[LongReport_output](https://github.com/USEPA/EJAM/labels/LongReport_output)""","Draft skeleton is in inst subfolder, subfolder written report, is .Rmd document. 
  - https://github.com/USEPA/EJAM/blob/main/inst/report/written_report/report.Rmd

Examples of published EJ analyses EPA has written to support national rulemakings: 

  - U.S.EPA. 2024a. Final Regulatory Impact Analysis for the Proposed Reconsideration of the National Ambient Air Quality Standards for Particulate Matter. U.S. Environmental Protection Agency, EPA-HQ-OAR-2015-0072. https://www.epa.gov/system/files/documents/2024-02/naaqs_pm_reconsideration_ria_final.pdf
  - U.S. EPA. 2024b. Regulatory Impact Analysis for the Safer Communities by Chemical Accident Prevention Final Rule. EPA-HQ-OLEM-2022-0174. https://www.regulations.gov/document/EPA-HQ-OLEM-2022-0174-0582
  - U.S.EPA. 2023a. Economic Analysis of the Proposed Reconsideration of the Dust-Lead Hazard Standards and Post-Abatement Clearance Levels. U.S. Environmental Protection Agency, Office of Pollution Prevention and Toxics. EPA-HQ-OPPT-2023-0231-0393. https://www.regulations.gov/document/EPA-HQ-OPPT-2023-0231-0393
  - U.S.EPA. 2023b. Economic Analysis for the Proposed Perand Polyfluoroalkyl Substances National Primary Drinking Water Regulation. EPA-HQ-OW-2022-0114-0028. https://www.regulations.gov/document/EPA-HQ-OW-2022-0114-0028
  - U.S.EPA. 2023c. Environmental Justice Analysis for the Proposed Lead and Copper Rule Improvements. EPA-HQ-OW-2022-0801. https://www.regulations.gov/document/EPA-HQ-OW-2022-0801-0689
  - U.S. EPA. 2023d. Preamble for Proposed New Source Performance Standards for the Synthetic Organic Chemical Manufacturing Industry and National Emission Standards for Hazardous Air Pollutants for the Synthetic Organic Chemical Manufacturing Industry and Group I & II Polymers and Resins Industry. EPA-HQ-OAR-2022-0730. https://www.govinfo.gov/content/pkg/FR-2023-04-25/pdf/2023-07188.pdf
  - U.S.EPA. 2023e. Regulatory Impact Analysis: Hazardous and Solid Waste Management System: Disposal of Coal Combustion Residuals from Electric Utilities; Legacy CCR Surface Impoundments. EPA-HQ-OLEM-2020-0107-0164. https://www.regulations.gov/document/EPA-HQ-OLEM-2020-0107-0164
  - U.S.EPA. 2022a. Economic Analysis of the TSCA Section 6 Proposed Rule for Asbestos Risk Management, Part 1. EPA-HQ-OPPT-2021-0057-0008. https://www.regulations.gov/document/EPA-HQ-OPPT-2021-0057-0008

Many examples of EPA EJ analysis reports are from HAP (haz air pollutant) NESHAP MACT RTR/NSPS rules -- Template-based reports are produced on many OAR rules and put in rule dockets as TSD (tech support document) to back up the rule preamble and/or a chapter of the RIA (reg impacts analysis) -- They call them demographic proximity analyses, and use them for many hazardous air pollutants RTRs (risk/tech. review under section 112 d and f) and for some other rules. Examples of those documents: 

  - https://www.regulations.gov/document/EPA-HQ-OAR-2023-0072-8401  page links to this TSD on the 2024 greenhouse gas EGU NSPS EG rule: https://downloads.regulations.gov/EPA-HQ-OAR-2023-0072-8401/content.pdf
  - Typical demographic proximity report for one RTR: https://www.regulations.gov/document/EPA-HQ-OAR-2020-0430-0210

EPA publishes many proposed rules with EJ analysis. A listing that includes the great majority of recent ones (some are brief discussions and some are extensive reports) can be generated with a query like the following: 

  - [Query of federal register showing many EPA published rules that had EJ analysis in recent years](https://www.federalregister.gov/documents/search?conditions%5Bagencies%5D%5B%5D=environmental-protection-agency&conditions%5Bpublication_date%5D%5Bgte%5D=01%2F01%2F2022&conditions%5Bterm%5D=%28%22demographic+analysis%22+%7C+%22justice+analysis%22+%7C+%22proximity+analysis%22+%7C+hispanic+%7C+african-american+%7C+poverty+%29+-%28%28%22Air+Plan%22+%7C+%22Air+Plans%22+%7C+%22State+Plans%22+%7C+%22Implementation+Plan%22%29++-%22reconsideration+of+the+national%22+-effluent+-%22aircraft+engines%22+-%28%22Office+of+Air+Quality+Planning+and+Standards%22+%26+%22NESHAP%22+%26+%28%22National+Emission+Standards+for+Hazardous+Air%22+%7C+%22National+Emissions+Standards+for+Hazardous+Air%22%29%29%29&conditions%5Btype%5D%5B%5D=RULE
). 
|Assigned to Teagan",,https://api.github.com/repos/USEPA/EJAM/issues/119/comments,11/8/2023,9/30/2024,ejanalysis,none,0,1,1,FALSE
153,118,open,Map-Table linked interactivity ,enhancement|urgency medium|maps-related,4538805068|6227894519|6228710425,cfd3d7|FBCA04|C2E0C6,New feature or request||related to maps,0,"Map-Table linked interactivity: when viewing table of all sites results, I think users would prefer to see a zoomed out map that clearly highlights/colors/animates? point on map for each site briefly as you mouse hover over them in the table, and stays highlighted if you click one or more sites in the table. As a linked, related feature - somehow integrated in a logical way, when viewing table of all sites results, I think users would prefer to see a zoomed out map where if you mouse hover over points on the map, they briefly get highlighted on the map. But also see isse about how many maps and what each does.",,,https://api.github.com/repos/USEPA/EJAM/issues/118/comments,11/8/2023,10/9/2024,ejanalysis,none,1,0,0,FALSE
154,113,open,Replicating EJScreen: MAKE EJAM REPLICATE EJSCREEN RESULTS (overview of issues/tasks),enhancement|good first issue|test|urgency medium|distance-related|calculate/validate to EJScreen,4538805068|4538805069|6148706060|6227894519|6343333395|6343712128,cfd3d7|7057ff|6F7271|FBCA04|C2E0C6|FBCA04,"New feature or request|Good for newcomers|test to be developed||related to distances variables or calculations or plots|related to errors in numbers, replicating EJScreen stats",0,"This issue is just an outline of what specifics are split out into other issues like #283 , #9, #185, #226, #31 and #38 and #241. Also it replaces issue #10 

1. **Update to new data and methods in mid-2024 version of EJScreen** This is #285 
2. **Reconcile _output formats_:**   Done, and Covered by #241  Modify ejscreenapi outputs to match EJAM's 
3. **_block points and population counts_ in circular buffers:**  - Covered by #283 now
4. Do replication checks for population counts:     - This is spelled out in #9 

5. **Reconcile _formulas / other indicators_:**

   a) Obtain SAIC code on formulas used to aggregate indicators, and on the **percentile** lookups in tables usastats and statestats (and even to create those tables in the first place).
     - DONE - WE HAVE THIS

   b) Try to modify EJAM code to match EJScreen method if they clearly differ. Best candidates for differences are **percentiles** lookup table usage, **rounding** at various stages of calculations, significant digits versus decimals **rounding**; and the actual **formulas** used for some indicators might be different in EJAM than EJScreen.
     - See #185 on using weighted means and denominators or weights.
     - See #226 on rounding (and signif digits)
     **- See ********* on different method and/or lookup table used to convert scores to percentiles**
   
   c) For the indicators other than total population counts, redo the replication analysis: run a large sample of sites at various distances through both tools, summarize which indicators differ how often by how much. Dig into and identify what might be the causes for differences. Confirm everything matches to some tolerance amount at least some target % of the time. **Document** any outstanding differences if relevant. 
    - DONE BUT SHOULD REDO AFTER ANY MORE CHANGES.  
    - See #9 ",,,https://api.github.com/repos/USEPA/EJAM/issues/113/comments,11/8/2023,1/10/2025,ejanalysis,ejanalysis,1,0,0,FALSE
155,99,open,Investigate options for asynchronous processing in R Shiny (espec for speed / performance at launch),good first issue|story|datasets/ pins/ AWS/ etc.|speed / performance (see #444)|urgency high-ish but not a bug,4538805069|6148703621|6343736234|6535412240|7539794549,7057ff|1D76DB|0E8A16|e99695|B9463A,"Good for newcomers|user story|related to data files via pins board, AWS, dataload_ etc.|related to monitoring the app too but mostly about speed / load, profiling, asynch, sessions,, etc.|for high urgency enhancements, to rank them just below high urgency bugs",2,"(also see issue #231 )

Shiny apps are limited by R's single-threaded nature. So if one user has a session where they are analyzing large amounts of data, it could prevent EJAM from being able to create graphics for another user, until the first, longer process is done. Since we have some large datasets and slow processing functions, this may become a problem as EJAM gets used by more people over time.

Asynchronous (or async) programming offers a way to offload large computations to another R process and let the ""main"" process continue working while they. This involves use of the {future} and {promises} packages, which can be combined with Shiny. However, they do not pass and return data easily (they use a ""promise"" of a data frame rather than the actual data), so this would require a fair amount of refactoring of our data pipeline.

**Resources:**
- **[NEW VIDEO](https://www.youtube.com/watch?v=GhX0PcEm3CY) 5/2024 from Joe Cheng/ Posit, about how to use the new feature in shiny 1.8.1, ""[ExtendedTask](https://shiny.posit.co/r/reference/shiny/latest/extendedtask)""**  or https://shiny.posit.co/r/articles/improve/nonblocking/index.html 
- repository about async in shiny: https://github.com/hypebright/async_shiny?tab=readme-ov-file#readme  
- See other good videos on asynch including **callR** and other approaches, in email MC sent MF in mid/early Nov 2023
- older Joe Cheng talk on [Scaling Shiny apps with Async Programming](https://posit.co/resources/videos/scaling-shiny-apps-with-async-programming/)
- [Improving scalability with async programming](https://shiny.posit.co/r/articles/improve/async/)
- [Using `promises` with Shiny](https://rstudio.github.io/promises/articles/promises_06_shiny.html)
- https://support.posit.co/hc/en-us/articles/231874748-Scaling-and-Performance-Tuning-in-Posit-RStudio-Connect
- see https://appsilon.github.io/shiny.worker/
- clear explanation of tradeoff between fast start for 2d/3d users versus fast performance for each user, here:
https://support.posit.co/hc/en-us/articles/231874748-Scaling-and-Performance-Tuning-in-Posit-RStudio-Connect
- look into `Shiny.renderDependenciesAsync()`, `Shiny.renderHtmlAsync()`, and `Shiny.renderContentAsync()`.
","Reassigning to @andreasmaier-abt 
cc: @alex-silverman |@alex-silverman - will reassign and get in touch",,https://api.github.com/repos/USEPA/EJAM/issues/99/comments,11/8/2023,12/2/2024,mlfurman3,alex-silverman,0,1,1,FALSE
156,94,open,Enable fast site selection map during category scrolling,enhancement|urgency low|maps-related,4538805068|6227891676|6228710425,cfd3d7|cfd3d7|C2E0C6,New feature or request||related to maps,0,"**From Mark**
enhancement: it would be neat and kind of informative to interactively immediately see the map change to show new points (& new sites count in box) as you scroll through the pulldown of MACT or EPA Program categories - maybe that could be fast via caching every possible map (one per category), or some tricky approach possibly more memory-efficient but less speedy like caching a full map of ALL points and filtering to show only the relevant ones as you hover over categories. You could simplify to ignore radius and overlaps etc etc during that hovering preview, and only do those extra map refinements when a category is actually picked. If this could be done for NAICS and SIC that would be nice too, noting the counts are bigger and the yes/no subcategory button matters there.

**Ideas**
- I'm not sure that R Shiny has the ability to update its input values only on hover. However, there may be a way to scroll through once one is clicked on using up and down arrow keys - TBD.
- We can still explore caching maps - or at least pre-processed datasets - for these categorical site selection options. That may cut down on time needed to display these maps when users are switching between NAICS codes quickly, for example.",,,https://api.github.com/repos/USEPA/EJAM/issues/94/comments,11/8/2023,10/9/2024,mlfurman3,none,0,0,0,FALSE
157,91,open,Remove unused report template files,enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,0,"*From Mark*
Reconcile EJAM/www and EJAM/inst/app/www folders and EJAM/inst/report to delete unused ones and keep useful files still.

**Ideas**

- Use only one folder for report files, most likely `inst/report/` and ensure that the path can be reached to read and write from the EJAM Shiny app. 
- Remove anything related to the old EJScreen report format, as well as placeholder images.
- Example PDF files do not belong in a folder that gets installed with the package itself; these should probably go with `vignettes` or be linked in the README.",,,https://api.github.com/repos/USEPA/EJAM/issues/91/comments,11/7/2023,9/5/2024,mlfurman3,none,0,0,0,FALSE
158,90,open,Include indicator formulas in Community Report,enhancement|urgency low,4538805068|6227891676,cfd3d7|cfd3d7,New feature or request|,0,"**From Mark**
Write code/ formulas for aggregating and displaying other indicators in community report, all the ones indicated in  EJAMejscreenapi::map_headernames[EJAMejscreenapi::map_headernames$reportsort != """", c(""rname"", ""reportlabel"", ""reportsort"", ""longname_tableheader"")] 

**Ideas**

This is tied to the development of the community report https://github.com/USEPA/EJAM/issues/48 , but should not happen until the html template and formatting of graphics, tables, and text is worked out.

",,,https://api.github.com/repos/USEPA/EJAM/issues/90/comments,11/7/2023,10/9/2024,mlfurman3,none,0,0,0,FALSE
159,73,open,Allow abort site selection processing when selections are changed,enhancement|good first issue|urgency high-ish but not a bug,4538805068|4538805069|7539794549,cfd3d7|7057ff|B9463A,"New feature or request|Good for newcomers|for high urgency enhancements, to rank them just below high urgency bugs",2,"When changing between site selections such as different NAICS codes, MACT subparts, etc. the code, and subsequently the preview map and preview dataset, does not update until the previous query is completed. This is problematic if a group with a large number of sites is accidentally selected or is the default selection. This is related to https://github.com/USEPA/EJAM/issues/72 because the slowness of the processing creates additional lag time.

We need a way to check during the initial data processing whether the inputs have changed and, if so, create a way to abort the previous selection and start the new one. Unsure if this should be a backend behavior, or if we need a button to interrupt the huge batch and a warning modal to confirm.

From Mark:
when you give up and pick a different one, even a small category, it still takes a while - not sure if it is trying to finish the long query first? That may be moot if all queries are pretty much instant, but you should be able to interrupt/ abort a slow query if there are any.",Reassigning ticket to @andreasmaier-abt cc: @alex-silverman |@alex-silverman will reassign and get in touch,,https://api.github.com/repos/USEPA/EJAM/issues/73/comments,11/7/2023,12/2/2024,mlfurman3,alex-silverman,0,1,1,FALSE
160,70,open,Review/revise/expand unit testing for FRS functions,test|urgency low,6148706060|6227891676,6F7271|cfd3d7,test to be developed|,3,"Develop unit tests for functions that read and process EPA facility registry service, or FRS, IDs. For those that already have tests, confirm that they still work as designed.

Will need to determine which ones, if any, are still used by EJAM app and prioritize those first. Check the following scripts to find FRS-related functions:

- [frs_from_siteid.R](https://github.com/USEPA/EJAM/blob/main/R/frs_from_siteid.R)
- [frs_is_valid.R](https://github.com/USEPA/EJAM/blob/main/R/frs_is_valid.R)"," There are still many tests failing.  Many still seem to be failing because the test was not written carefully.  I fixed some more today. But this is the latest tally:

**[ FAIL 68 | WARN 62 | SKIP 1 | PASS 668 ]**

 Terminated early 

|@mlfurman3 requesting reassignment - no time for unit testing|Archiving old test ticket",,https://api.github.com/repos/USEPA/EJAM/issues/70/comments,11/1/2023,11/22/2024,mlfurman3,none,0,0,0,FALSE
161,69,open,Review/revise/expand unit testing for SIC functions,test|urgency low,6148706060|6227891676,6F7271|cfd3d7,test to be developed|,1,"Develop unit tests for functions that read and process SIC codes. For those that already have tests, confirm that they still work as designed.

Will need to determine which ones, if any, are still used by EJAM app and prioritize those first. Check the following scripts to find SIC-related functions:

- [sic_categories.R](https://github.com/USEPA/EJAM/blob/main/R/sic_categories.R)
- [sic_from_any.R](https://github.com/USEPA/EJAM/blob/main/R/sic_from_any.R)

We may also need to pull out SIC functionality from `app_server.R` into separate functions during refactoring.",@mlfurman3 requesting reassignment - no time for unit testing,,https://api.github.com/repos/USEPA/EJAM/issues/69/comments,11/1/2023,11/22/2024,mlfurman3,none,0,0,0,FALSE
162,68,open,Review/revise/expand unit testing for FIPS code functions,test|urgency low,6148706060|6227891676,6F7271|cfd3d7,test to be developed|,2,"Develop unit tests for functions that read and process FIPS codes. For those that already have tests, confirm that they still work as designed.

Will need to determine which ones, if any, are still used by EJAM app and prioritize those first. Check the following scripts to find FIPS code-related functions:

- [fips_counties_from.R](https://github.com/USEPA/EJAM/blob/main/R/fips_counties_from.R)
- [fips_lead_zero.R](https://github.com/USEPA/EJAM/blob/main/R/fips_lead_zero.R)
- [fipsbg_from_anyfips.R](https://github.com/USEPA/EJAM/blob/main/R/fipsbg_from_anyfips.R)
- [getblocksnearby_from_fips.R](https://github.com/USEPA/EJAM/blob/main/R/getblocksnearby_from_fips.R)",@mlfurman3 requesting reassignment - no time for unit testing|@mlfurman3 requesting reassignment - no time for unit testing,,https://api.github.com/repos/USEPA/EJAM/issues/68/comments,11/1/2023,11/22/2024,mlfurman3,none,0,0,0,FALSE
163,67,open,MODULE? Review/revise/expand unit testing for shapefile functions,test|refactor|urgency low|shapefile-related|server,6148706060|6208400114|6227891676|6343756696|7384237694,6F7271|8F13A1|cfd3d7|C2E0C6|25B9F0,test to be developed|Rewrite how code works or break into smaller pieces||related to polygons/ shapefile/ GIS data/ buffers|removing code from app_server.R,1,"Develop unit tests for functions that read and process shapefiles. For those that already have tests, confirm that they still work as designed.

Check the following scripts to find shapefile-related functions:

- [get_blockpoints_in_shape.R](https://github.com/USEPA/EJAM/blob/main/R/get_blockpoints_in_shape.R)
- [get_shapefile_from_sitepoints.R](https://github.com/USEPA/EJAM/blob/main/R/get_shapefile_from_sitepoints.R)
- [get_shape_buffered_from_shapefile_points.R](https://github.com/USEPA/EJAM/blob/main/R/get_shape_buffered_from_shapefile_points.R)

Mark has also started a Shiny module related to shapefiles - TBD if we will incorporate that into the EJAM app.
",@mlfurman3 requesting reassignment - no time for unit testing,,https://api.github.com/repos/USEPA/EJAM/issues/67/comments,11/1/2023,10/15/2024,mlfurman3,ParkerJanMalek,0,0,0,FALSE
164,66,open,Review/revise/expand unit testing for lat/lon functions,test|urgency low,6148706060|6227891676,6F7271|cfd3d7,test to be developed|,2,"Develop unit tests for functions that read and process lat/lon sites. For those that already have tests, confirm that they still work as designed.

Will need to determine which ones, if any, are still used by EJAM app and prioritize those first. Check the following scripts to find latlon-related functions:

- [latlon_as.numeric.R](https://github.com/USEPA/EJAM/blob/main/R/latlon_as.numeric.R)
- [latlon_df_clean.R](https://github.com/USEPA/EJAM/blob/main/R/latlon_df_clean.R)
- [latlon_from_anything.R](https://github.com/USEPA/EJAM/blob/main/R/latlon_from_anything.R)
- [latlon_from_mactsubpart.R](https://github.com/USEPA/EJAM/blob/main/R/latlon_from_mactsubpart.R)
- [latlon_from_naics.R](https://github.com/USEPA/EJAM/blob/main/R/latlon_from_naics.R)
- [latlon_from_program.R](https://github.com/USEPA/EJAM/blob/main/R/latlon_from_program.R)
- [latlon_from_programid.R](https://github.com/USEPA/EJAM/blob/main/R/latlon_from_programid.R)
- [latlon_from_siteid.R](https://github.com/USEPA/EJAM/blob/main/R/latlon_from_siteid.R)
- [latlon_infer.R](https://github.com/USEPA/EJAM/blob/main/R/latlon_infer.R)
- [latlon_is.valid.R](https://github.com/USEPA/EJAM/blob/main/R/latlon_is.valid.R)
- [state_from_latlon.R](https://github.com/USEPA/EJAM/blob/main/R/state_from_latlon.R)",@mlfurman3 requesting reassignment - no time for unit testing|Archiving old test ticket,,https://api.github.com/repos/USEPA/EJAM/issues/66/comments,11/1/2023,11/22/2024,mlfurman3,none,0,0,0,FALSE
165,65,open,Review/revise/expand unit testing for NAICS functions,test|tasklist|urgency medium|URL-related,6148706060|6148808139|6227894519|6228638798,6F7271|8E5406|FBCA04|C2E0C6,test to be developed|single issue containing a list of sub-tasks or sub-issues||relates to functions making URLs for links to reports,2,"Develop unit tests for functions that read and process NAICS codes. For those that already have tests, confirm that they still work as designed.

Will need to determine which ones, if any, are still used by EJAM app and prioritize those first. Check the following scripts to find NAICS-related functions:

- [ ] [naics_categories.R](https://github.com/USEPA/EJAM/blob/main/R/NAICS_FUNCTIONS.R)  --   [(help doc)](https://usepa.github.io/EJAM/reference/naics_categories.html)
- [ ] [naics_findwebscrape.R](https://github.com/USEPA/EJAM/blob/main/R/NAICS_FUNCTIONS.R)  --   [(help doc)](https://usepa.github.io/EJAM/reference/naics_findwebscrape.html)
- [ ] [naics_validation.R](https://github.com/USEPA/EJAM/blob/main/R/NAICS_FUNCTIONS.R)  --   [(help doc)](https://usepa.github.io/EJAM/reference/naics_validation.html)
- [ ] [naics2children.R](https://github.com/USEPA/EJAM/blob/main/R/NAICS_FUNCTIONS.R)  --   [(help doc)](https://usepa.github.io/EJAM/reference/naics2children.html)
- [ ] [naics_download.R](https://github.com/USEPA/EJAM/blob/main/R/NAICS_FUNCTIONS.R)  --   [(help doc)](https://usepa.github.io/EJAM/reference/naics_download.html)
- [ ] [naics_from_any.R](https://github.com/USEPA/EJAM/blob/main/R/NAICS_FUNCTIONS.R)  --   [(help doc)](https://usepa.github.io/EJAM/reference/naics_from_any.html)
- [ ] [naics_from_federalregister.R](https://github.com/USEPA/EJAM/blob/main/R/NAICS_FUNCTIONS.R)  --   [(help doc)](https://usepa.github.io/EJAM/reference/naics_from_federalregister.html)
- [ ] [latlon_from_naics.R](https://github.com/USEPA/EJAM/blob/main/R/latlon_from_naics.R)  --   [(help doc)](https://usepa.github.io/EJAM/reference/latlon_from_naics.html)
- [ ] [frs_from_naics](https://github.com/USEPA/EJAM/blob/HEAD/R/frs_from_xyz.R) --   [(help doc)](https://usepa.github.io/EJAM/reference/frs_from_naics.html)
- [ ] [regid_from_naics](https://github.com/USEPA/EJAM/blob/main/R/latlon_from_naics.R)  --   [(help doc)](https://usepa.github.io/EJAM/reference/regid_from_naics.html)
- [ ] [url_naics.com.R](https://github.com/USEPA/EJAM/blob/HEAD/R/URL_FUNCTIONS_part2.R)  --   [(help doc)](https://usepa.github.io/EJAM/reference/url_naics.com.html)","see notes on test results in  EJAM\tests\manual_nonalphabetical.R
These test files account for the erorrs or warnings in testing NAICS-related functions:  
```
  #                                          file fails_byfile fails_bygroup      testgroup
# 5:                     test-naics_from_code.R            4             8     test_naics
  # 6:                    test-naics_validation.R            2             8     test_naics
  # 7:                     test-naics_from_name.R            1             8     test_naics
  # 8:                 test-naics_findwebscrape.R            1             8     test_naics
```|@mlfurman3 to review if completed.",,https://api.github.com/repos/USEPA/EJAM/issues/65/comments,11/1/2023,2/10/2025,mlfurman3,sarasoko,1,0,0,FALSE
166,64,open,MODULE: make a Shiny module for typing in lat/lon values,enhancement|good first issue|story|refactor|urgency medium|server,4538805068|4538805069|6148703621|6208400114|6227894519|7384237694,cfd3d7|7057ff|1D76DB|8F13A1|FBCA04|25B9F0,New feature or request|Good for newcomers|user story|Rewrite how code works or break into smaller pieces||removing code from app_server.R,0,"Mark has created a Shiny module (see [Ch. 19 of Mastering Shiny](https://mastering-shiny.org/scaling-modules.html)) within the EJAM shiny app to allow for the option to type in lat/lon values manually on the site selection page - see ['R/MODULE_latlontypedin.R'](https://github.com/USEPA/EJAM/blob/main/R/MODULE_latlontypedin.R) for details. As of now, it does not fully cooperate with the EJAM app due to Shiny reactivity issues.

Review steps needed
- review module code to ensure it makes sense as standalone code
- work out any namespacing issues for input and output IDs
- confirm that shiny inputs, outputs, and reactives can be passed to and retrieved from the module code
- integrate the module with EJAM app server functionality
  - make sure it can work with current site selection pieces
  - make sure it can bypass EJAM processing functions and return data in same format - especially columns!
- incorporate module into the UI and adjust appearance ",,,https://api.github.com/repos/USEPA/EJAM/issues/64/comments,11/1/2023,12/2/2024,mlfurman3,alex-silverman,1,0,0,FALSE
167,63,open,"MODULE: Review, fix, and incorporate Shiny module for EJAMejscreenapi functionality",bug|enhancement|good first issue|refactor|urgency medium|calculate/validate to EJScreen|server,4538805065|4538805068|4538805069|6208400114|6227894519|6343712128|7384237694,d73a4a|cfd3d7|7057ff|8F13A1|FBCA04|FBCA04|25B9F0,"Something isn't working|New feature or request|Good for newcomers|Rewrite how code works or break into smaller pieces||related to errors in numbers, replicating EJScreen stats|removing code from app_server.R",1,"Mark has created a Shiny module (see [Ch. 19 of Mastering Shiny](https://mastering-shiny.org/scaling-modules.html)) within the EJAM shiny app to allow for the option to use the EJAMejscreenapi method for analyzing sites rather than the EJAM method - see ['R/MODULE_ejscreenapi.R'](https://github.com/USEPA/EJAM/blob/main/R/MODULE_ejscreenapi.R) for details. As of now, it does not fully cooperate with the EJAM app due to Shiny reactivity issues.

Review steps needed
- review module code to ensure it makes sense as standalone code
- work out any namespacing issues for input and output IDs
- confirm that shiny inputs, outputs, and reactives can be passed to and retrieved from the module code
- integrate the module with EJAM app server functionality
  - make sure it can work with current site selection pieces
  - make sure it can bypass EJAM processing functions and return data in same format - especially columns!
- incorporate module into the UI and adjust appearance ","This needs to work as app or be removed? differs from the module ??
this had worked and does not now?
[app_run_EJAMejscreenapi()](https://usepa.github.io/EJAM/reference/app_run_EJAMejscreenapi.html)",,https://api.github.com/repos/USEPA/EJAM/issues/63/comments,11/1/2023,1/7/2025,mlfurman3,alex-silverman,1,0,0,FALSE
168,58,open,Review/revise/expand unit testing for URL functions,test|urgency low|URL-related,6148706060|6227891676|6228638798,6F7271|cfd3d7|C2E0C6,test to be developed||relates to functions making URLs for links to reports,1,"Develop unit tests for functions that build or generate URLs. For those that already have tests, confirm that they still work as designed. 

Will need to determine which ones, if any, are still used by EJAM app and prioritize those first. Check the following scripts to find URL-related functions:

- [ ] [url_4table.R](https://github.com/USEPA/EJAM/blob/main/R/url_4table.R)
- [ ] [url_naics.com.R](https://github.com/USEPA/EJAM/blob/main/R/url_naics.com.R)
- [ ] [url_bookmark-DRAFT.R]()
- [ ] [naics_url_of_code.R](https://github.com/USEPA/EJAM/blob/main/R/NAICS_url_of_code.R)
- [ ] [url_get_via_url-DRAFT.R](https://github.com/USEPA/EJAM/blob/main/R/url_get_via_url-DRAFT.R)                                                     
- [ ] [url_getacs_epaquery-DRAFT.R](https://github.com/USEPA/EJAM/blob/main/R/url_getacs_epaquery-DRAFT.R)                                                 
- [ ] [url_to_any_rest_services_ejscreen_ejquery-DRAFT.R](https://github.com/USEPA/EJAM/blob/main/R/url_to_any_rest_services_ejscreen_ejquery-DRAFT.R)
- [ ] [url_to_get_ACS2019_rest_services_ejscreen_ejquery_MapServer_7-DRAFT.R](https://github.com/USEPA/EJAM/blob/main/R/url_to_get_ACS2019_rest_services_ejscreen_ejquery_MapServer_7-DRAFT.R)
- [ ] [url_to_get_nearby_blocks_rest_services_ejscreen_ejquery_MapServer_71-DRAFT.R](https://github.com/USEPA/EJAM/blob/main/R/url_to_get_nearby_blocks_rest_services_ejscreen_ejquery_MapServer_71-DRAFT.R)
",@mlfurman3 requesting reassignment - no time for unit testing,,https://api.github.com/repos/USEPA/EJAM/issues/58/comments,10/31/2023,11/22/2024,mlfurman3,none,0,0,0,FALSE
169,51,open,Remove extraneous comments from Shiny app scripts,refactor|urgency medium|server,6208400114|6227894519|7384237694,8F13A1|FBCA04|25B9F0,Rewrite how code works or break into smaller pieces||removing code from app_server.R,1,"The app_ui.R and app_server.R scripts have become bloated as the app has grown over time. There is a need to cleanup defunct components from these files that is no longer used and is fully commented out, such as in the UI [here](https://github.com/USEPA/EJAM/blob/e5efaf0efe9202963f5f053b9d4d9e0f25701b06/R/app_ui.R#L466C18-L512C22) and [here](https://github.com/USEPA/EJAM/blob/e5efaf0efe9202963f5f053b9d4d9e0f25701b06/R/app_ui.R#L747C19-L764C105) and in the server code [here](https://github.com/USEPA/EJAM/blob/e5efaf0efe9202963f5f053b9d4d9e0f25701b06/R/app_server.R#L86C5-L97C8) and [here](https://github.com/USEPA/EJAM/blob/e5efaf0efe9202963f5f053b9d4d9e0f25701b06/R/app_server.R#L2087C7-L2114C126).

These lines of code can be deleted in full, it is not necessary to keep them in a separate script or text file. They can be recovered from a previous commit if they become needed at a later time. ","**Additional comments from Mark**

Reduce size of EJAM package deployed by removing or not importing parts of EJAMbatch.summarizer and EJAMejscreenapi packages

\# Most of the code is in these files: 
\#    lines comments code              package where                           filename
\# 2   1702        8 1694 EJAMbatch.summarizer   /R/                       app_server.R ** NOT USED BY EJAM. avoid importing / loading with EJAM? JUST import KEY FUNCTIONS?
\# 5   1169       19 1150                 EJAM   /R/                           app_ui.R 
\# 6   1084       16 1068 EJAMbatch.summarizer   /R/                           app_ui.R ** NOT USED BY EJAM. If do not need standalone summarizer, REMOVE ui AND JUST USE pkg for its KEY FUNCTIONS?
\# 9    719        2  717      EJAMejscreenapi   /R/                       app_server.R ** NOT USED BY EJAM. avoid importing / loading with EJAM? JUST import KEY FUNCTIONS?
\# 10   623       20  603      EJAMejscreenapi   /R/                           app_ui.R ** NOT USED BY EJAM. avoid importing / loading with EJAM? 

",,https://api.github.com/repos/USEPA/EJAM/issues/51/comments,10/30/2023,9/5/2024,mlfurman3,none,1,0,0,FALSE
170,50,open,"Move HTML, CSS, and Javascript code into appropriate external files",refactor|urgency medium|server,6208400114|6227894519|7384237694,8F13A1|FBCA04|25B9F0,Rewrite how code works or break into smaller pieces||removing code from app_server.R,0,"Action: take non-R code that relates to UI appearance, JS functions, or formatting out of app_ui.R and app_server.R code out of and into scripts within the `inst/app/www` folder. These scripts can then be loaded at the top of app_ui.R. 

Examples include
- raw HTML used for bullet points or help text, such as [here](https://github.com/USEPA/EJAM/blob/5892c53ca7296d80c02ab8467aa95b1509ac5963/R/app_ui.R#L191C23-L197C25)
- CSS applied to Shiny components, like [wellPanel](https://github.com/USEPA/EJAM/blob/5892c53ca7296d80c02ab8467aa95b1509ac5963/R/app_ui.R#L169C16-L169C72) and [radioButtons](https://github.com/USEPA/EJAM/blob/5892c53ca7296d80c02ab8467aa95b1509ac5963/R/app_ui.R#L295C23-L300C25)
- Javascript functions, such as [scrolling to top](https://github.com/USEPA/EJAM/blob/5892c53ca7296d80c02ab8467aa95b1509ac5963/R/app_ui.R#L20C6-L21C113)",,,https://api.github.com/repos/USEPA/EJAM/issues/50/comments,10/30/2023,9/5/2024,mlfurman3,none,1,0,0,FALSE
171,49,open,*** MOVE CODE OUT OF SERVER and app_ui,tasklist|refactor|urgency medium|server,6148808139|6208400114|6227894519|7384237694,8E5406|8F13A1|FBCA04|25B9F0,single issue containing a list of sub-tasks or sub-issues|Rewrite how code works or break into smaller pieces||removing code from app_server.R,0,"**Moving a lot of code out of app_server.R will be very helpful. It is hard to collaborate, test, debug and enhance anything in server/app when so much code is in that one file (app_server.R).**  (See new [issues tag ""server""](https://github.com/USEPA/EJAM/labels/server))

- [**Functions** are one key way to move code out of server](https://mastering-shiny.org/scaling-functions.html#server-functions). There are many chunks of script inside reactives, download handlers, etc. that _should get turned into functions_ that can be stored in separate source files. Note that tricky part is to be sure to handle reactives such that either the function relies only on non-reactive parameters and ideally no global variables;  or you just  code the functions in a way that lets the server pass reactives to the functions as parameters. The syntax is a bit tricky - when to use parentheses on the reactive and when no parens. Books and ref docs on shiny explain this clearly with examples.

- [Modules ](https://www.appsilon.com/post/r-shiny-modules) (and see [modules](https://mastering-shiny.org/scaling-modules.html)) are another way to do this. 

- Moving code out of `app_ui.R `is less critical - mostly useful if there is something repeated many times and that could be replaced with a function.

- Examples of specific chunks of code to pull out are already noted in these specific issues:
  - [ ] Reduce _redundant_ code chunks in app_server
  - [x] #493
  - [ ] #63 
  - [ ] #64 
  - [ ] #465 
  - [ ] #311 
  - [ ] #234
  - [ ] #235  
  - [ ] #180 
  - [ ] #178
  - [ ] #50  
  - [ ] #51 

",,,https://api.github.com/repos/USEPA/EJAM/issues/49/comments,10/30/2023,1/27/2025,mlfurman3,mlfurman3,1,0,0,FALSE
172,42,open,fix distance_avg in doaggregate()$results_bybg_people,bug|good first issue|urgency medium|distance-related,4538805065|4538805069|6227894519|6343333395,d73a4a|7057ff|FBCA04|C2E0C6,Something isn't working|Good for newcomers||related to distances variables or calculations or plots,2,"approx line 290 of doaggregate() should find avg distance of all people in a blockgroup to a single site, but $results_bybg_people$distance_avg seems to have the same distance_avg for a blockgroup to site 1 and same bg to site 2 -- they should differ. We want to have distance_by_group() be able to use the shorter distance to any of the nearby sites, for a given blockgroup but it somehow is already averaged across all sites the bg is near which isnt what we wanted and isnt what the code below should be doing. 

in doaggregate() 
sites2bgs_bysite    <-    sites2blocks[         , .(bgwt = sum(blockwt, na.rm = TRUE), 
                                                      proximityscore = stats::weighted.mean(proximityscore,   w = blockwt, na.rm = TRUE),
                                                      distance_avg   = stats::weighted.mean(distance,         w = blockwt, na.rm = TRUE),
                                                      sitedistance_min = min(sitedistance_min, na.rm = TRUE),
                                                      sitecount_max    = max(sitecount,        na.rm = TRUE)
  ), by=.(siteid, bgid)]
",@ejanalysis can this be closed?|@ejanalysis what is the status of this ticket?,,https://api.github.com/repos/USEPA/EJAM/issues/42/comments,3/15/2023,1/7/2025,ejanalysis,ejanalysis,1,0,0,FALSE
173,38,open,add siteid (row number 1 to n) to ejscreenapi outputs ,enhancement|good first issue|refactor|urgency low|calculate/validate to EJScreen,4538805068|4538805069|6208400114|6227891676|6343712128,cfd3d7|7057ff|8F13A1|cfd3d7|FBCA04,"New feature or request|Good for newcomers|Rewrite how code works or break into smaller pieces||related to errors in numbers, replicating EJScreen stats",1,EJAM provides this and ejscreenapi code could easily as well - helps keep track of which input site matches which output site,BUT see changes made circa 12/2023 in development branch that moved from using siteid to ejam_uniq_id as column name... ,,https://api.github.com/repos/USEPA/EJAM/issues/38/comments,2/23/2023,9/5/2024,ejanalysis,none,0,0,0,FALSE
174,37,open,"add NUM_NPL, NUM_TSDF to EJAM::doaggregate() outputs (as already provided by EJAMejscreenapi::ejscreenapi() output)",enhancement|good first issue|urgency low|calculate/validate to EJScreen,4538805068|4538805069|6227891676|6343712128,cfd3d7|7057ff|cfd3d7|FBCA04,"New feature or request|Good for newcomers||related to errors in numbers, replicating EJScreen stats",0,"if possible, include these. Not sure how EJScreen gets that info, though. we could get it from the api but it is slow. they must have the whole list of NPL site points in usa (about 1600 of them?) and TSDF points (over 8k of them??) 
if too much trouble, skip this. ",,,https://api.github.com/repos/USEPA/EJAM/issues/37/comments,2/23/2023,6/4/2024,ejanalysis,ejanalysis,0,0,0,FALSE
175,36,open,"add info about zero results/ zero pop & near other sites, to EJAM::doaggregate() outputs (as already provided by EJAMejscreenapi::ejscreenapi() output)",enhancement|refactor|urgency low,4538805068|6208400114|6227891676,cfd3d7|8F13A1|cfd3d7,New feature or request|Rewrite how code works or break into smaller pieces|,2,"These 4 columns are provided by ejscreenapi and should be provided by EJAM:

msg  - text message indicating why no results returned (note: this means EJAM must output a row for every input site, even in cases where no blocks were found nearby)

statLayerZeroPopCount ----  count of blockgroups that had zero population in circle (sum of blockweights was 0) 

overlaps_another  --- a flag indicating if the site's circle overlaps any others (see code in ejscreenapi app)

inputAreaMiles = pi * radius.miles^2  in square miles 
","this one is done|This was not actually finished:

- [ ] **overlaps_another** was not added. it should be calculated like this in doaggregate: 
` overlaps_another =  testoutput_ejamit_1000pts_1miles$results_bysite$sitecount_max > 1 `
The entry in map_headernames is probably needed, with longname = ""Overlaps with another site - Some residents are near both sites (or in both polygons)""  as it could be for polygons

- [ ] **inputAreaMiles** was not added.

It should be done via the row in map_headernames that is
 rname = ""inputAreaMiles""
but the longname should be changed to be ""Area in square miles"" since it may be from a polygon or fips not always circular buffer.

It will need to be added in doaggregate() as something that gets returned, and is simply 
` inputAreaMiles <- pi * radius.miles^2 `
for sitetype == ""latlon"" 
but for shapefiles, do this in doaggregate
` inputAreaMiles <- sf::st_area(shp) / (meters_per_mile^2)` (using the buffered shp if buffer was added)

and for FIPS case, ideally we would look it up from census instead of getting the bounds and calculating area! can make it 
` inputAreaMiles <- NA`
 until may add later if no easy quick way for now.

- [ ] **msg** from ejscreenapi functions might be the same as what EJAM calls invalid_msg ? the name in ejscreenapi outputs should be changed to be like the one in EJAM outputs. 

- [ ] **statLayerZeroPopCount** was not added to EJAM outputs, but is an output of ejscreenit(), but I think it might be another name for what EJAM calls `bgcount_zeropop_near_site` so I guess if so then ejscreenapi functions should change the rname they use from statLayerZeroPopCount to that, so the same name would get returned by both.
",,https://api.github.com/repos/USEPA/EJAM/issues/36/comments,2/23/2023,9/6/2024,ejanalysis,none,0,0,0,FALSE
176,34,open,"for each siteid, add ST, statename, and REGION columns to EJAM::doaggregate() outputs (as already provided by EJAMejscreenapi::ejscreenapi() output)",enhancement|refactor,4538805068|6208400114,cfd3d7|8F13A1,New feature or request|Rewrite how code works or break into smaller pieces,4,"This is essential if you want to convert calculated scores at each site (circular buffer) to state percentiles. 

This will be done via sites2states_or_latlon param in doaggregate(), and via states_infer() as used in doaggregate(), partly implemented as of 3/9/23. That param passes siteid,ST lookup table, from server code to doaggregate(), since output of getblocksnearby() does not provide lat lon coords or any info on states.
Code can also can find out which state a point is inside, based on lat/lon coords, using state_from_latlon() and see EJAM/data-raw/make_states_shapefile.R and data(states_shapefile)
","This looks to be partially implemented as of 11/2023? I see the ST and statename variables in doaggregate() output, but not the REGION column.|To add REGION (EPA Region number) to outputs of doaggregate and ejamit() and in server...

see  doaggregate() roughly line 589 that might be where REGION would get added: 
   sites2bgs_plusblockgroupdata_bysite  <- merge(sites2bgs_bysite,  
   blockgroupstats[ , c('bgid', 'ST', ..countcols_inbgstats, ..popmeancols_inbgstats, ..calculatedcols_inbgstats)], 
       all.x = TRUE, all.y = FALSE, by = 'bgid')
but also, around line 1063 TO 1086 see where State info actually assigned to each site!?
    if (missing(sites2states_or_latlon) | !(""ST"" %in% names(sites2states_or_latlon))) 

and fyi, around 1430 it does specify where REGION column would go if available, 
   useful_column_order <- c( 
and fyi, just note at 1320 or so, it uses REGION in the sense of the ST info that is REGION as a colname of statestats, not the EPA Region 
And fyi, also note in app_server around line 2068, 
  dplyr::left_join(stateinfo %>% dplyr::select(ST, statename, REGION), by = 'ST') %>%

Be very careful about the fact that 
1. REGION was the name of the variable for EPA Region (1-10) used in some places to report or analyze by EPA region, as in `EJAM::stateinfo[1:5, ]` and `EJAM::stateinfo2[1:5, ] `  and there is code for example creating  output$view3_table  in app_server() 
2. REGION also is the name of a column in usastats and statestats that is either ""USA"" or the 2-character abbreviation for the State, like TX or NY. See `EJAM::statestats[1:104, 1:5] ` and `EJAM::usastats[1:5, 1:5]`  |this one is done|**This got closed but was not completed so I am reopening it to note that. I finally did this myself -- added REGION to the output of doaggregate() and will put that in a PR. Then when tested and merged, this can actually get closed.**

**REGION was supposed to be added to output of doaggregate() and thus ejamit() etc., but it was only added to the server code** in lines that are something like this in app_server.R
```

dplyr::left_join(stateinfo %>% dplyr::select(ST, statename, REGION), by = 'ST') %>%
      dplyr::mutate(
        REGION = factor(REGION, levels = 1:10),
        statename = factor(statename)
      )  
```
It could have just used the functions designed for this that have unit tests in them, something like this:
```
dt[, REGION := fips_st2eparegion(fips_state_from_state_abbrev(ST))]

```
in both doaggregate() and app_server



> This looks to be partially implemented as of 11/2023? I see the ST and statename variables in doaggregate() output, but not the REGION column.

yes, that was a good catch",,https://api.github.com/repos/USEPA/EJAM/issues/34/comments,2/23/2023,11/22/2024,ejanalysis,ParkerJanMalek,0,0,0,FALSE
177,29,open,add ability to save/load/bookmark static report settings (the parameters),enhancement|refactor|urgency low,4538805068|6208400114|6227891676,cfd3d7|8F13A1|cfd3d7,New feature or request|Rewrite how code works or break into smaller pieces|,1,,@saradelessio-abt not a priority at this time,,https://api.github.com/repos/USEPA/EJAM/issues/29/comments,2/9/2023,2/10/2025,ejanalysis,alex-silverman,0,0,0,FALSE
178,27,open,Create LongReport (quarto/word doc/TSD) Settings Panel,enhancement|urgency medium|LongReport_output,4538805068|6227894519|6954028026,cfd3d7|FBCA04|304702,New feature or request||static word doc TSD on results of ejam run - via Quarto template,4,"In EJAM Shiny app, create panel for report settings including user-provided text and details, along with a preview and download of the Static Report (#28 ). Some existing code can be used from the EJAMbatch.summarizer Shiny app, but UI formatting will need to be improved.

User-provided features to include:
- name for analysis and (up to 2) comparisons
- percentile / threshold values for each set of (up to 2) comparisons
- fields to compare to thresholds: these will be lists of indicators, type TBD
- author name and email
- details about ""where"" an analysis took place, e.g. ""within XYZ miles of *""
- conclusions to add to report text

Other features:
- download button for static report
- preview of report file before downloading, indicating where their changes or placeholder text can be located","Some of the parameters should be prefilled but allow the user to change them, such as ""within 4 miles of"" would have the number 4 based on the radius that had been selected for analysis, but the user could edit those words if they want to.
|Some parameters are phrases that have about 3 to 7 reasonable options, so I'd like those to be offered via pulldown list. They would be examples of text that could be chosen and then further edited to be user-specific: 
IN_THE_X_ZONE could be, for example picked from this list: 
  in the study area//in the analyzed locations//in Colorado//in EPA Region XX
and then the user could change the word Colorado or whatever.|The long word doc static report parameters should be set in a tab or page that is sort of like what we already drafted and sort of like some of the Advanced settings tab. Right now the advanced tab has a placedholder for that and the long report tab that is hidden for now also had several parameters to be used by the long report. |Also see #383 about using Quarto",,https://api.github.com/repos/USEPA/EJAM/issues/27/comments,2/2/2023,5/16/2024,mlfurman3,ejanalysis,1,0,0,FALSE
179,11,open,Tools for multiple radius cutoffs (requery cached distances table and/or let user download it),enhancement|urgency medium|distance-related,4538805068|6227894519|6343333395,cfd3d7|FBCA04|C2E0C6,New feature or request||related to distances variables or calculations or plots,0,"Some users want stats on more than one radius, such as demographics and envt stats within 1 mile, within 2 miles, and within 5km and within 50km --  i.e., multiple buffer distances.  This would be useful and is a common user need. 

One solution that should be explored and probably implemented is storing the table of distances obtained from EJAM::getblocksnearby() which would save info on full distribution of distances, and then having UI/functions to let user query same points at different distance and get results immediately from doaggregate() applied to the same distances table but with a new cutoff distance  It would run doaggregate() again, but not have to run getblocksnearby() again. The simplest is to let user redo query with same points but new distance. 

A more useful but later solution would be to let them specify 2 or more distances up front and also to have standard summary tables that show results for the 2 or 3 distances in one table, to make clear how demographics and envt conditions may be different within 1 mile than within 5 miles, for example. Right now the results tables are all designed to show results for only 1 distance, so it would need new tables and graphics to be designed. Note the related ideas in #7 continuous distance versus this issue that is about 2 or 3 discreate distances. 

Also, expert users should be able to download the distances table and later analyze it for any set of distance cutpoints. 
",,,https://api.github.com/repos/USEPA/EJAM/issues/11/comments,1/31/2023,11/22/2024,ejanalysis,none,1,0,0,FALSE
180,6,open,"Enable areal apportionment as option, via existing OW and/or OP code",enhancement|urgency low|shapefile-related,4538805068|6227891676|6343756696,cfd3d7|cfd3d7|C2E0C6,New feature or request||related to polygons/ shapefile/ GIS data/ buffers,0,"The primary method of finding who lives in bounds of a shapefile will be finding blockpoints inside a shape. But we want to give users the option of using areal apportionment via code already written by OW and or NCEE. That needs to be adapted for inclusion in EJAM as an alternate method.  See the OW code in https://github.com/adamtheising/EJSCREENBatch or https://github.com/USEPA/EJSCREENBatch (not sure which is further ahead) and the NCEE/OP code MC can provide a copy of. They both have code to do areal apportionment of either raster grid cells or of block groups (I think).  

see notes also in   EJAM/inst/0- NOTES_BREAK_EJAM_INTO_FUNCTIONS.R",,,https://api.github.com/repos/USEPA/EJAM/issues/6/comments,1/30/2023,10/9/2024,ejanalysis,none,0,0,0,FALSE
181,2,open,"map popups in make.popups.api() and other functions are too cluttered, move most info to separate popup (see example in comment)",urgency medium|popups-related,6227894519|6228696683,FBCA04|C2E0C6,|related to map popups,1,https://campd.epa.gov/tools/facility-map/  is an example of showing some basic info on the map popup and then additional info in a separate popup where it does not get in the way of the map or cause problems with not seeing the whole popup within the map sometimes.,@saradelessio-abt not high priority at this time,,https://api.github.com/repos/USEPA/EJAM/issues/2/comments,1/30/2023,11/22/2024,ejanalysis,none,1,0,0,FALSE
